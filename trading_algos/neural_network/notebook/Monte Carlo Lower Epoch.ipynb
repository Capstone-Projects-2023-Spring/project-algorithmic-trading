{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688093b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from alpha_vantage.timeseries import TimeSeries \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas_market_calendars as mcal\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "os.chdir(\"../scripts\")\n",
    "import preprocess, train, inference, interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036137b",
   "metadata": {},
   "source": [
    "### Note that only 5% of the data is used for validation as we are concerned with short term predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05782eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"alpha_vantage\": {\n",
    "        \"key\": \"2JMCN347HZ3BU9RC\", \n",
    "        \"symbol\": \"SPY\",\n",
    "        \"outputsize\": \"full\",\n",
    "        \"key_adjusted_close\": \"5. adjusted close\",\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"window_size\": 20,\n",
    "        \"train_split_size\": 0.95,\n",
    "    }, \n",
    "    \"plots\": {\n",
    "        \"xticks_interval\": 90, # show a date every 90 days\n",
    "        \"color_actual\": \"#001f3f\",\n",
    "        \"color_train\": \"#3D9970\",\n",
    "        \"color_val\": \"#0074D9\",\n",
    "        \"color_pred_train\": \"#3D9970\",\n",
    "        \"color_pred_val\": \"#0074D9\",\n",
    "        \"color_pred_test\": \"#FF4136\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"input_size\": 1, # since for now we are only using close price\n",
    "        \"num_lstm_layers\": 2,\n",
    "        \"lstm_size\": 32,\n",
    "        \"dropout\": 0.2,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"device\": \"cpu\",\n",
    "        \"batch_size\": 64,\n",
    "        \"num_epoch\": 100,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"scheduler_step_size\": 40,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6915b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>390.800</td>\n",
       "      <td>393.74</td>\n",
       "      <td>390.07</td>\n",
       "      <td>394.17</td>\n",
       "      <td>93055783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5883</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>397.240</td>\n",
       "      <td>398.91</td>\n",
       "      <td>395.58</td>\n",
       "      <td>399.41</td>\n",
       "      <td>91524248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884</th>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>398.730</td>\n",
       "      <td>392.11</td>\n",
       "      <td>392.07</td>\n",
       "      <td>402.49</td>\n",
       "      <td>111746583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>395.090</td>\n",
       "      <td>393.17</td>\n",
       "      <td>390.35</td>\n",
       "      <td>399.29</td>\n",
       "      <td>119351319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5886</th>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>391.841</td>\n",
       "      <td>395.75</td>\n",
       "      <td>389.40</td>\n",
       "      <td>395.84</td>\n",
       "      <td>107770124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     Open   Close     Low    High       Volume\n",
       "5882  2023-03-20  390.800  393.74  390.07  394.17   93055783.0\n",
       "5883  2023-03-21  397.240  398.91  395.58  399.41   91524248.0\n",
       "5884  2023-03-22  398.730  392.11  392.07  402.49  111746583.0\n",
       "5885  2023-03-23  395.090  393.17  390.35  399.29  119351319.0\n",
       "5886  2023-03-24  391.841  395.75  389.40  395.84  107770124.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../model/params.yaml\", \"r\") as params_file:\n",
    "    params = yaml.safe_load(params_file)\n",
    "\n",
    "data_dir = params['data_dir']\n",
    "file_name = \"SPY.csv\"\n",
    "data = preprocess.load_data(file_name)\n",
    "data.columns = data.columns.str.capitalize()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23711909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of simulations and early stop amount\n",
    "\n",
    "n = 100\n",
    "stop = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54106e",
   "metadata": {},
   "source": [
    "### Univariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb560d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88.21718508,  87.58674188,  88.17651326, ..., 392.11      ,\n",
       "       393.17      , 395.75      ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data for univariate time series model \n",
    "\n",
    "num_data_points = len(data.index)\n",
    "date_data = data['Date'].to_numpy()\n",
    "display_date_range = \"from \" + date_data[0] + \" to \" + date_data[num_data_points-1]\n",
    "close_price_data = data['Close'].to_numpy()\n",
    "close_price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b1318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary classes for univariate model\n",
    "\n",
    "class Normalization():\n",
    "    def __init__(self):\n",
    "        self.mu = None\n",
    "        self.sd = None\n",
    "\n",
    "    def fit_transform(self, x):\n",
    "        self.mu = np.mean(x, axis=(0), keepdims=True)\n",
    "        self.sd = np.std(x, axis=(0), keepdims=True)\n",
    "        normalized_x = (x - self.mu)/self.sd\n",
    "        return normalized_x\n",
    "\n",
    "    def inverse_transform(self, x):\n",
    "        return (x*self.sd) + self.mu\n",
    "    \n",
    "def prepare_data_x(x, window_size):\n",
    "    # perform windowing\n",
    "    n_row = x.shape[0] - window_size + 1\n",
    "    output = np.lib.stride_tricks.as_strided(x, shape=(n_row, window_size), strides=(x.strides[0], x.strides[0]))\n",
    "    return output[:-1], output[-1]\n",
    "\n",
    "\n",
    "def prepare_data_y(x, window_size):\n",
    "    # use the next day as label\n",
    "    output = x[window_size:]\n",
    "    return output\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x = np.expand_dims(x, 2) # right now we have only 1 feature, so we need to convert `x` into [batch, sequence, features]\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=32, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(hidden_layer_size, hidden_size=self.hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(num_layers*hidden_layer_size, output_size)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                 nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                 nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                 nn.init.orthogonal_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # layer 1\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # reshape output from hidden cell into [batch, features] for `linear_2`\n",
    "        x = h_n.permute(1, 0, 2).reshape(batchsize, -1) \n",
    "        \n",
    "        # layer 2\n",
    "        x = self.dropout(x)\n",
    "        predictions = self.linear_2(x)\n",
    "        return predictions[:,-1]\n",
    "    \n",
    "def run_epoch(dataloader, is_training=False):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for idx, (x, y) in enumerate(dataloader):\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        x = x.to(config[\"training\"][\"device\"])\n",
    "        y = y.to(config[\"training\"][\"device\"])\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out.contiguous(), y.contiguous())\n",
    "\n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss += (loss.detach().item() / batchsize)\n",
    "\n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    return epoch_loss, lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9deb5444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (5573, 20, 1) (5573,)\n",
      "Validation data shape (294, 20, 1) (294,)\n"
     ]
    }
   ],
   "source": [
    "# prerequisite data manipulation\n",
    "\n",
    "scaler = Normalization()\n",
    "normalized_close_price_data = scaler.fit_transform(close_price_data)\n",
    "normalized_close_price_data\n",
    "\n",
    "data_x, data_x_unseen = prepare_data_x(normalized_close_price_data, window_size=config[\"data\"][\"window_size\"])\n",
    "data_y = prepare_data_y(normalized_close_price_data, window_size=config[\"data\"][\"window_size\"])\n",
    "\n",
    "split_index = int(data_y.shape[0]*config[\"data\"][\"train_split_size\"])\n",
    "data_x_train = data_x[:split_index]\n",
    "data_x_val = data_x[split_index:]\n",
    "data_y_train = data_y[:split_index]\n",
    "data_y_val = data_y[split_index:]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "val_dataset = TimeSeriesDataset(data_x_val, data_y_val)\n",
    "\n",
    "print(\"Train data shape\", train_dataset.x.shape, train_dataset.y.shape)\n",
    "print(\"Validation data shape\", val_dataset.x.shape, val_dataset.y.shape)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60e8562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] | loss train:0.079000, test:0.003074 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.015098, test:0.002027 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011957, test:0.000332 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013097, test:0.000290 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009396, test:0.005753 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010186, test:0.000375 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008221, test:0.001553 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011663, test:0.007646 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008623, test:0.001055 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007788, test:0.002245 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009263, test:0.000462 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007645, test:0.002081 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009320, test:0.003101 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009699, test:0.001230 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008617, test:0.000824 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008590, test:0.001847 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008198, test:0.000391 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010357, test:0.001580 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009575, test:0.000440 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008686, test:0.000470 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008528, test:0.000510 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008214, test:0.001691 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008199, test:0.000835 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008444, test:0.001257 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007406, test:0.000854 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007926, test:0.001602 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007120, test:0.000403 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007098, test:0.001407 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008385, test:0.000686 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006241, test:0.000406 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007385, test:0.000679 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007065, test:0.000419 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006864, test:0.000624 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006900, test:0.000412 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007943, test:0.003152 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008420, test:0.000431 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008324, test:0.004024 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007338, test:0.001668 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006875, test:0.000718 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007643, test:0.000995 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006470, test:0.000391 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005653, test:0.000748 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005593, test:0.000442 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005887, test:0.000362 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005562, test:0.000336 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005805, test:0.000352 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006071, test:0.000434 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006123, test:0.000332 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005239, test:0.000415 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005354, test:0.000382 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005542, test:0.000330 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005380, test:0.000343 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005382, test:0.000536 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005485, test:0.001116 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006347, test:0.000334 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006514, test:0.000392 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005237, test:0.000356 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005654, test:0.000545 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005739, test:0.000311 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005631, test:0.000616 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006261, test:0.000434 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005122, test:0.000502 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005777, test:0.000415 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005294, test:0.000407 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005418, test:0.000377 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.007234, test:0.000314 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005762, test:0.000323 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005222, test:0.000292 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005578, test:0.000351 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005548, test:0.000298 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005692, test:0.000342 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005202, test:0.000314 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005532, test:0.000339 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.009818, test:0.000422 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006183, test:0.000337 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005293, test:0.000421 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006737, test:0.000355 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.008244, test:0.000325 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005476, test:0.000328 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005927, test:0.000310 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004655, test:0.000309 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005821, test:0.000361 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006052, test:0.000338 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005097, test:0.000307 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.006020, test:0.000349 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.007136, test:0.000329 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005341, test:0.000359 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006078, test:0.000306 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005431, test:0.000308 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.007007, test:0.000343 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004994, test:0.000331 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005202, test:0.000300 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005810, test:0.000315 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005987, test:0.000341 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005133, test:0.000338 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005734, test:0.000370 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005446, test:0.000323 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005822, test:0.000318 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005648, test:0.000306 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005269, test:0.000314 | lr:0.000100\n",
      "Mean absolute error:  1.7088798243532306\n",
      "Root mean squared error:  5.795059182489413\n",
      "Epoch[1/100] | loss train:0.049701, test:0.000889 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010090, test:0.001538 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011484, test:0.002322 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013023, test:0.005991 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012320, test:0.003799 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010121, test:0.002486 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009316, test:0.002837 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009860, test:0.002190 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011743, test:0.003199 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010881, test:0.000595 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009856, test:0.000887 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007578, test:0.000877 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.013755, test:0.000569 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009185, test:0.000909 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.012437, test:0.001408 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007665, test:0.000448 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008391, test:0.000449 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007706, test:0.001091 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006723, test:0.002215 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007023, test:0.000811 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007610, test:0.000918 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006487, test:0.000401 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008546, test:0.002268 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.012909, test:0.001270 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008525, test:0.000933 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26/100] | loss train:0.008804, test:0.000584 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007563, test:0.000956 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008424, test:0.000794 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006308, test:0.000768 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007133, test:0.003354 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007793, test:0.002024 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009376, test:0.000759 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008253, test:0.003099 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007378, test:0.000363 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007376, test:0.000510 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008375, test:0.000741 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007419, test:0.000312 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006367, test:0.004608 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007634, test:0.000940 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006840, test:0.002296 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006548, test:0.000381 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005385, test:0.000384 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005367, test:0.000458 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005415, test:0.000400 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006316, test:0.000506 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004965, test:0.000341 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005877, test:0.000336 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005343, test:0.000376 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005094, test:0.000512 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006765, test:0.000334 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005493, test:0.000600 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006558, test:0.000418 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005287, test:0.000501 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006790, test:0.000339 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005723, test:0.000303 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005192, test:0.000591 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005744, test:0.000362 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005522, test:0.000342 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005210, test:0.000645 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.007026, test:0.000363 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005160, test:0.000296 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005097, test:0.000296 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005311, test:0.000385 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006777, test:0.000319 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005356, test:0.000329 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005674, test:0.000311 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.008917, test:0.000372 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005532, test:0.000422 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006024, test:0.000314 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005148, test:0.000334 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005966, test:0.000331 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005219, test:0.000327 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005115, test:0.000337 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005751, test:0.000503 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005769, test:0.000310 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005494, test:0.000457 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005864, test:0.000308 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005466, test:0.000338 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004752, test:0.000339 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006474, test:0.000331 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.007469, test:0.000307 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004816, test:0.000308 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006620, test:0.000308 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005147, test:0.000305 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005084, test:0.000364 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005539, test:0.000299 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005249, test:0.000327 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006708, test:0.000319 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005372, test:0.000312 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005181, test:0.000312 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006014, test:0.000327 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005214, test:0.000298 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004926, test:0.000359 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005362, test:0.000328 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005186, test:0.000297 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005958, test:0.000332 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004913, test:0.000298 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004870, test:0.000293 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005079, test:0.000302 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004742, test:0.000320 | lr:0.000100\n",
      "Mean absolute error:  1.7129679907086046\n",
      "Root mean squared error:  5.791321815793805\n",
      "Epoch[1/100] | loss train:0.054059, test:0.000719 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010107, test:0.000802 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012330, test:0.001648 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.017639, test:0.008001 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009424, test:0.001916 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009194, test:0.000325 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008954, test:0.000509 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007113, test:0.000631 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010750, test:0.001397 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008500, test:0.000445 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.014074, test:0.002605 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009019, test:0.001502 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008517, test:0.001463 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006678, test:0.000738 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007262, test:0.000643 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.014233, test:0.002561 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009716, test:0.000468 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007603, test:0.002207 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007232, test:0.000748 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007944, test:0.000374 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006757, test:0.005534 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008853, test:0.005603 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010181, test:0.000993 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008649, test:0.000615 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007476, test:0.000465 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007501, test:0.005524 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.010237, test:0.001737 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007949, test:0.006382 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008047, test:0.000307 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007409, test:0.001398 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007455, test:0.000392 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007020, test:0.000375 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006288, test:0.000384 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008227, test:0.001540 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008029, test:0.001143 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006132, test:0.000660 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007304, test:0.001749 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007544, test:0.000345 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006250, test:0.000313 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007117, test:0.000434 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005257, test:0.000445 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005319, test:0.000290 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005496, test:0.000437 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005275, test:0.000331 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005265, test:0.000297 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005077, test:0.000309 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005358, test:0.000298 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004841, test:0.000339 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004921, test:0.000295 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004920, test:0.000362 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[51/100] | loss train:0.005158, test:0.000333 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005125, test:0.000505 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004647, test:0.000489 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005183, test:0.000295 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004854, test:0.000403 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005178, test:0.000411 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004831, test:0.000306 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005706, test:0.000395 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005475, test:0.000287 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004822, test:0.000358 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005395, test:0.000326 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005533, test:0.000389 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.017045, test:0.000326 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004581, test:0.000300 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005330, test:0.000618 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006746, test:0.000334 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004677, test:0.000356 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005821, test:0.000352 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005206, test:0.000385 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004586, test:0.000403 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005229, test:0.000315 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.011736, test:0.000549 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005901, test:0.000418 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004934, test:0.000308 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.007221, test:0.000337 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004934, test:0.000388 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005236, test:0.000281 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004823, test:0.000402 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005919, test:0.000466 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005349, test:0.000310 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005497, test:0.000307 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005022, test:0.000303 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004858, test:0.000299 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005012, test:0.000288 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004945, test:0.000308 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.009834, test:0.000300 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005001, test:0.000274 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005251, test:0.000293 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005513, test:0.000323 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006422, test:0.000289 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.007636, test:0.000303 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004717, test:0.000303 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004649, test:0.000313 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005147, test:0.000308 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005169, test:0.000314 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005060, test:0.000301 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005657, test:0.000284 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004569, test:0.000301 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005893, test:0.000302 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004824, test:0.000285 | lr:0.000100\n",
      "Mean absolute error:  1.6609033819781078\n",
      "Root mean squared error:  5.782275615481974\n",
      "Epoch[1/100] | loss train:0.065622, test:0.001586 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013935, test:0.000786 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.017151, test:0.001487 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011537, test:0.005181 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011184, test:0.005521 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011361, test:0.000303 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010484, test:0.001231 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.014628, test:0.004126 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.013572, test:0.008153 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009319, test:0.000455 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007574, test:0.002404 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008829, test:0.002655 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009943, test:0.000343 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009195, test:0.000726 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009003, test:0.000688 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008067, test:0.001245 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007792, test:0.000552 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008425, test:0.001952 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007865, test:0.000928 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007156, test:0.000687 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.011696, test:0.008204 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008807, test:0.003142 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008181, test:0.000442 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009980, test:0.002613 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007743, test:0.000834 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007513, test:0.000644 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007355, test:0.001353 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007989, test:0.002068 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007129, test:0.000453 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006629, test:0.000505 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006813, test:0.001310 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008878, test:0.001483 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008662, test:0.001289 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008073, test:0.000914 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007547, test:0.001981 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008196, test:0.000478 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006968, test:0.001004 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007143, test:0.001231 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007245, test:0.000504 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006711, test:0.000467 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007488, test:0.000404 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005526, test:0.000390 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005138, test:0.000423 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005353, test:0.000388 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005455, test:0.000407 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005836, test:0.000386 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005059, test:0.000467 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005351, test:0.000398 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005946, test:0.000372 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005569, test:0.000359 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005217, test:0.000442 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005066, test:0.000371 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005186, test:0.000506 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006590, test:0.000344 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005169, test:0.000376 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005475, test:0.000362 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005151, test:0.000412 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005522, test:0.000368 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005217, test:0.000379 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005479, test:0.000336 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004631, test:0.000363 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005503, test:0.000483 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005209, test:0.000357 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005940, test:0.000612 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005046, test:0.000362 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005169, test:0.000446 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005454, test:0.000348 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006197, test:0.000294 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005208, test:0.000382 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004832, test:0.000349 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004679, test:0.000348 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005550, test:0.000688 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005658, test:0.000425 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005271, test:0.000353 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005085, test:0.000394 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[76/100] | loss train:0.005213, test:0.000339 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004978, test:0.000574 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005081, test:0.000358 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005236, test:0.000326 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005358, test:0.000358 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005420, test:0.000388 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005140, test:0.000366 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004893, test:0.000364 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004799, test:0.000331 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004893, test:0.000365 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004938, test:0.000345 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004738, test:0.000358 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004654, test:0.000348 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005562, test:0.000366 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006082, test:0.000324 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.011195, test:0.000380 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005311, test:0.000375 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005432, test:0.000331 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004381, test:0.000337 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005064, test:0.000311 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004903, test:0.000329 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005126, test:0.000329 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.007425, test:0.000377 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005180, test:0.000333 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005740, test:0.000314 | lr:0.000100\n",
      "Mean absolute error:  1.6940261510708214\n",
      "Root mean squared error:  5.796586451629025\n",
      "Epoch[1/100] | loss train:0.045797, test:0.001325 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011532, test:0.000747 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009488, test:0.000279 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013385, test:0.009532 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.013288, test:0.000420 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009708, test:0.009648 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009378, test:0.000303 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008919, test:0.000807 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010925, test:0.001670 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007762, test:0.000363 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008731, test:0.000497 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008556, test:0.001451 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008476, test:0.002536 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008802, test:0.001473 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007483, test:0.000492 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008668, test:0.000559 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007597, test:0.000632 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006895, test:0.000549 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007103, test:0.000585 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.010544, test:0.002683 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.011486, test:0.001013 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008418, test:0.001167 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007095, test:0.000575 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007354, test:0.000434 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009562, test:0.000469 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008555, test:0.000982 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006953, test:0.001167 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.010125, test:0.001735 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008713, test:0.000379 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007963, test:0.000646 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008160, test:0.000979 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009798, test:0.000693 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008222, test:0.000658 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008569, test:0.004919 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007982, test:0.000397 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006547, test:0.000435 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007381, test:0.001118 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008048, test:0.000375 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008241, test:0.000593 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007035, test:0.001049 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005898, test:0.000529 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006185, test:0.000455 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005220, test:0.000379 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005454, test:0.000375 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006531, test:0.000443 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005734, test:0.000370 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005327, test:0.000425 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006098, test:0.000388 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005393, test:0.000472 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005667, test:0.000412 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.009188, test:0.000391 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005032, test:0.000373 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005554, test:0.000366 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005335, test:0.000398 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004868, test:0.000474 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005599, test:0.000391 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005248, test:0.000344 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005074, test:0.000341 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005186, test:0.000489 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004927, test:0.000326 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005543, test:0.000578 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005197, test:0.000362 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006538, test:0.000554 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006185, test:0.000573 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005033, test:0.000661 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004843, test:0.000371 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005465, test:0.000387 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005060, test:0.000311 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005758, test:0.000369 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004975, test:0.000346 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004879, test:0.000394 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004918, test:0.000332 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005144, test:0.000452 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006425, test:0.000474 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006769, test:0.000338 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005670, test:0.000523 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005159, test:0.000365 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005339, test:0.000328 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005910, test:0.000330 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005241, test:0.000608 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005016, test:0.000356 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006793, test:0.000336 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004651, test:0.000320 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005121, test:0.000353 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004926, test:0.000339 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005144, test:0.000420 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005439, test:0.000338 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004427, test:0.000340 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005758, test:0.000390 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005259, test:0.000341 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005485, test:0.000359 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004860, test:0.000343 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.011944, test:0.000335 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005434, test:0.000338 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.009715, test:0.000310 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005177, test:0.000359 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.006340, test:0.000337 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005582, test:0.000315 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004943, test:0.000361 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005224, test:0.000325 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error:  1.731096765328927\n",
      "Root mean squared error:  5.808278556974992\n",
      "Epoch[1/100] | loss train:0.044094, test:0.000659 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009674, test:0.000367 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013513, test:0.007223 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009263, test:0.001122 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008372, test:0.003767 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009149, test:0.001460 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007396, test:0.000321 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009535, test:0.001094 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007971, test:0.001366 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007014, test:0.005660 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011275, test:0.000586 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007832, test:0.000457 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007746, test:0.002041 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008698, test:0.003216 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007011, test:0.000603 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006430, test:0.004749 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007562, test:0.002218 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.011471, test:0.000524 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007789, test:0.000640 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008455, test:0.000520 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006765, test:0.000500 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.017108, test:0.000908 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008076, test:0.002402 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007602, test:0.003276 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007139, test:0.002857 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008167, test:0.001271 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007139, test:0.000584 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006583, test:0.000490 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006606, test:0.000382 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006965, test:0.000495 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008063, test:0.000614 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008148, test:0.000477 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008717, test:0.006024 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007388, test:0.000554 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007056, test:0.000758 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006721, test:0.000505 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008162, test:0.001117 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008571, test:0.001216 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008670, test:0.001137 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006653, test:0.000456 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006946, test:0.000324 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005544, test:0.000283 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.004939, test:0.000285 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005568, test:0.000496 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005073, test:0.000366 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004931, test:0.000387 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005324, test:0.000283 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005087, test:0.000415 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006995, test:0.000423 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006690, test:0.000354 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005058, test:0.000303 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005968, test:0.000455 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006716, test:0.000402 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005112, test:0.000355 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005019, test:0.000368 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004954, test:0.000311 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004984, test:0.000363 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004927, test:0.000326 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005720, test:0.000331 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005185, test:0.000426 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006615, test:0.000326 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006407, test:0.000324 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004849, test:0.000285 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005895, test:0.000344 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004822, test:0.000432 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.008037, test:0.000443 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004710, test:0.000350 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005162, test:0.000348 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005394, test:0.000297 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005314, test:0.000390 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005529, test:0.000390 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005066, test:0.000386 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004849, test:0.000352 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005322, test:0.000437 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005013, test:0.000308 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005641, test:0.000434 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005858, test:0.000316 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005101, test:0.000324 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005030, test:0.000399 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005960, test:0.000293 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004803, test:0.000319 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004860, test:0.000310 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006007, test:0.000299 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004714, test:0.000301 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005483, test:0.000289 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.006673, test:0.000330 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005337, test:0.000308 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004552, test:0.000297 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004834, test:0.000310 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005327, test:0.000281 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004686, test:0.000280 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.006203, test:0.000301 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004570, test:0.000301 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004739, test:0.000279 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005036, test:0.000304 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004902, test:0.000300 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004940, test:0.000287 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005280, test:0.000290 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.012711, test:0.000297 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005280, test:0.000282 | lr:0.000100\n",
      "Mean absolute error:  1.642795649365509\n",
      "Root mean squared error:  5.762085210582546\n",
      "Epoch[1/100] | loss train:0.047138, test:0.001990 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010081, test:0.003281 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010562, test:0.000824 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010201, test:0.001868 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011022, test:0.005947 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008779, test:0.001675 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011721, test:0.004143 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010625, test:0.010286 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010770, test:0.000663 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007764, test:0.002563 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009397, test:0.000582 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007349, test:0.000354 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007987, test:0.002346 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009187, test:0.000501 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006973, test:0.007239 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008109, test:0.001447 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006980, test:0.000515 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007557, test:0.001385 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008401, test:0.000860 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007333, test:0.001383 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007239, test:0.000469 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006683, test:0.000976 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007055, test:0.000925 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006626, test:0.000380 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/100] | loss train:0.007963, test:0.001257 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006638, test:0.001644 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.025249, test:0.002255 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008637, test:0.000556 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006529, test:0.002495 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.011548, test:0.001707 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009294, test:0.000417 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006534, test:0.000532 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007043, test:0.002375 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006654, test:0.000679 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007366, test:0.000403 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007168, test:0.001473 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007225, test:0.003414 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006487, test:0.000862 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007068, test:0.001010 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007786, test:0.001450 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.008960, test:0.000408 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005738, test:0.000441 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.008257, test:0.000425 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005764, test:0.000406 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005109, test:0.000383 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005491, test:0.000395 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004803, test:0.000325 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006866, test:0.000414 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005338, test:0.000539 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005308, test:0.000384 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005266, test:0.000356 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005313, test:0.000683 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005544, test:0.000343 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006165, test:0.000334 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005213, test:0.000486 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004669, test:0.000431 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005286, test:0.000306 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005497, test:0.000438 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005402, test:0.000482 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004946, test:0.000337 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004833, test:0.000535 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004918, test:0.000464 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004849, test:0.000329 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004870, test:0.000557 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005369, test:0.000327 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005114, test:0.000337 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.010967, test:0.000357 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004948, test:0.000337 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004760, test:0.000365 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005518, test:0.000429 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005431, test:0.000354 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005459, test:0.000375 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004968, test:0.000513 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005030, test:0.000568 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004877, test:0.000372 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.008217, test:0.000416 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005144, test:0.000341 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005101, test:0.000338 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005091, test:0.000445 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005999, test:0.000553 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006875, test:0.000335 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005152, test:0.000358 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005511, test:0.000351 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004840, test:0.000337 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005102, test:0.000358 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005469, test:0.000324 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004841, test:0.000348 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004873, test:0.000310 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005003, test:0.000321 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005114, test:0.000309 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005164, test:0.000346 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.006369, test:0.000334 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004779, test:0.000337 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005222, test:0.000354 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004563, test:0.000312 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004782, test:0.000329 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004682, test:0.000342 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005124, test:0.000305 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004959, test:0.000326 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004819, test:0.000334 | lr:0.000100\n",
      "Mean absolute error:  1.6848124763158885\n",
      "Root mean squared error:  5.783896975756419\n",
      "Epoch[1/100] | loss train:0.041773, test:0.001186 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010793, test:0.000322 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008612, test:0.000368 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010148, test:0.000743 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008550, test:0.000679 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009499, test:0.000314 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009279, test:0.001220 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008104, test:0.004728 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008505, test:0.001965 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007471, test:0.000646 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008795, test:0.000377 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007138, test:0.001528 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008563, test:0.001150 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007118, test:0.000402 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006973, test:0.000424 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007281, test:0.002616 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008196, test:0.002897 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009001, test:0.002741 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009182, test:0.001378 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006378, test:0.001165 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009265, test:0.001780 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009097, test:0.001295 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008783, test:0.001683 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007568, test:0.001341 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009118, test:0.001108 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007351, test:0.003763 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.013447, test:0.000538 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007541, test:0.000703 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.014277, test:0.001666 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008531, test:0.002024 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007920, test:0.000479 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006600, test:0.000320 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006952, test:0.000503 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007470, test:0.000899 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006593, test:0.000671 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006794, test:0.000582 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008085, test:0.002146 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006645, test:0.000642 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007205, test:0.000432 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006818, test:0.001704 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005433, test:0.000412 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005902, test:0.000420 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005075, test:0.000481 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006152, test:0.000451 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006080, test:0.000397 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005405, test:0.000386 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005044, test:0.000399 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004886, test:0.000376 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005382, test:0.000349 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[50/100] | loss train:0.006192, test:0.000382 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004756, test:0.000425 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004703, test:0.000413 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004792, test:0.000340 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005348, test:0.000519 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005343, test:0.000511 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004881, test:0.000454 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005180, test:0.000341 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004622, test:0.000351 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.009099, test:0.000347 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005202, test:0.000349 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004520, test:0.000498 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005308, test:0.000351 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005318, test:0.000950 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005803, test:0.000360 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004936, test:0.000459 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005626, test:0.000555 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004822, test:0.000534 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005067, test:0.000467 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005663, test:0.000479 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005025, test:0.000432 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005662, test:0.000334 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004849, test:0.000325 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005257, test:0.000514 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005266, test:0.000361 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006713, test:0.000361 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004842, test:0.000460 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005154, test:0.000358 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005548, test:0.000365 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005697, test:0.000461 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004970, test:0.000504 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005701, test:0.000309 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005229, test:0.000298 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005695, test:0.000326 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004906, test:0.000334 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004853, test:0.000341 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005061, test:0.000308 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005245, test:0.000341 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004983, test:0.000319 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006789, test:0.000336 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004882, test:0.000306 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005947, test:0.000359 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004857, test:0.000299 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006322, test:0.000327 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005751, test:0.000302 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004986, test:0.000312 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004846, test:0.000300 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004754, test:0.000325 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004787, test:0.000318 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004776, test:0.000319 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005047, test:0.000328 | lr:0.000100\n",
      "Mean absolute error:  1.7856455729083904\n",
      "Root mean squared error:  5.858071531399732\n",
      "Epoch[1/100] | loss train:0.060384, test:0.003573 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011169, test:0.000459 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009214, test:0.001012 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009200, test:0.002880 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008756, test:0.000434 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007396, test:0.000296 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008602, test:0.003493 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007812, test:0.002361 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007665, test:0.002550 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007927, test:0.001096 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009238, test:0.000342 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007965, test:0.006599 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007759, test:0.000801 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007198, test:0.004714 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.012558, test:0.002367 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006793, test:0.000538 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008560, test:0.000482 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006777, test:0.000501 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.014912, test:0.001127 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008681, test:0.000544 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007138, test:0.004235 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007745, test:0.000635 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007890, test:0.001791 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007733, test:0.000578 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007147, test:0.000803 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009397, test:0.000972 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007900, test:0.000613 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009585, test:0.001732 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007184, test:0.001470 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007284, test:0.002721 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008815, test:0.000360 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007658, test:0.003389 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006201, test:0.000823 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007123, test:0.000517 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007092, test:0.000907 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006524, test:0.001825 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007525, test:0.000491 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006355, test:0.000519 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006527, test:0.003555 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007028, test:0.000764 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005498, test:0.000817 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005362, test:0.000350 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005432, test:0.000411 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005304, test:0.000315 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005239, test:0.000474 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005513, test:0.000344 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007185, test:0.000444 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004642, test:0.000516 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005073, test:0.000329 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005181, test:0.000514 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005004, test:0.000382 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004892, test:0.000415 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004954, test:0.000315 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004803, test:0.000463 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004967, test:0.000361 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.009572, test:0.000461 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004939, test:0.000316 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005398, test:0.000446 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005478, test:0.000304 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004789, test:0.000344 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004863, test:0.000564 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005223, test:0.000340 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.007027, test:0.000300 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006746, test:0.000447 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004985, test:0.000337 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004779, test:0.000348 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005805, test:0.000375 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004838, test:0.000317 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005396, test:0.000303 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004963, test:0.000325 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005438, test:0.000470 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.008455, test:0.000468 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004834, test:0.000364 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005218, test:0.000314 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[75/100] | loss train:0.008041, test:0.000375 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006727, test:0.000296 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004928, test:0.000320 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004890, test:0.000288 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005011, test:0.000410 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004881, test:0.000320 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005139, test:0.000301 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005387, test:0.000309 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004868, test:0.000300 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.007436, test:0.000304 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005111, test:0.000290 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005362, test:0.000311 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004439, test:0.000311 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004495, test:0.000291 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005247, test:0.000270 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004813, test:0.000290 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005137, test:0.000297 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.008917, test:0.000301 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.007017, test:0.000291 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.009327, test:0.000311 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004641, test:0.000311 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004961, test:0.000321 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005318, test:0.000327 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004701, test:0.000358 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004854, test:0.000295 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005187, test:0.000329 | lr:0.000100\n",
      "Mean absolute error:  1.741752940360249\n",
      "Root mean squared error:  5.81979417425903\n",
      "Epoch[1/100] | loss train:0.052108, test:0.000750 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011631, test:0.000390 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009348, test:0.001552 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010177, test:0.003192 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009382, test:0.002436 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007366, test:0.003873 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009281, test:0.000485 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009846, test:0.000379 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009054, test:0.000382 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007524, test:0.000340 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008776, test:0.000376 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007965, test:0.000740 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007667, test:0.000482 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009329, test:0.000759 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007553, test:0.001344 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007415, test:0.004904 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007263, test:0.002818 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008729, test:0.000513 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008554, test:0.000415 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008294, test:0.002608 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006190, test:0.000618 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010783, test:0.002167 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007736, test:0.003295 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007612, test:0.002131 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007306, test:0.000936 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007238, test:0.004173 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006879, test:0.000377 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006952, test:0.001051 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006463, test:0.000394 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008529, test:0.000581 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006537, test:0.001075 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006850, test:0.000336 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008029, test:0.000495 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007286, test:0.001305 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008666, test:0.001434 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007645, test:0.001149 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007266, test:0.000436 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006102, test:0.002135 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008020, test:0.000297 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008107, test:0.001667 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005811, test:0.000394 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007220, test:0.000376 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005912, test:0.000540 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005505, test:0.000306 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005731, test:0.000334 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005903, test:0.000378 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005680, test:0.000340 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004840, test:0.000407 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005092, test:0.000319 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005311, test:0.000310 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005030, test:0.000336 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004826, test:0.000329 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006137, test:0.000366 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006397, test:0.000485 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005033, test:0.000341 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005497, test:0.000354 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005343, test:0.000333 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004867, test:0.000321 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005175, test:0.000304 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004904, test:0.000291 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005289, test:0.000309 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005197, test:0.000326 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005422, test:0.000380 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005234, test:0.000629 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005580, test:0.000302 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004633, test:0.000352 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005235, test:0.000454 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004919, test:0.000340 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006071, test:0.000480 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005115, test:0.000374 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004723, test:0.000349 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005182, test:0.000305 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005469, test:0.000314 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004658, test:0.000341 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004950, test:0.000329 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005464, test:0.000377 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005028, test:0.000346 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004924, test:0.000426 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004932, test:0.000316 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005042, test:0.000313 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.007229, test:0.000325 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005037, test:0.000314 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005222, test:0.000331 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005036, test:0.000313 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005108, test:0.000300 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004568, test:0.000298 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004653, test:0.000307 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005185, test:0.000280 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004934, test:0.000343 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005224, test:0.000307 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.007019, test:0.000316 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004739, test:0.000319 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004596, test:0.000312 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005847, test:0.000292 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005155, test:0.000288 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.007051, test:0.000281 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004551, test:0.000314 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006086, test:0.000291 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005106, test:0.000294 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[100/100] | loss train:0.010912, test:0.000332 | lr:0.000100\n",
      "Mean absolute error:  1.7510201254624465\n",
      "Root mean squared error:  5.824139977090864\n",
      "Epoch[1/100] | loss train:0.038913, test:0.003893 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014419, test:0.001161 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011384, test:0.005967 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009956, test:0.001089 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008178, test:0.000398 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007962, test:0.001436 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.018099, test:0.004784 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011584, test:0.000636 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008079, test:0.000409 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007515, test:0.000429 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009259, test:0.000478 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.006798, test:0.000632 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010785, test:0.010702 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008699, test:0.000987 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008890, test:0.002641 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007319, test:0.000428 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.011334, test:0.002711 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009119, test:0.000358 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006914, test:0.001666 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008610, test:0.003497 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008004, test:0.000441 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009928, test:0.000958 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008980, test:0.000375 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007284, test:0.000476 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007284, test:0.000598 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007410, test:0.001084 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008266, test:0.001258 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007453, test:0.001445 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007744, test:0.006886 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.011370, test:0.000614 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007327, test:0.002572 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007632, test:0.001119 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008447, test:0.002889 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009082, test:0.001025 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007389, test:0.000338 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006248, test:0.000813 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006531, test:0.001067 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006801, test:0.001316 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007456, test:0.000465 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.005728, test:0.000693 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006326, test:0.000401 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005396, test:0.000389 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.013652, test:0.000383 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005608, test:0.000332 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005058, test:0.000390 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005693, test:0.000344 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005321, test:0.000447 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004912, test:0.000360 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005547, test:0.000395 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005031, test:0.000407 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005471, test:0.000326 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005115, test:0.000584 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004841, test:0.000349 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005583, test:0.000336 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004740, test:0.000379 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004614, test:0.000344 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005275, test:0.000331 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005895, test:0.000334 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004864, test:0.000424 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004808, test:0.000384 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005185, test:0.000384 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005151, test:0.000407 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004956, test:0.000352 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004562, test:0.000377 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004797, test:0.000392 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005147, test:0.000392 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005130, test:0.000389 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005109, test:0.000367 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005081, test:0.000383 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005198, test:0.000368 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005765, test:0.000352 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005830, test:0.000761 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005798, test:0.000374 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005158, test:0.000330 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005907, test:0.000414 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005301, test:0.000448 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005263, test:0.000331 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005100, test:0.000329 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005132, test:0.000418 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004905, test:0.000532 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005580, test:0.000370 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004920, test:0.000326 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006026, test:0.000329 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005346, test:0.000344 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.007265, test:0.000334 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.006002, test:0.000338 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005674, test:0.000341 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006413, test:0.000344 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004673, test:0.000323 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005058, test:0.000323 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005104, test:0.000319 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004833, test:0.000319 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004914, test:0.000354 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004860, test:0.000313 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005419, test:0.000350 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005120, test:0.000333 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004823, test:0.000343 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005107, test:0.000320 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004523, test:0.000349 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005173, test:0.000333 | lr:0.000100\n",
      "Mean absolute error:  1.6743260967030835\n",
      "Root mean squared error:  5.7957204004492295\n",
      "Epoch[1/100] | loss train:0.066158, test:0.000586 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011185, test:0.000921 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009781, test:0.000461 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008914, test:0.007167 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012708, test:0.006501 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010141, test:0.000496 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010277, test:0.002268 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008327, test:0.001262 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008715, test:0.003470 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008270, test:0.002387 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008802, test:0.000499 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008250, test:0.003263 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.014762, test:0.003154 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008807, test:0.001676 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009930, test:0.000397 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007670, test:0.000552 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007017, test:0.000558 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008358, test:0.000432 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007479, test:0.000562 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008186, test:0.000545 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007925, test:0.000982 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008781, test:0.000533 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008178, test:0.001524 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[24/100] | loss train:0.006945, test:0.000600 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007385, test:0.000747 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006544, test:0.001828 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007054, test:0.000608 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006505, test:0.004115 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007597, test:0.000314 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006553, test:0.000669 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007436, test:0.001377 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006488, test:0.000921 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006740, test:0.000507 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.010173, test:0.000359 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006338, test:0.002257 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007006, test:0.000806 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009559, test:0.000480 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006159, test:0.000405 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006021, test:0.000717 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007886, test:0.000612 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005649, test:0.000346 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.004815, test:0.000295 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005364, test:0.000289 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005650, test:0.000317 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006615, test:0.000303 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004907, test:0.000331 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005125, test:0.000297 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005952, test:0.000436 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005109, test:0.000347 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006151, test:0.000348 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005393, test:0.000292 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004864, test:0.000378 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005210, test:0.000278 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005025, test:0.000666 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005118, test:0.000399 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005086, test:0.000309 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005157, test:0.000333 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004832, test:0.000327 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005517, test:0.000710 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004591, test:0.000289 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005070, test:0.000273 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004825, test:0.000291 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005318, test:0.000285 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005320, test:0.000293 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005330, test:0.000341 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004958, test:0.000315 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005383, test:0.000291 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004802, test:0.000291 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004664, test:0.000375 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005082, test:0.000294 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005013, test:0.000421 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005140, test:0.000322 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006101, test:0.000429 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005245, test:0.000312 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004992, test:0.000297 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005361, test:0.000317 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005803, test:0.000365 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005513, test:0.000370 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005164, test:0.000294 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004921, test:0.000426 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005152, test:0.000280 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004601, test:0.000269 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004747, test:0.000279 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005475, test:0.000275 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005194, test:0.000347 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005757, test:0.000276 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006420, test:0.000283 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004473, test:0.000323 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004456, test:0.000281 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004810, test:0.000316 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004970, test:0.000322 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004933, test:0.000264 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005513, test:0.000277 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004806, test:0.000281 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005095, test:0.000289 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005973, test:0.000291 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.006978, test:0.000288 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004925, test:0.000298 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005024, test:0.000278 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004568, test:0.000282 | lr:0.000100\n",
      "Mean absolute error:  1.6666650877777214\n",
      "Root mean squared error:  5.7779382641428825\n",
      "Epoch[1/100] | loss train:0.070521, test:0.000487 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012685, test:0.002073 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.017639, test:0.013635 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011657, test:0.000360 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007877, test:0.000629 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007674, test:0.000322 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007962, test:0.000541 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007995, test:0.001306 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008769, test:0.001003 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010850, test:0.002574 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011371, test:0.001689 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007834, test:0.000405 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008432, test:0.002518 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007746, test:0.002179 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007385, test:0.002413 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009028, test:0.002322 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008310, test:0.000490 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007629, test:0.000795 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008217, test:0.000412 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009547, test:0.005537 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008933, test:0.000416 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007460, test:0.000876 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008484, test:0.000828 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008954, test:0.001694 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.015957, test:0.002123 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.010277, test:0.002274 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008918, test:0.001410 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008930, test:0.004362 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007410, test:0.000597 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009609, test:0.004234 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008391, test:0.000498 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007600, test:0.003765 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007260, test:0.000470 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007051, test:0.000906 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007252, test:0.000389 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007073, test:0.000926 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007331, test:0.002727 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007360, test:0.001861 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007161, test:0.000538 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007326, test:0.002077 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006156, test:0.000418 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005294, test:0.000666 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005540, test:0.000508 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.007319, test:0.000449 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005540, test:0.000705 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005480, test:0.000397 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005848, test:0.000979 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005599, test:0.000499 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49/100] | loss train:0.005634, test:0.000576 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005367, test:0.000352 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005680, test:0.000358 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005466, test:0.000730 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005586, test:0.000481 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005099, test:0.000489 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005058, test:0.000432 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005131, test:0.000633 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.007230, test:0.000371 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005184, test:0.000357 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005165, test:0.000685 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005162, test:0.000623 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005848, test:0.000397 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005219, test:0.000388 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005850, test:0.000406 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004712, test:0.000319 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.007643, test:0.000477 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005234, test:0.000330 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004973, test:0.000417 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005439, test:0.000393 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005592, test:0.000341 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005358, test:0.000572 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006573, test:0.000317 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005360, test:0.000353 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005116, test:0.000305 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004768, test:0.000334 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005469, test:0.000350 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005102, test:0.000319 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005349, test:0.000451 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005313, test:0.000357 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.008178, test:0.000374 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005350, test:0.000349 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005051, test:0.000377 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005246, test:0.000373 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005413, test:0.000344 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004995, test:0.000343 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005139, test:0.000319 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005540, test:0.000328 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004757, test:0.000326 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005115, test:0.000330 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004677, test:0.000368 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.007221, test:0.000315 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004864, test:0.000316 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004903, test:0.000320 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005150, test:0.000322 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005054, test:0.000367 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005874, test:0.000303 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005522, test:0.000350 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004992, test:0.000322 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005422, test:0.000348 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005610, test:0.000329 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004994, test:0.000331 | lr:0.000100\n",
      "Mean absolute error:  1.6886711869112403\n",
      "Root mean squared error:  5.804070582893531\n",
      "Epoch[1/100] | loss train:0.059464, test:0.000534 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010437, test:0.000597 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011190, test:0.001456 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010060, test:0.003621 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008846, test:0.000281 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008561, test:0.000388 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009846, test:0.000909 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009880, test:0.001119 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.015345, test:0.003220 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009879, test:0.001498 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007764, test:0.001715 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007603, test:0.002444 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008444, test:0.000948 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008034, test:0.001513 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007224, test:0.001966 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007076, test:0.000563 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007128, test:0.001012 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007396, test:0.000319 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007505, test:0.000391 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007341, test:0.003252 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008544, test:0.001071 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007076, test:0.005734 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008319, test:0.000364 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006968, test:0.002011 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007734, test:0.000449 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006746, test:0.000363 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007433, test:0.000387 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006880, test:0.001180 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007494, test:0.001189 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006956, test:0.000738 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006570, test:0.001877 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007956, test:0.001038 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006606, test:0.000367 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007527, test:0.000875 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007039, test:0.000502 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008423, test:0.001890 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007418, test:0.000632 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007541, test:0.000321 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007808, test:0.000498 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006422, test:0.001038 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006174, test:0.000459 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005732, test:0.000406 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006229, test:0.000545 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005901, test:0.000569 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005894, test:0.000361 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005534, test:0.000343 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005287, test:0.000385 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004911, test:0.000340 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006751, test:0.000356 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005242, test:0.000327 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005407, test:0.000314 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005559, test:0.000334 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005786, test:0.000314 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005018, test:0.000347 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005407, test:0.000388 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005833, test:0.000299 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005248, test:0.000310 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004737, test:0.000320 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.013716, test:0.000301 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005183, test:0.000298 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005159, test:0.000323 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.010622, test:0.000386 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005393, test:0.000382 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005347, test:0.000431 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004810, test:0.000307 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005034, test:0.000323 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005471, test:0.000784 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005606, test:0.000332 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005136, test:0.000309 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006445, test:0.000368 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005238, test:0.000300 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004892, test:0.000441 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005394, test:0.000295 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[74/100] | loss train:0.008060, test:0.000314 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006120, test:0.000302 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004763, test:0.000318 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005294, test:0.000485 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004902, test:0.000437 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005093, test:0.000383 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005358, test:0.000366 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005309, test:0.000305 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004971, test:0.000319 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005199, test:0.000372 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005548, test:0.000347 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004992, test:0.000285 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005024, test:0.000287 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005594, test:0.000313 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006239, test:0.000309 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006561, test:0.000310 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004876, test:0.000313 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004819, test:0.000297 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004649, test:0.000313 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004829, test:0.000289 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004737, test:0.000312 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005906, test:0.000302 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005253, test:0.000298 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004966, test:0.000325 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005899, test:0.000354 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004882, test:0.000291 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004559, test:0.000349 | lr:0.000100\n",
      "Mean absolute error:  1.7611237396869004\n",
      "Root mean squared error:  5.830823156854557\n",
      "Epoch[1/100] | loss train:0.065085, test:0.000633 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011228, test:0.000521 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011365, test:0.012296 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013091, test:0.000304 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009355, test:0.002550 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009524, test:0.006191 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007680, test:0.000307 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009774, test:0.001323 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007694, test:0.000325 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007287, test:0.002567 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008038, test:0.001552 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009469, test:0.000970 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.012047, test:0.001775 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008942, test:0.001013 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007779, test:0.000521 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009831, test:0.000519 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007405, test:0.000411 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007653, test:0.000708 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009273, test:0.000580 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007527, test:0.000601 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008247, test:0.001384 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007279, test:0.000710 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006988, test:0.002477 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007730, test:0.000736 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007228, test:0.000851 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006746, test:0.000364 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007119, test:0.000392 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007830, test:0.002426 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007897, test:0.001395 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006890, test:0.000779 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007469, test:0.001116 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008972, test:0.000350 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008064, test:0.001556 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006748, test:0.000297 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006129, test:0.000427 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006830, test:0.000405 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006348, test:0.000401 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008331, test:0.001907 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007034, test:0.000289 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.005760, test:0.000374 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006342, test:0.000498 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005260, test:0.000372 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005461, test:0.000372 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005287, test:0.000411 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006686, test:0.000433 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005325, test:0.000395 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004917, test:0.000322 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005948, test:0.000286 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005224, test:0.000286 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004895, test:0.000593 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005311, test:0.000340 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006342, test:0.000317 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004877, test:0.000270 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004945, test:0.000443 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006250, test:0.000284 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005625, test:0.000345 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004937, test:0.000301 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004878, test:0.000283 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005313, test:0.000456 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006441, test:0.000295 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004627, test:0.000290 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004847, test:0.000298 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006453, test:0.000301 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006859, test:0.000286 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004681, test:0.000448 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004887, test:0.000361 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006761, test:0.000442 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005333, test:0.000333 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005566, test:0.000290 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005345, test:0.000348 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005091, test:0.000455 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005922, test:0.000375 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004665, test:0.000327 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005321, test:0.000300 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004952, test:0.000317 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005037, test:0.000307 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004755, test:0.000294 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.008767, test:0.000373 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005240, test:0.000336 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005049, test:0.000404 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004814, test:0.000284 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005675, test:0.000280 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005497, test:0.000277 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004738, test:0.000259 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004621, test:0.000267 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.006015, test:0.000291 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005126, test:0.000288 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004850, test:0.000263 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004800, test:0.000274 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005077, test:0.000266 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006115, test:0.000298 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004824, test:0.000284 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004767, test:0.000280 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005899, test:0.000271 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004811, test:0.000277 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005340, test:0.000271 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005103, test:0.000264 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004530, test:0.000259 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[99/100] | loss train:0.004455, test:0.000275 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004791, test:0.000298 | lr:0.000100\n",
      "Mean absolute error:  1.650408658156605\n",
      "Root mean squared error:  5.7628944670178\n",
      "Epoch[1/100] | loss train:0.049659, test:0.001219 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012298, test:0.004004 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011636, test:0.000517 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010842, test:0.003584 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011391, test:0.002777 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008594, test:0.000325 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007952, test:0.000832 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.018174, test:0.000802 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009095, test:0.000404 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.013629, test:0.000625 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008118, test:0.000438 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008247, test:0.000444 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008064, test:0.001073 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007037, test:0.000394 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.024305, test:0.000539 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.021762, test:0.000825 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008767, test:0.001049 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006929, test:0.001649 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006717, test:0.005079 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007787, test:0.001244 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.011160, test:0.001181 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006419, test:0.000504 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006853, test:0.005609 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.010667, test:0.000404 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008451, test:0.000498 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008743, test:0.000444 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007995, test:0.000832 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006761, test:0.001113 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007048, test:0.003932 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007338, test:0.000636 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007111, test:0.000460 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008847, test:0.001068 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008331, test:0.001419 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007609, test:0.001508 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007570, test:0.000710 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006295, test:0.000355 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007848, test:0.000764 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006968, test:0.000442 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006287, test:0.000532 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006754, test:0.000632 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005310, test:0.000439 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005154, test:0.000442 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005736, test:0.000763 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005017, test:0.000603 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005694, test:0.000400 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005006, test:0.000468 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005941, test:0.000552 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004647, test:0.000349 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005865, test:0.000404 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004969, test:0.000405 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005142, test:0.000391 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004950, test:0.000613 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004944, test:0.000401 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004867, test:0.000339 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005744, test:0.000367 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005671, test:0.000358 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004930, test:0.000327 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005116, test:0.000535 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005237, test:0.000315 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005188, test:0.000355 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005354, test:0.000550 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005437, test:0.000392 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005591, test:0.000333 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006977, test:0.000331 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005793, test:0.000327 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005101, test:0.000335 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006033, test:0.000303 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004950, test:0.000382 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004933, test:0.000334 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005406, test:0.000329 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005031, test:0.000298 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005433, test:0.000435 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004831, test:0.000341 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005168, test:0.000362 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005379, test:0.000297 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005449, test:0.000398 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005510, test:0.000317 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004641, test:0.000321 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004915, test:0.000696 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.007039, test:0.000319 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004745, test:0.000370 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004733, test:0.000319 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004557, test:0.000345 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004796, test:0.000297 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005535, test:0.000338 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004712, test:0.000323 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004613, test:0.000358 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005308, test:0.000333 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006859, test:0.000324 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005541, test:0.000315 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005401, test:0.000321 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005039, test:0.000320 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004738, test:0.000310 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005388, test:0.000321 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005067, test:0.000307 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005111, test:0.000305 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005761, test:0.000330 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004929, test:0.000320 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005102, test:0.000318 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004938, test:0.000315 | lr:0.000100\n",
      "Mean absolute error:  1.675089499048663\n",
      "Root mean squared error:  5.785155419527821\n",
      "Epoch[1/100] | loss train:0.055426, test:0.000396 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.016199, test:0.000593 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011893, test:0.000683 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009537, test:0.011563 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011174, test:0.001071 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010761, test:0.000326 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010683, test:0.000391 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008297, test:0.003377 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.022363, test:0.006301 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009384, test:0.002139 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008701, test:0.000315 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008943, test:0.004360 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010591, test:0.002993 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008506, test:0.003047 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009493, test:0.006164 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010803, test:0.000836 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008745, test:0.004892 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008719, test:0.000385 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007443, test:0.000439 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008207, test:0.000529 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007268, test:0.000373 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008611, test:0.002323 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[23/100] | loss train:0.008291, test:0.000677 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007476, test:0.000608 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008451, test:0.000537 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007697, test:0.001085 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008487, test:0.000457 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007062, test:0.001463 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007947, test:0.000754 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006973, test:0.000530 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007792, test:0.000373 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007457, test:0.001680 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009182, test:0.002543 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007604, test:0.002669 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008997, test:0.000630 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007480, test:0.000620 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008008, test:0.000394 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007480, test:0.002265 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007447, test:0.000857 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007176, test:0.000439 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007444, test:0.000319 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005659, test:0.000366 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005367, test:0.000353 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005417, test:0.000423 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005160, test:0.000537 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.007768, test:0.000641 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005999, test:0.000369 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005294, test:0.000455 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005730, test:0.000467 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005065, test:0.000378 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005284, test:0.000498 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006346, test:0.000368 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005640, test:0.000406 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.008339, test:0.000446 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005312, test:0.000437 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005882, test:0.000382 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005133, test:0.000333 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.011383, test:0.000539 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005910, test:0.000298 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005307, test:0.000396 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005559, test:0.000326 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.007921, test:0.000316 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005234, test:0.000346 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004846, test:0.000362 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005240, test:0.000388 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006012, test:0.000772 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005696, test:0.000392 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.007910, test:0.000619 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005528, test:0.000380 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005156, test:0.000513 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004908, test:0.000338 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005841, test:0.000505 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005414, test:0.000343 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005840, test:0.000330 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005297, test:0.000370 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005068, test:0.000298 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004909, test:0.000371 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005811, test:0.000501 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.006119, test:0.000503 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005660, test:0.000403 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005241, test:0.000317 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005168, test:0.000336 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005776, test:0.000328 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005163, test:0.000331 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005800, test:0.000349 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005362, test:0.000321 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004880, test:0.000311 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005164, test:0.000338 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005183, test:0.000307 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005103, test:0.000324 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005193, test:0.000306 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004813, test:0.000302 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.007722, test:0.000331 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005443, test:0.000324 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005037, test:0.000315 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.008635, test:0.000310 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005363, test:0.000320 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004933, test:0.000320 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004895, test:0.000345 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006102, test:0.000343 | lr:0.000100\n",
      "Mean absolute error:  1.6893879381488965\n",
      "Root mean squared error:  5.800297354591963\n",
      "Epoch[1/100] | loss train:0.070940, test:0.003284 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013193, test:0.000879 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010428, test:0.007584 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011326, test:0.010555 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011336, test:0.002251 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012289, test:0.001170 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011657, test:0.000374 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008468, test:0.003438 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010566, test:0.000381 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008404, test:0.000356 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008945, test:0.000352 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008227, test:0.000772 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008638, test:0.005586 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010126, test:0.001008 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009838, test:0.000662 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008969, test:0.001202 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007403, test:0.000649 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007562, test:0.000760 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009780, test:0.000552 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008754, test:0.000370 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007845, test:0.001314 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008213, test:0.001021 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007668, test:0.001778 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007900, test:0.000940 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007726, test:0.000577 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007884, test:0.000365 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.012089, test:0.001058 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.010276, test:0.000439 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008221, test:0.000584 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007467, test:0.000356 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008336, test:0.000873 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006551, test:0.002806 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008029, test:0.000468 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007737, test:0.000345 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007368, test:0.000458 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.011195, test:0.000443 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.010680, test:0.000339 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007349, test:0.000464 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.010676, test:0.001544 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007854, test:0.000502 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007533, test:0.000360 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005797, test:0.000341 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005500, test:0.000355 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.011229, test:0.000358 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005479, test:0.000366 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005503, test:0.000401 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006049, test:0.000411 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[48/100] | loss train:0.008430, test:0.000478 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005305, test:0.000293 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006391, test:0.000325 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005372, test:0.000326 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005995, test:0.000432 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005478, test:0.000307 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005229, test:0.000407 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005180, test:0.000325 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006371, test:0.000301 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.007335, test:0.000363 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005427, test:0.000346 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005338, test:0.000283 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005365, test:0.000298 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005425, test:0.000343 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005430, test:0.000378 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005121, test:0.000286 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005450, test:0.000297 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006129, test:0.000295 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005839, test:0.000283 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005347, test:0.000750 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005173, test:0.000493 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005246, test:0.000301 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005233, test:0.000329 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006157, test:0.000401 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005322, test:0.000323 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006398, test:0.000594 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005172, test:0.000329 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005480, test:0.000326 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005899, test:0.000489 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005676, test:0.000366 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005327, test:0.000331 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005952, test:0.000318 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005089, test:0.000357 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005055, test:0.000326 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004946, test:0.000315 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005552, test:0.000305 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005331, test:0.000286 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005521, test:0.000294 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005144, test:0.000274 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005074, test:0.000309 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005053, test:0.000294 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005225, test:0.000315 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006433, test:0.000297 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005193, test:0.000306 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005230, test:0.000303 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004988, test:0.000289 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005261, test:0.000277 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005584, test:0.000284 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004934, test:0.000297 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005087, test:0.000293 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005053, test:0.000296 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005800, test:0.000279 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005671, test:0.000305 | lr:0.000100\n",
      "Mean absolute error:  1.6774126874363324\n",
      "Root mean squared error:  5.772119896648536\n",
      "Epoch[1/100] | loss train:0.066674, test:0.001771 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014976, test:0.001561 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010804, test:0.000490 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009868, test:0.000731 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010952, test:0.000353 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009750, test:0.000447 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009405, test:0.003148 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008427, test:0.001727 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008308, test:0.001626 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008258, test:0.000376 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011359, test:0.000307 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007949, test:0.000751 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.011495, test:0.005620 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010127, test:0.000363 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.010135, test:0.006807 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008824, test:0.000357 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.013849, test:0.001702 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.012202, test:0.002523 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.010835, test:0.000423 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009546, test:0.002105 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009182, test:0.000380 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007833, test:0.002958 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.016854, test:0.000677 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009327, test:0.000478 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008582, test:0.001884 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008603, test:0.005077 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009895, test:0.001279 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007756, test:0.002149 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008503, test:0.000452 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008811, test:0.000394 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007388, test:0.001132 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007518, test:0.003004 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.018772, test:0.000710 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009439, test:0.000442 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007675, test:0.001206 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007742, test:0.000743 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006991, test:0.001840 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.011031, test:0.000702 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.011542, test:0.001095 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008898, test:0.002721 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006364, test:0.000425 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005710, test:0.000459 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.010772, test:0.000436 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.007306, test:0.000399 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005996, test:0.000433 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006272, test:0.000457 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006536, test:0.000447 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005993, test:0.000557 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005503, test:0.000717 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.013380, test:0.000502 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006978, test:0.000415 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006311, test:0.000424 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006219, test:0.000417 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006460, test:0.000860 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006420, test:0.000386 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006352, test:0.000378 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006074, test:0.000394 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.007077, test:0.000359 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006162, test:0.000373 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005535, test:0.000351 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006106, test:0.000775 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005975, test:0.000635 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.009579, test:0.000819 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006147, test:0.000565 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006022, test:0.000388 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005889, test:0.000414 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005931, test:0.000430 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006128, test:0.000445 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006030, test:0.000646 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005890, test:0.000485 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005902, test:0.000366 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005446, test:0.000334 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[73/100] | loss train:0.006045, test:0.000982 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005945, test:0.000374 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.007565, test:0.000365 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005973, test:0.000432 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006108, test:0.000375 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005168, test:0.000380 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.007144, test:0.000355 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006255, test:0.000343 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005397, test:0.000343 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005373, test:0.000367 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005700, test:0.000346 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005801, test:0.000373 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005536, test:0.000342 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005561, test:0.000370 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005960, test:0.000345 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005426, test:0.000364 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005835, test:0.000357 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005670, test:0.000346 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005911, test:0.000334 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005663, test:0.000341 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.009775, test:0.000348 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.007864, test:0.000340 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.006336, test:0.000350 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005624, test:0.000369 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005149, test:0.000382 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005770, test:0.000349 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005714, test:0.000354 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005455, test:0.000346 | lr:0.000100\n",
      "Mean absolute error:  1.7741065551894957\n",
      "Root mean squared error:  5.828006323757676\n",
      "Epoch[1/100] | loss train:0.054076, test:0.001046 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010769, test:0.002147 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009668, test:0.000361 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009871, test:0.000388 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007543, test:0.007988 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008179, test:0.001067 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008242, test:0.001554 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007619, test:0.000330 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007942, test:0.000334 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008652, test:0.002061 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007357, test:0.003072 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007451, test:0.000695 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009153, test:0.000984 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006857, test:0.000479 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007089, test:0.000406 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.011096, test:0.001486 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008099, test:0.000459 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006776, test:0.000496 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006722, test:0.000488 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007762, test:0.000393 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006460, test:0.000721 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008236, test:0.000419 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008004, test:0.000520 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008894, test:0.000989 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008434, test:0.001148 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007380, test:0.000393 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007504, test:0.000513 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007157, test:0.001457 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007825, test:0.001089 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007224, test:0.000393 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006719, test:0.000406 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006356, test:0.000497 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007465, test:0.003928 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009225, test:0.002491 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008297, test:0.001786 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006226, test:0.000801 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007496, test:0.000441 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008458, test:0.000520 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.022519, test:0.002855 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007923, test:0.000884 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.008777, test:0.000322 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005725, test:0.000327 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007600, test:0.000331 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005496, test:0.000345 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005356, test:0.000468 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006914, test:0.000499 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006155, test:0.000323 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005489, test:0.000302 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004684, test:0.000357 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005069, test:0.000329 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005308, test:0.000408 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004888, test:0.000358 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004849, test:0.000355 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005680, test:0.000371 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004903, test:0.000344 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005355, test:0.000418 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005179, test:0.000314 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005004, test:0.000392 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004754, test:0.000406 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005169, test:0.000318 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.008068, test:0.000355 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005489, test:0.000307 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005113, test:0.000437 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004875, test:0.000301 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006087, test:0.000298 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006762, test:0.000341 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005061, test:0.000314 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.007547, test:0.000312 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005759, test:0.000358 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005186, test:0.000324 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005189, test:0.000354 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005547, test:0.000296 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005103, test:0.000315 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004893, test:0.000311 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006014, test:0.000415 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004889, test:0.000378 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005455, test:0.000408 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006035, test:0.000368 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004606, test:0.000437 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.007644, test:0.000346 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005230, test:0.000306 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005371, test:0.000287 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004763, test:0.000321 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.007670, test:0.000301 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005698, test:0.000333 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005000, test:0.000312 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.007356, test:0.000322 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005538, test:0.000313 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004823, test:0.000311 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005400, test:0.000298 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005598, test:0.000284 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005034, test:0.000330 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005459, test:0.000312 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.014340, test:0.000304 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004555, test:0.000295 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004799, test:0.000335 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004858, test:0.000313 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[98/100] | loss train:0.004913, test:0.000341 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005098, test:0.000290 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005469, test:0.000372 | lr:0.000100\n",
      "Mean absolute error:  1.8113014155853298\n",
      "Root mean squared error:  5.877807638952578\n",
      "Epoch[1/100] | loss train:0.052776, test:0.001405 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011646, test:0.002237 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009217, test:0.008009 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009431, test:0.001391 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008100, test:0.003862 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009462, test:0.001428 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007749, test:0.002314 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008368, test:0.005028 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008710, test:0.000474 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008414, test:0.001658 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010114, test:0.004345 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009550, test:0.000864 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007452, test:0.000382 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008674, test:0.001731 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007718, test:0.000444 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007682, test:0.000329 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007410, test:0.001462 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006966, test:0.004742 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007991, test:0.001416 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008572, test:0.002060 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007795, test:0.000345 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006609, test:0.000379 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008091, test:0.001295 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006871, test:0.001702 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010335, test:0.000740 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007279, test:0.000502 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006305, test:0.000355 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008536, test:0.000402 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007107, test:0.000706 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007963, test:0.001336 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007348, test:0.004961 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009029, test:0.006294 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009352, test:0.000685 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007249, test:0.001101 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007165, test:0.003592 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.012355, test:0.001092 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007145, test:0.000357 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008545, test:0.002013 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007463, test:0.000728 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006738, test:0.000333 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006068, test:0.000377 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.012166, test:0.000438 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005062, test:0.000480 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004861, test:0.000369 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004946, test:0.000394 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004997, test:0.000435 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005043, test:0.000340 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005410, test:0.000343 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004817, test:0.000490 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005903, test:0.000317 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005022, test:0.000334 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005769, test:0.000547 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005229, test:0.000363 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005003, test:0.000336 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005127, test:0.000521 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004938, test:0.000446 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005435, test:0.000395 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004916, test:0.000315 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005059, test:0.000323 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004909, test:0.000303 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005445, test:0.000344 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005489, test:0.000438 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005388, test:0.000300 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005208, test:0.000333 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.009386, test:0.000332 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006282, test:0.000421 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004941, test:0.000425 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005054, test:0.000301 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005149, test:0.000336 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005521, test:0.000334 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.007585, test:0.000570 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004807, test:0.000390 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005185, test:0.000432 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004752, test:0.000311 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004810, test:0.000613 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005706, test:0.000269 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005512, test:0.000420 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006783, test:0.000425 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005878, test:0.000509 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005148, test:0.000387 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004866, test:0.000287 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004569, test:0.000279 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004823, test:0.000301 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004639, test:0.000292 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005122, test:0.000289 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004694, test:0.000279 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005156, test:0.000315 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006039, test:0.000300 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005691, test:0.000296 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004713, test:0.000311 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004919, test:0.000317 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004855, test:0.000287 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005144, test:0.000302 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004751, test:0.000302 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004958, test:0.000298 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005521, test:0.000316 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005934, test:0.000302 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004649, test:0.000303 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005095, test:0.000306 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005113, test:0.000285 | lr:0.000100\n",
      "Mean absolute error:  1.6551540994721736\n",
      "Root mean squared error:  5.768201022759467\n",
      "Epoch[1/100] | loss train:0.047665, test:0.001789 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011041, test:0.001225 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009532, test:0.002364 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009778, test:0.005851 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009393, test:0.000604 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007396, test:0.000332 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.016524, test:0.005430 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.014740, test:0.005293 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010564, test:0.002707 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011149, test:0.000379 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007653, test:0.001382 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007237, test:0.001167 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009667, test:0.006248 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.015687, test:0.000680 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009670, test:0.001635 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010596, test:0.001020 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.013189, test:0.000933 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008107, test:0.000872 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009564, test:0.007640 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007712, test:0.000430 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007030, test:0.000763 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/100] | loss train:0.010303, test:0.007436 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008720, test:0.001144 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009201, test:0.000451 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008869, test:0.000620 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007472, test:0.001492 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008333, test:0.000435 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007578, test:0.000421 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006780, test:0.000429 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007220, test:0.001524 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007660, test:0.000715 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007313, test:0.000668 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007330, test:0.000378 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008450, test:0.000751 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006480, test:0.000862 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007370, test:0.000650 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007329, test:0.000465 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006603, test:0.000481 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007719, test:0.000509 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007964, test:0.000461 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005649, test:0.000550 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005478, test:0.000373 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005172, test:0.000426 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005429, test:0.000489 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005594, test:0.000411 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005740, test:0.000382 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005191, test:0.000356 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005400, test:0.000347 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005015, test:0.000343 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005185, test:0.000360 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006288, test:0.000373 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005166, test:0.000366 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005847, test:0.000385 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005435, test:0.000353 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005027, test:0.000432 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005198, test:0.000360 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005585, test:0.000385 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005171, test:0.000404 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006039, test:0.000315 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005224, test:0.000347 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005159, test:0.000383 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005391, test:0.000411 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006024, test:0.000343 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005958, test:0.000327 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004945, test:0.000332 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005255, test:0.000321 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005191, test:0.000432 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006010, test:0.000379 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005337, test:0.000400 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004953, test:0.000364 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004988, test:0.000516 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005065, test:0.000484 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.007825, test:0.000628 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005661, test:0.000338 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005848, test:0.000454 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005705, test:0.000494 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005031, test:0.000398 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005712, test:0.000307 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005669, test:0.000346 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005569, test:0.000314 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004726, test:0.000308 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.008694, test:0.000319 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006062, test:0.000320 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005185, test:0.000349 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.006088, test:0.000308 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005052, test:0.000312 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005273, test:0.000293 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005804, test:0.000329 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004903, test:0.000303 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005048, test:0.000296 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005419, test:0.000365 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.006756, test:0.000315 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004889, test:0.000321 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.006736, test:0.000355 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005361, test:0.000336 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006309, test:0.000336 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004560, test:0.000300 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005399, test:0.000332 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005086, test:0.000316 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005997, test:0.000362 | lr:0.000100\n",
      "Mean absolute error:  1.840857961291381\n",
      "Root mean squared error:  5.882570607098315\n",
      "Epoch[1/100] | loss train:0.066933, test:0.005140 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013636, test:0.001534 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010836, test:0.001623 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009312, test:0.000952 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010455, test:0.000382 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008600, test:0.002191 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009626, test:0.005317 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009960, test:0.000413 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008593, test:0.002108 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009200, test:0.001551 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009807, test:0.001096 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008444, test:0.001497 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008627, test:0.000970 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008955, test:0.003433 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007597, test:0.000792 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008171, test:0.000517 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008518, test:0.004716 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009475, test:0.000498 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007369, test:0.002877 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008474, test:0.000537 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007442, test:0.002338 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009865, test:0.000963 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008379, test:0.000404 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008728, test:0.001063 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.012696, test:0.001380 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008972, test:0.000549 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007005, test:0.000634 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007488, test:0.000569 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006689, test:0.000415 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006884, test:0.000632 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007236, test:0.001663 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007513, test:0.000728 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008526, test:0.000804 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007923, test:0.000365 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.012343, test:0.002160 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008901, test:0.000443 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006988, test:0.000778 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007441, test:0.000707 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007467, test:0.000344 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008252, test:0.001531 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005638, test:0.000412 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006911, test:0.000392 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.010574, test:0.000388 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005687, test:0.000404 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005333, test:0.000512 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005655, test:0.000380 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[47/100] | loss train:0.006762, test:0.000866 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005311, test:0.000358 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005119, test:0.000311 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006526, test:0.000442 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005315, test:0.000570 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006265, test:0.000647 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006058, test:0.000750 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005375, test:0.000437 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005212, test:0.000391 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006022, test:0.000466 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005341, test:0.000344 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005394, test:0.000410 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006620, test:0.000360 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005248, test:0.000325 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004775, test:0.000414 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005129, test:0.000372 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005670, test:0.000326 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005268, test:0.000371 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005542, test:0.000360 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005283, test:0.000461 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005964, test:0.000355 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005146, test:0.000601 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.011056, test:0.000334 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006020, test:0.000369 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005064, test:0.000745 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005059, test:0.000439 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005139, test:0.000303 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005101, test:0.000334 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005878, test:0.000395 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005116, test:0.000433 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005578, test:0.000460 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006843, test:0.000324 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.007821, test:0.000556 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005526, test:0.000446 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006136, test:0.000328 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005173, test:0.000340 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004897, test:0.000320 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005360, test:0.000314 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.008442, test:0.000329 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004962, test:0.000289 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005010, test:0.000297 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004674, test:0.000338 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.007241, test:0.000335 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004685, test:0.000317 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005142, test:0.000309 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004982, test:0.000301 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005637, test:0.000401 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005266, test:0.000328 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004970, test:0.000330 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004843, test:0.000297 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004645, test:0.000328 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005219, test:0.000307 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005746, test:0.000303 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005217, test:0.000322 | lr:0.000100\n",
      "Mean absolute error:  1.696010596983547\n",
      "Root mean squared error:  5.811466872238447\n",
      "Epoch[1/100] | loss train:0.062108, test:0.002363 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010713, test:0.000404 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010708, test:0.000890 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008804, test:0.003064 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009313, test:0.000622 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009630, test:0.001017 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.015988, test:0.000481 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009994, test:0.003206 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008571, test:0.001983 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008811, test:0.000348 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007527, test:0.000580 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007591, test:0.001510 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007892, test:0.000406 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007654, test:0.000868 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006997, test:0.000535 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009894, test:0.000839 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007336, test:0.003928 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007778, test:0.000476 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006653, test:0.010921 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007200, test:0.000392 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.010089, test:0.000370 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007848, test:0.000458 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006924, test:0.000962 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007698, test:0.000803 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008480, test:0.004765 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008013, test:0.000727 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008912, test:0.001262 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006826, test:0.000396 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007174, test:0.001716 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007160, test:0.002885 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008592, test:0.002384 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007545, test:0.000847 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006506, test:0.000346 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007544, test:0.000902 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008650, test:0.000452 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008521, test:0.000324 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007576, test:0.000401 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006875, test:0.000368 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007144, test:0.004794 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006796, test:0.002667 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006365, test:0.000492 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005716, test:0.000325 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.008085, test:0.000342 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005363, test:0.000322 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005553, test:0.000408 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005875, test:0.000389 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006492, test:0.000526 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005235, test:0.000320 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005135, test:0.000305 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005820, test:0.000294 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005348, test:0.000370 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005247, test:0.000489 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005237, test:0.000490 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005208, test:0.000301 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005015, test:0.000430 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005734, test:0.000286 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005673, test:0.000333 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005340, test:0.000496 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006030, test:0.000323 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005560, test:0.000273 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005113, test:0.000429 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005936, test:0.000312 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005109, test:0.000324 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005342, test:0.000300 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005408, test:0.000292 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005290, test:0.000312 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005915, test:0.000386 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005131, test:0.000358 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005216, test:0.000296 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005240, test:0.000313 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005008, test:0.000322 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[72/100] | loss train:0.005461, test:0.000276 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005592, test:0.000352 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005435, test:0.000416 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005130, test:0.000312 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005051, test:0.000307 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005131, test:0.000492 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004803, test:0.000275 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005199, test:0.000433 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005543, test:0.000381 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.009491, test:0.000288 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005079, test:0.000300 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004794, test:0.000291 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005283, test:0.000273 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004954, test:0.000261 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004983, test:0.000292 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005086, test:0.000276 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005363, test:0.000289 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004715, test:0.000286 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005052, test:0.000304 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005004, test:0.000295 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004956, test:0.000305 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006089, test:0.000349 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.007615, test:0.000277 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005490, test:0.000293 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005638, test:0.000280 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005005, test:0.000288 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004792, test:0.000295 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.008374, test:0.000258 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004989, test:0.000278 | lr:0.000100\n",
      "Mean absolute error:  1.6448836183205853\n",
      "Root mean squared error:  5.769116763433851\n",
      "Epoch[1/100] | loss train:0.068352, test:0.001372 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012312, test:0.004980 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009395, test:0.000320 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008901, test:0.010012 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011752, test:0.000812 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007431, test:0.001535 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.013671, test:0.016665 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011121, test:0.000335 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008025, test:0.000812 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008893, test:0.001095 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008225, test:0.000367 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008007, test:0.000479 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008470, test:0.008172 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.011729, test:0.000975 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008470, test:0.001870 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006766, test:0.001514 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007922, test:0.002864 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008396, test:0.000376 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007669, test:0.000387 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008151, test:0.005924 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007623, test:0.001262 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007976, test:0.002210 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010302, test:0.001168 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008117, test:0.000484 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008064, test:0.001259 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007081, test:0.001318 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007613, test:0.000369 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007385, test:0.000662 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007623, test:0.000769 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006283, test:0.003673 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006842, test:0.002938 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007119, test:0.001349 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.012627, test:0.001015 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007723, test:0.000377 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006975, test:0.000474 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008977, test:0.002242 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007211, test:0.000403 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007039, test:0.000664 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007441, test:0.003023 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008155, test:0.000871 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.019144, test:0.000833 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005962, test:0.000450 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005771, test:0.000401 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005696, test:0.000365 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005372, test:0.000322 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004996, test:0.000397 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.008128, test:0.000377 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005494, test:0.000448 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005677, test:0.000313 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004817, test:0.000413 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005540, test:0.000369 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005494, test:0.000381 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005382, test:0.000328 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004902, test:0.000361 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005675, test:0.000310 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006125, test:0.000314 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005844, test:0.000456 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005082, test:0.000439 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005425, test:0.000306 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005632, test:0.000447 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005605, test:0.000374 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005336, test:0.000377 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005138, test:0.000325 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006388, test:0.000304 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005731, test:0.000310 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005939, test:0.000405 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005591, test:0.000301 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005877, test:0.000346 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006616, test:0.000352 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004824, test:0.000282 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005496, test:0.000344 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005222, test:0.000914 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004984, test:0.000421 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.007245, test:0.000328 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005579, test:0.000339 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005690, test:0.000300 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005219, test:0.000296 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005269, test:0.000362 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.006357, test:0.000279 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005278, test:0.000365 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005905, test:0.000294 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005473, test:0.000301 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005051, test:0.000277 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005177, test:0.000286 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.011736, test:0.000310 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005450, test:0.000297 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005012, test:0.000281 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004867, test:0.000291 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005280, test:0.000325 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006080, test:0.000277 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005752, test:0.000323 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005191, test:0.000305 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005453, test:0.000292 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005799, test:0.000329 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004819, test:0.000303 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004650, test:0.000286 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[97/100] | loss train:0.005389, test:0.000285 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004918, test:0.000291 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005362, test:0.000331 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004934, test:0.000283 | lr:0.000100\n",
      "Mean absolute error:  1.7200626767071105\n",
      "Root mean squared error:  5.7917138241789035\n",
      "Epoch[1/100] | loss train:0.049379, test:0.000601 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013060, test:0.000348 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010625, test:0.001311 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009999, test:0.000915 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009815, test:0.000830 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009971, test:0.003765 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007406, test:0.001707 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009082, test:0.000349 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007707, test:0.000961 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007973, test:0.000721 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009430, test:0.000662 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008003, test:0.000480 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008137, test:0.000274 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006808, test:0.001932 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007074, test:0.002546 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008819, test:0.003768 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007486, test:0.001656 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006484, test:0.000604 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007888, test:0.000566 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007235, test:0.001526 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007928, test:0.000292 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007079, test:0.000402 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007507, test:0.000627 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007707, test:0.000576 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007004, test:0.000691 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007034, test:0.002816 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007361, test:0.003012 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006615, test:0.000302 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007060, test:0.002959 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007218, test:0.000840 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007458, test:0.000935 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007345, test:0.000344 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007389, test:0.001626 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007588, test:0.000595 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.019733, test:0.000375 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008674, test:0.000351 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006232, test:0.000303 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006482, test:0.001405 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006359, test:0.000583 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006832, test:0.002220 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005923, test:0.000338 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006386, test:0.000339 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006523, test:0.000306 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005365, test:0.000413 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005305, test:0.000309 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.007895, test:0.000315 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005030, test:0.000338 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005585, test:0.000319 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006450, test:0.000320 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005369, test:0.000392 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005623, test:0.000338 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005608, test:0.000288 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005251, test:0.000366 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005501, test:0.000287 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005451, test:0.000292 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005501, test:0.000289 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005292, test:0.000425 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.010982, test:0.000307 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004856, test:0.000294 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005067, test:0.000276 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005603, test:0.000305 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005862, test:0.000424 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006845, test:0.000306 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005434, test:0.000291 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005332, test:0.000401 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005374, test:0.000284 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004581, test:0.000323 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004926, test:0.000313 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005632, test:0.000328 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005080, test:0.000316 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006639, test:0.000347 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006553, test:0.000298 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006496, test:0.000387 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005956, test:0.000474 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005327, test:0.000334 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006947, test:0.000341 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005537, test:0.000285 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004725, test:0.000342 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004507, test:0.000357 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006071, test:0.000512 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004775, test:0.000285 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006175, test:0.000277 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004951, test:0.000289 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004944, test:0.000287 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005193, test:0.000295 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004596, test:0.000282 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005188, test:0.000359 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005802, test:0.000294 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005146, test:0.000297 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004669, test:0.000306 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004896, test:0.000312 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.009898, test:0.000299 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004931, test:0.000301 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.010456, test:0.000287 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005071, test:0.000295 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.008003, test:0.000310 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004396, test:0.000283 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004993, test:0.000284 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004618, test:0.000305 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006158, test:0.000279 | lr:0.000100\n",
      "Mean absolute error:  1.6859045629245795\n",
      "Root mean squared error:  5.776998267906706\n",
      "Epoch[1/100] | loss train:0.050638, test:0.000587 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012707, test:0.001076 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010904, test:0.000668 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009808, test:0.004048 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008671, test:0.000296 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009935, test:0.000423 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010223, test:0.007118 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009575, test:0.001351 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007986, test:0.000476 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008013, test:0.000419 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007078, test:0.000525 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008598, test:0.000498 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008309, test:0.002219 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007697, test:0.000421 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008493, test:0.002214 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009170, test:0.003068 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008642, test:0.001861 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010435, test:0.000734 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007576, test:0.002727 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007579, test:0.000497 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21/100] | loss train:0.007261, test:0.000775 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008530, test:0.000489 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006414, test:0.001720 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.010266, test:0.000356 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008312, test:0.003344 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007710, test:0.000893 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007929, test:0.001808 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007602, test:0.001742 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007339, test:0.000288 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006342, test:0.000599 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007955, test:0.001206 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006415, test:0.000539 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007578, test:0.000482 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.013886, test:0.002121 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006902, test:0.000537 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006993, test:0.000335 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006497, test:0.000588 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006939, test:0.000928 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007110, test:0.000418 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006600, test:0.000452 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005689, test:0.000378 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005127, test:0.000366 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005369, test:0.000329 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005435, test:0.000351 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005067, test:0.000592 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005408, test:0.000311 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005118, test:0.000311 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005152, test:0.000325 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005350, test:0.000292 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004702, test:0.000284 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005938, test:0.000314 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005174, test:0.000355 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004967, test:0.000367 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004841, test:0.000346 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005159, test:0.000327 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004718, test:0.000311 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005034, test:0.000349 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005057, test:0.000311 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005471, test:0.000337 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005388, test:0.000338 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005088, test:0.000298 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005392, test:0.000295 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005695, test:0.000290 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004959, test:0.000368 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004604, test:0.000545 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004787, test:0.000304 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005218, test:0.000305 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005542, test:0.000291 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004619, test:0.000436 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005209, test:0.000286 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006961, test:0.000374 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005281, test:0.000315 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004906, test:0.000290 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005138, test:0.000283 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004900, test:0.000304 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005064, test:0.000304 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005780, test:0.000269 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006675, test:0.000316 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005507, test:0.000293 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004900, test:0.000290 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004644, test:0.000284 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004555, test:0.000316 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004838, test:0.000304 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005124, test:0.000281 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004517, test:0.000318 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004790, test:0.000292 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005903, test:0.000307 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004809, test:0.000320 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004884, test:0.000283 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005055, test:0.000327 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.008710, test:0.000276 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005081, test:0.000279 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005299, test:0.000332 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004608, test:0.000263 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005264, test:0.000327 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004717, test:0.000266 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004997, test:0.000312 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005119, test:0.000284 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005178, test:0.000267 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006288, test:0.000277 | lr:0.000100\n",
      "Mean absolute error:  1.7434460165209569\n",
      "Root mean squared error:  5.776272304873394\n",
      "Epoch[1/100] | loss train:0.062602, test:0.001630 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012613, test:0.001609 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011019, test:0.000760 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.014168, test:0.000764 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009821, test:0.001344 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010012, test:0.000390 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009291, test:0.000771 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008455, test:0.000574 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007672, test:0.003833 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009193, test:0.002848 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007538, test:0.000828 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009665, test:0.000660 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008442, test:0.003422 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007367, test:0.000599 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007478, test:0.001865 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008564, test:0.000383 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007060, test:0.001362 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007839, test:0.000534 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007788, test:0.002641 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007148, test:0.001145 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009935, test:0.004252 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006719, test:0.001320 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006964, test:0.000752 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007537, test:0.000539 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010898, test:0.000455 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007390, test:0.002528 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008612, test:0.000624 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007989, test:0.000428 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.012518, test:0.000688 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010152, test:0.000991 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008267, test:0.002629 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008331, test:0.000494 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006626, test:0.000329 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007071, test:0.001235 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007468, test:0.000766 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007117, test:0.002493 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009572, test:0.000804 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006954, test:0.001596 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007159, test:0.001790 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007918, test:0.000787 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005927, test:0.000614 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005961, test:0.000378 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005669, test:0.000539 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006344, test:0.000478 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.011230, test:0.000402 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[46/100] | loss train:0.005344, test:0.000412 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005000, test:0.000479 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004997, test:0.000372 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005204, test:0.000368 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005270, test:0.000381 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004862, test:0.000440 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005370, test:0.000432 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006261, test:0.000394 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005202, test:0.000478 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005636, test:0.000372 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006822, test:0.000395 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004835, test:0.000364 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004854, test:0.000378 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005451, test:0.000395 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005256, test:0.000338 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005352, test:0.000456 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.007387, test:0.000433 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005624, test:0.000619 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005095, test:0.000357 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005389, test:0.000372 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005106, test:0.000333 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004734, test:0.000491 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006170, test:0.000626 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005413, test:0.000343 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.007169, test:0.000371 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005679, test:0.000529 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004882, test:0.000315 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005105, test:0.000454 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005183, test:0.000503 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004833, test:0.000344 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005470, test:0.000456 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005255, test:0.000366 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005157, test:0.000317 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005835, test:0.000352 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005024, test:0.000348 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004613, test:0.000319 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004880, test:0.000333 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005026, test:0.000320 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004930, test:0.000309 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005105, test:0.000305 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004778, test:0.000328 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005317, test:0.000348 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006066, test:0.000303 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004775, test:0.000369 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005490, test:0.000308 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005118, test:0.000316 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005392, test:0.000344 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005351, test:0.000328 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004722, test:0.000317 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004687, test:0.000301 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005157, test:0.000338 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004806, test:0.000352 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005039, test:0.000363 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005011, test:0.000311 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004928, test:0.000308 | lr:0.000100\n",
      "Mean absolute error:  1.757943380058231\n",
      "Root mean squared error:  5.8011193250392985\n",
      "Epoch[1/100] | loss train:0.069262, test:0.001649 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012710, test:0.001034 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010462, test:0.014980 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013467, test:0.000481 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009966, test:0.002576 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010016, test:0.000352 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009949, test:0.004894 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008966, test:0.000316 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007420, test:0.008984 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009012, test:0.000383 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008530, test:0.001555 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.018876, test:0.005030 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010432, test:0.000383 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008044, test:0.001359 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008470, test:0.000445 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007495, test:0.000680 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009634, test:0.000955 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007313, test:0.000804 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008423, test:0.000605 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006703, test:0.001075 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008366, test:0.000415 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007223, test:0.000992 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009490, test:0.001374 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008197, test:0.002823 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008170, test:0.003751 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007799, test:0.000755 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008346, test:0.000573 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006505, test:0.001098 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007617, test:0.000576 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007283, test:0.000478 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008381, test:0.002033 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007073, test:0.000632 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006852, test:0.000533 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007315, test:0.000767 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007296, test:0.000782 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.019646, test:0.000972 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008652, test:0.000787 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.011828, test:0.003078 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007921, test:0.000550 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007919, test:0.001103 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006627, test:0.000367 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007417, test:0.000416 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006157, test:0.000371 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005975, test:0.000339 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005201, test:0.000320 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005152, test:0.000394 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005741, test:0.000391 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006001, test:0.000385 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005246, test:0.000352 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005646, test:0.000382 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005322, test:0.000423 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005236, test:0.000352 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005351, test:0.000398 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006008, test:0.000410 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005351, test:0.000339 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006002, test:0.000298 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005645, test:0.000590 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005370, test:0.000285 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005439, test:0.000340 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005148, test:0.000366 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.007038, test:0.000365 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005916, test:0.000376 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006620, test:0.000713 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006011, test:0.000366 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005339, test:0.000447 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005217, test:0.000376 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005360, test:0.000344 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005252, test:0.000371 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005286, test:0.000499 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005828, test:0.000328 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[71/100] | loss train:0.005555, test:0.000473 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005902, test:0.000420 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005276, test:0.000542 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005385, test:0.000324 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006730, test:0.000348 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006027, test:0.000330 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.008099, test:0.000396 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.007423, test:0.000488 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.006254, test:0.000410 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006316, test:0.000552 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005015, test:0.000308 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005094, test:0.000318 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005175, test:0.000304 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005528, test:0.000341 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005288, test:0.000297 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005845, test:0.000333 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004958, test:0.000300 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005168, test:0.000305 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006260, test:0.000305 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004740, test:0.000301 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005131, test:0.000298 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.007957, test:0.000333 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005652, test:0.000299 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005297, test:0.000328 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005701, test:0.000302 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005224, test:0.000297 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004967, test:0.000367 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004873, test:0.000299 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005049, test:0.000291 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006521, test:0.000293 | lr:0.000100\n",
      "Mean absolute error:  1.6445380017825746\n",
      "Root mean squared error:  5.760801134137833\n",
      "Epoch[1/100] | loss train:0.052091, test:0.000939 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012448, test:0.006972 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012914, test:0.000389 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009110, test:0.001795 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009718, test:0.001483 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009252, test:0.002345 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008548, test:0.000526 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008921, test:0.003442 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007413, test:0.000349 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009443, test:0.000326 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008944, test:0.000289 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008110, test:0.000527 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008909, test:0.001070 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008927, test:0.000647 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007593, test:0.004278 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008408, test:0.000844 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008690, test:0.000701 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006839, test:0.000438 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008839, test:0.000387 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007817, test:0.000427 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006718, test:0.000408 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009439, test:0.003871 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009205, test:0.000405 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006822, test:0.001110 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007791, test:0.000489 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006928, test:0.000426 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006800, test:0.000341 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006651, test:0.000977 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006541, test:0.000509 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.005897, test:0.002038 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.014320, test:0.000345 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007658, test:0.000393 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007910, test:0.000500 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007006, test:0.001200 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006348, test:0.000401 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007658, test:0.003609 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007756, test:0.000399 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006005, test:0.000542 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006803, test:0.001514 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007204, test:0.000528 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.011075, test:0.000356 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005922, test:0.000391 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006273, test:0.000385 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.007090, test:0.000427 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005575, test:0.000457 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005454, test:0.000303 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005680, test:0.000318 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005566, test:0.000323 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005312, test:0.000337 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004750, test:0.000354 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005170, test:0.000331 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005044, test:0.000652 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005431, test:0.000396 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006650, test:0.000320 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005294, test:0.000322 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005155, test:0.000306 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005270, test:0.000345 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.009080, test:0.000349 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005605, test:0.000334 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004627, test:0.000310 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005289, test:0.000326 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004996, test:0.000317 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005071, test:0.000343 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005048, test:0.000296 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004695, test:0.000534 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005405, test:0.000348 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005134, test:0.000308 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004790, test:0.000403 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005749, test:0.000417 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005045, test:0.000313 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006382, test:0.000355 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004819, test:0.000384 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005183, test:0.000382 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005781, test:0.000351 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004971, test:0.000353 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004945, test:0.000704 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005637, test:0.000410 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004838, test:0.000318 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004741, test:0.000355 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005030, test:0.000333 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005195, test:0.000332 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005016, test:0.000320 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006293, test:0.000325 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004700, test:0.000330 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.006160, test:0.000326 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004894, test:0.000330 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005121, test:0.000328 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005053, test:0.000318 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004597, test:0.000328 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004543, test:0.000314 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004901, test:0.000294 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004750, test:0.000344 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005245, test:0.000318 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004425, test:0.000326 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004958, test:0.000298 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[96/100] | loss train:0.005359, test:0.000326 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005141, test:0.000326 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004520, test:0.000337 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004578, test:0.000310 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004982, test:0.000317 | lr:0.000100\n",
      "Mean absolute error:  1.708259413303387\n",
      "Root mean squared error:  5.803713120632178\n",
      "Epoch[1/100] | loss train:0.049183, test:0.001199 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010956, test:0.000467 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010373, test:0.004731 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009631, test:0.005146 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010064, test:0.005607 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008362, test:0.001979 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009340, test:0.002078 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008974, test:0.000710 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.013693, test:0.001732 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010363, test:0.000386 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007417, test:0.002396 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007488, test:0.000349 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009648, test:0.000524 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008463, test:0.001019 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007626, test:0.001172 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007292, test:0.000978 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.015305, test:0.006162 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009252, test:0.000429 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.011830, test:0.000452 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007267, test:0.002985 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007100, test:0.003155 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007354, test:0.003295 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007621, test:0.000578 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007814, test:0.003046 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009518, test:0.001481 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007411, test:0.001695 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006671, test:0.001143 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006912, test:0.001811 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006936, test:0.000527 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006141, test:0.000578 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006813, test:0.001870 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006667, test:0.000792 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008005, test:0.000544 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006766, test:0.000897 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006712, test:0.002869 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006690, test:0.000454 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006303, test:0.000462 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006166, test:0.000343 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007123, test:0.000999 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007596, test:0.001348 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005411, test:0.000383 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005888, test:0.000353 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005534, test:0.000372 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004919, test:0.000306 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005486, test:0.000295 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005287, test:0.000293 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005255, test:0.000297 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005039, test:0.000394 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004847, test:0.000373 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.008150, test:0.000313 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005553, test:0.000308 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004907, test:0.000291 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004668, test:0.000306 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005226, test:0.000304 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004878, test:0.000320 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006762, test:0.000452 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005716, test:0.000508 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006137, test:0.000297 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005302, test:0.000354 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004946, test:0.000324 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005654, test:0.000334 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004756, test:0.000528 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004991, test:0.000348 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005244, test:0.000333 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.007213, test:0.000307 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005059, test:0.000385 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.007677, test:0.000284 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005059, test:0.000280 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004973, test:0.000303 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005204, test:0.000295 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004764, test:0.000443 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004748, test:0.000496 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005567, test:0.000602 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004829, test:0.000407 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004744, test:0.000283 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005680, test:0.000304 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006930, test:0.000298 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006401, test:0.000396 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005012, test:0.000319 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005400, test:0.000338 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006013, test:0.000340 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005136, test:0.000294 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005919, test:0.000280 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004669, test:0.000307 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005855, test:0.000288 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005556, test:0.000315 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005129, test:0.000285 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004822, test:0.000292 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.009176, test:0.000332 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004602, test:0.000289 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005170, test:0.000277 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005069, test:0.000309 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004837, test:0.000323 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004822, test:0.000296 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004607, test:0.000284 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005817, test:0.000321 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004891, test:0.000281 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004646, test:0.000307 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005359, test:0.000288 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004710, test:0.000278 | lr:0.000100\n",
      "Mean absolute error:  1.6577787647442923\n",
      "Root mean squared error:  5.76634730397037\n",
      "Epoch[1/100] | loss train:0.048014, test:0.013127 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011889, test:0.003842 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009588, test:0.001577 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009651, test:0.000402 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011849, test:0.004658 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009635, test:0.002071 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008764, test:0.000386 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010236, test:0.000359 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010051, test:0.002930 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010251, test:0.004103 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009164, test:0.001538 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008044, test:0.002486 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008232, test:0.000691 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006995, test:0.000578 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009531, test:0.000467 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008139, test:0.002466 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007925, test:0.000448 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008251, test:0.000585 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006778, test:0.001070 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/100] | loss train:0.007016, test:0.001015 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007728, test:0.003178 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007084, test:0.002084 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007779, test:0.001293 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.012883, test:0.001542 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008543, test:0.000666 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.010439, test:0.003181 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009795, test:0.000937 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007659, test:0.002157 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008283, test:0.000413 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007242, test:0.001533 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007208, test:0.000643 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007296, test:0.000634 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007458, test:0.000561 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007543, test:0.000868 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006888, test:0.000924 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006970, test:0.001235 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006657, test:0.000752 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009232, test:0.001849 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008336, test:0.001800 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006887, test:0.001856 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005743, test:0.000740 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005800, test:0.000393 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005256, test:0.000517 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006028, test:0.000610 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005184, test:0.000403 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005239, test:0.000424 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005394, test:0.000611 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006423, test:0.000441 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005370, test:0.000450 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005614, test:0.000385 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004906, test:0.000377 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005128, test:0.000642 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004803, test:0.000314 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005464, test:0.000484 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004958, test:0.000393 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005268, test:0.000360 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006816, test:0.000414 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006060, test:0.000392 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005414, test:0.000375 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005335, test:0.000383 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005708, test:0.000350 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005295, test:0.000356 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004829, test:0.000447 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005281, test:0.000318 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.009494, test:0.000498 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.008730, test:0.000389 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004963, test:0.000386 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005720, test:0.000373 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004705, test:0.000385 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006865, test:0.000378 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.007650, test:0.000349 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005322, test:0.000323 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005173, test:0.000546 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005648, test:0.000393 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004899, test:0.000398 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004969, test:0.000545 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005420, test:0.000319 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005401, test:0.000457 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005352, test:0.000572 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005207, test:0.000376 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005302, test:0.000345 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004849, test:0.000320 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005459, test:0.000326 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004957, test:0.000349 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005460, test:0.000350 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.007118, test:0.000375 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005766, test:0.000387 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006404, test:0.000338 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004935, test:0.000327 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005326, test:0.000362 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004655, test:0.000330 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005037, test:0.000339 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006338, test:0.000390 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004444, test:0.000327 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004556, test:0.000376 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005716, test:0.000329 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005799, test:0.000347 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004902, test:0.000329 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004918, test:0.000322 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.009494, test:0.000306 | lr:0.000100\n",
      "Mean absolute error:  1.7046404645956261\n",
      "Root mean squared error:  5.8020199267001775\n",
      "Epoch[1/100] | loss train:0.057657, test:0.001460 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013114, test:0.001857 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011860, test:0.000366 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009755, test:0.000498 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009961, test:0.010761 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009844, test:0.001558 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008993, test:0.000378 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007576, test:0.006042 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008378, test:0.000344 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010891, test:0.004946 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008100, test:0.000897 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.016124, test:0.000378 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008229, test:0.000580 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006726, test:0.001031 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007305, test:0.000958 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007293, test:0.001573 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007462, test:0.001010 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007360, test:0.000386 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007185, test:0.000369 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009035, test:0.003533 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007654, test:0.003039 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007249, test:0.000347 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006858, test:0.000876 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007779, test:0.000779 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007091, test:0.000678 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007769, test:0.001740 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007169, test:0.000408 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006807, test:0.000640 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008034, test:0.001332 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007670, test:0.000689 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006702, test:0.000405 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007005, test:0.000539 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006994, test:0.009815 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007467, test:0.000388 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007275, test:0.000481 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007311, test:0.002468 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006789, test:0.000892 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007238, test:0.000370 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008183, test:0.001818 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008524, test:0.000890 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006187, test:0.000443 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005454, test:0.000400 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005638, test:0.000375 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005577, test:0.000380 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[45/100] | loss train:0.005021, test:0.000444 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006153, test:0.000429 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004780, test:0.000358 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004776, test:0.000427 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004748, test:0.000582 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005485, test:0.000725 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004850, test:0.000401 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005810, test:0.000414 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005297, test:0.000360 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005071, test:0.000401 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005557, test:0.000358 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005176, test:0.000435 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005417, test:0.000361 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006228, test:0.000407 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005350, test:0.000404 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006189, test:0.000370 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005035, test:0.000403 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005551, test:0.000353 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.009116, test:0.000351 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004873, test:0.000340 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.008070, test:0.000443 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005179, test:0.000408 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005582, test:0.000422 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004686, test:0.000537 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005001, test:0.000664 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005806, test:0.000406 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004921, test:0.000311 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005162, test:0.000381 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004826, test:0.000313 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006209, test:0.000335 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006722, test:0.000546 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005103, test:0.000330 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004956, test:0.000349 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004873, test:0.000331 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004861, test:0.000362 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005664, test:0.000403 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005128, test:0.000338 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.007658, test:0.000316 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004888, test:0.000333 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005351, test:0.000321 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005987, test:0.000312 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004882, test:0.000361 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005574, test:0.000324 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004866, test:0.000334 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004962, test:0.000355 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005429, test:0.000344 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004534, test:0.000321 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.009794, test:0.000398 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005246, test:0.000371 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004949, test:0.000361 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005964, test:0.000340 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005667, test:0.000321 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004982, test:0.000320 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.010597, test:0.000330 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005422, test:0.000361 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005149, test:0.000339 | lr:0.000100\n",
      "Mean absolute error:  1.7019110585332324\n",
      "Root mean squared error:  5.806160931921408\n",
      "Epoch[1/100] | loss train:0.060298, test:0.000502 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011878, test:0.000697 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011817, test:0.002337 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011050, test:0.002565 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009887, test:0.008885 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010759, test:0.000848 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007790, test:0.000300 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007274, test:0.001814 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.012444, test:0.001089 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010863, test:0.000336 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009827, test:0.004054 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010220, test:0.001669 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008793, test:0.003092 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010582, test:0.001046 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.010280, test:0.000693 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007570, test:0.000523 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007509, test:0.000369 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008528, test:0.000981 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007968, test:0.000442 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007783, test:0.000571 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007425, test:0.001044 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007515, test:0.000976 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007925, test:0.000437 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007268, test:0.002327 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008442, test:0.002291 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008463, test:0.004562 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007226, test:0.002444 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007765, test:0.000490 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008208, test:0.001491 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007385, test:0.005517 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007874, test:0.000386 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008388, test:0.002666 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008263, test:0.000488 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.010238, test:0.006536 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.010143, test:0.001518 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007795, test:0.000893 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008430, test:0.000928 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007624, test:0.000382 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008170, test:0.000805 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007491, test:0.000444 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005764, test:0.000413 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005757, test:0.000507 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006740, test:0.000460 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006926, test:0.000360 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005708, test:0.000393 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004960, test:0.000409 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005718, test:0.000598 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.008402, test:0.000372 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005504, test:0.000452 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005387, test:0.000539 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005602, test:0.000356 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005408, test:0.000477 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005664, test:0.000559 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005918, test:0.000422 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005740, test:0.000446 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005656, test:0.000357 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006144, test:0.000388 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.012206, test:0.000399 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005103, test:0.000328 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005246, test:0.000376 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005598, test:0.000642 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006902, test:0.000530 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005515, test:0.000404 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005516, test:0.000497 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005118, test:0.000938 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005242, test:0.000329 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005460, test:0.000620 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005883, test:0.000391 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005517, test:0.000347 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[70/100] | loss train:0.005678, test:0.000331 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005751, test:0.000374 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005290, test:0.000406 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005514, test:0.000334 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005359, test:0.000368 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.010087, test:0.000357 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006046, test:0.000360 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006158, test:0.000329 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005296, test:0.000318 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005381, test:0.000363 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006346, test:0.000347 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005387, test:0.000343 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005508, test:0.000371 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005376, test:0.000352 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.006187, test:0.000336 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005020, test:0.000332 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005047, test:0.000353 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.011442, test:0.000346 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005576, test:0.000325 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005195, test:0.000346 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005306, test:0.000323 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005435, test:0.000345 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005146, test:0.000315 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006134, test:0.000316 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.007093, test:0.000346 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005108, test:0.000379 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005131, test:0.000354 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005270, test:0.000340 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006137, test:0.000335 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005469, test:0.000333 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005442, test:0.000334 | lr:0.000100\n",
      "Mean absolute error:  1.6779258700331268\n",
      "Root mean squared error:  5.798549293957455\n",
      "Epoch[1/100] | loss train:0.063687, test:0.001207 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013324, test:0.005783 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010623, test:0.000356 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011082, test:0.001232 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007555, test:0.000615 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008920, test:0.001162 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008487, test:0.001607 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007713, test:0.000409 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009074, test:0.000569 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007565, test:0.000484 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007639, test:0.001619 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008258, test:0.000601 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010197, test:0.000452 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007317, test:0.000450 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008385, test:0.000501 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010345, test:0.001439 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008423, test:0.000496 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007864, test:0.005993 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006882, test:0.001206 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007660, test:0.000778 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006863, test:0.001153 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007715, test:0.000389 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006613, test:0.000494 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007442, test:0.000449 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007749, test:0.005390 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008703, test:0.000533 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006778, test:0.000689 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007029, test:0.002235 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007377, test:0.001516 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007459, test:0.000369 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009268, test:0.003514 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008193, test:0.000348 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009229, test:0.000408 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008378, test:0.001074 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006511, test:0.001068 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007047, test:0.001685 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009332, test:0.001031 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006269, test:0.000441 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.011358, test:0.005375 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.010637, test:0.000697 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006443, test:0.000347 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005496, test:0.000375 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005744, test:0.000768 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005835, test:0.000410 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005186, test:0.000425 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005208, test:0.000495 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006696, test:0.000570 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005223, test:0.000395 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004622, test:0.000347 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005090, test:0.000351 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006829, test:0.000703 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006192, test:0.000410 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005277, test:0.000294 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005247, test:0.000677 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005629, test:0.000316 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005649, test:0.000459 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005560, test:0.000314 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004885, test:0.000286 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005039, test:0.000332 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005202, test:0.000292 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005307, test:0.000321 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005753, test:0.000356 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004787, test:0.000441 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005189, test:0.000361 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004991, test:0.000455 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005120, test:0.000310 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004658, test:0.000325 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005284, test:0.000296 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005021, test:0.000307 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005333, test:0.000309 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006422, test:0.000316 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006560, test:0.000287 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006097, test:0.000320 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005704, test:0.000324 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005210, test:0.000309 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.014727, test:0.000310 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006466, test:0.000330 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.008931, test:0.000433 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.006018, test:0.000307 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006189, test:0.000342 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006258, test:0.000296 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.011064, test:0.000272 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005324, test:0.000337 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005162, test:0.000301 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005363, test:0.000305 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004744, test:0.000277 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004681, test:0.000291 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004927, test:0.000313 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005377, test:0.000318 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004969, test:0.000330 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005072, test:0.000286 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005689, test:0.000307 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005843, test:0.000293 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005369, test:0.000292 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[95/100] | loss train:0.004955, test:0.000305 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005407, test:0.000292 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.011755, test:0.000301 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004946, test:0.000279 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005055, test:0.000285 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004874, test:0.000301 | lr:0.000100\n",
      "Mean absolute error:  1.7631447805235134\n",
      "Root mean squared error:  5.814527428714107\n",
      "Epoch[1/100] | loss train:0.059576, test:0.001400 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009894, test:0.008244 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012460, test:0.000777 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011097, test:0.000315 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007815, test:0.000823 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009918, test:0.000882 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007424, test:0.000378 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008243, test:0.003662 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010407, test:0.002776 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008470, test:0.000594 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009761, test:0.000766 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007888, test:0.000625 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008636, test:0.000608 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009771, test:0.001053 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008278, test:0.001149 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007718, test:0.000332 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007325, test:0.002094 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010959, test:0.005773 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007661, test:0.004180 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007627, test:0.000479 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008193, test:0.000398 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007308, test:0.000793 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006841, test:0.000765 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008545, test:0.000468 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007492, test:0.001536 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006555, test:0.001175 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006572, test:0.000634 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007790, test:0.001844 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006880, test:0.000418 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006360, test:0.000627 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.013461, test:0.001085 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007226, test:0.000540 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008164, test:0.001565 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006695, test:0.000781 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007163, test:0.001189 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.011005, test:0.001163 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007566, test:0.001117 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006513, test:0.000752 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006669, test:0.000943 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007254, test:0.002551 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006183, test:0.000441 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006186, test:0.000421 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005098, test:0.000465 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004959, test:0.000431 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005587, test:0.000405 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004880, test:0.000360 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006048, test:0.000560 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005421, test:0.000471 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007972, test:0.000355 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005379, test:0.000542 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005646, test:0.000391 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005586, test:0.000348 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005056, test:0.000395 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005107, test:0.000369 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005259, test:0.000376 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.007081, test:0.000401 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005182, test:0.000389 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005071, test:0.000444 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006030, test:0.000350 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004951, test:0.000360 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005710, test:0.000452 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005329, test:0.000471 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005253, test:0.000385 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005209, test:0.000353 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005425, test:0.000669 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004963, test:0.000322 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004922, test:0.000342 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005179, test:0.000315 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005243, test:0.000678 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005363, test:0.000364 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004924, test:0.000399 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005906, test:0.000344 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004754, test:0.000415 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004550, test:0.000353 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004855, test:0.000354 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005276, test:0.000358 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004805, test:0.000388 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006003, test:0.000373 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.007462, test:0.000526 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005018, test:0.000328 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005343, test:0.000340 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005649, test:0.000324 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005022, test:0.000330 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005856, test:0.000359 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005546, test:0.000345 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004991, test:0.000327 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004901, test:0.000317 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004932, test:0.000350 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006781, test:0.000293 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005080, test:0.000363 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005241, test:0.000315 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004400, test:0.000351 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005222, test:0.000358 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005141, test:0.000336 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004837, test:0.000357 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004768, test:0.000319 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004778, test:0.000321 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005820, test:0.000347 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004533, test:0.000364 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005131, test:0.000329 | lr:0.000100\n",
      "Mean absolute error:  1.6798412950768808\n",
      "Root mean squared error:  5.799476650194717\n",
      "Epoch[1/100] | loss train:0.049985, test:0.001650 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013968, test:0.000535 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009771, test:0.003914 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010044, test:0.001558 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010010, test:0.004331 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009817, test:0.008719 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011266, test:0.000333 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009024, test:0.000366 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008988, test:0.000305 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007629, test:0.000277 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011691, test:0.000349 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009279, test:0.000345 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007791, test:0.000584 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010094, test:0.000576 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007502, test:0.000867 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008362, test:0.001128 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010332, test:0.000378 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008868, test:0.000847 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/100] | loss train:0.007640, test:0.000685 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007771, test:0.000565 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007215, test:0.003316 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007665, test:0.001662 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008006, test:0.000490 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007136, test:0.000674 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006489, test:0.001987 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006236, test:0.000491 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.010646, test:0.002642 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.010324, test:0.000522 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006722, test:0.001443 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007270, test:0.000618 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008597, test:0.003050 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.011185, test:0.001441 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008831, test:0.000602 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007978, test:0.000439 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008860, test:0.000413 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007174, test:0.002062 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008180, test:0.000504 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008369, test:0.002683 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007541, test:0.001868 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006171, test:0.001197 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005879, test:0.000547 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006049, test:0.000463 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006313, test:0.000425 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.007568, test:0.000528 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005288, test:0.000474 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005161, test:0.000405 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005199, test:0.000386 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005567, test:0.000403 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005799, test:0.000514 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006488, test:0.000446 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005086, test:0.000397 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.007111, test:0.000427 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005184, test:0.000418 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005026, test:0.000410 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005318, test:0.000383 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005058, test:0.000532 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005402, test:0.000385 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006403, test:0.000872 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005577, test:0.000379 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005207, test:0.000357 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.007556, test:0.000367 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005495, test:0.000700 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006160, test:0.000426 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005074, test:0.000451 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004794, test:0.000394 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004860, test:0.000398 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005315, test:0.000337 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005073, test:0.000405 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005136, test:0.000345 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004800, test:0.000378 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005484, test:0.000341 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005616, test:0.000368 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005225, test:0.000372 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.010571, test:0.000324 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005126, test:0.000380 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004667, test:0.000337 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005448, test:0.000461 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006370, test:0.000426 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005294, test:0.000341 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005080, test:0.000349 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.007805, test:0.000363 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006017, test:0.000352 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.009963, test:0.000345 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004836, test:0.000374 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005998, test:0.000342 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005036, test:0.000339 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006273, test:0.000369 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005796, test:0.000436 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006317, test:0.000341 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005135, test:0.000335 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.007858, test:0.000370 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.007553, test:0.000319 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004883, test:0.000361 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004913, test:0.000349 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004866, test:0.000331 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004715, test:0.000338 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005482, test:0.000334 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005520, test:0.000370 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005656, test:0.000388 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005687, test:0.000323 | lr:0.000100\n",
      "Mean absolute error:  1.7049930294724562\n",
      "Root mean squared error:  5.8247612300202745\n",
      "Epoch[1/100] | loss train:0.041302, test:0.000415 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012432, test:0.001224 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010911, test:0.001003 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010498, test:0.000527 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012275, test:0.005399 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.014033, test:0.001416 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007740, test:0.002119 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007830, test:0.000546 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008468, test:0.000578 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009626, test:0.001840 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007824, test:0.000825 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009340, test:0.000738 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010200, test:0.000890 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008479, test:0.000564 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006988, test:0.002742 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007279, test:0.002843 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008719, test:0.000508 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007469, test:0.001456 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008632, test:0.001608 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009869, test:0.000547 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008470, test:0.000468 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007557, test:0.000534 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006783, test:0.000595 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.012706, test:0.004892 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007572, test:0.000709 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007356, test:0.000675 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007721, test:0.001827 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007625, test:0.000508 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008152, test:0.002882 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007357, test:0.000451 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006963, test:0.000590 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008197, test:0.001566 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007337, test:0.001555 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007932, test:0.000426 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008050, test:0.001001 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007463, test:0.000838 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006522, test:0.000588 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006765, test:0.001819 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007496, test:0.000742 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008227, test:0.000652 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005319, test:0.000569 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005562, test:0.000701 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005475, test:0.000564 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[44/100] | loss train:0.006230, test:0.000618 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004905, test:0.000424 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004988, test:0.000636 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006130, test:0.000401 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005412, test:0.000391 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006132, test:0.000426 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004985, test:0.000430 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005229, test:0.000402 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005368, test:0.000507 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005178, test:0.000365 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004946, test:0.000437 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004903, test:0.000380 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005907, test:0.000365 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005664, test:0.000436 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004792, test:0.000362 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005202, test:0.000402 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004623, test:0.000333 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005113, test:0.000324 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005675, test:0.000482 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005180, test:0.000343 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006285, test:0.000362 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005103, test:0.000566 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006970, test:0.000356 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005896, test:0.000340 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005695, test:0.000301 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005059, test:0.000313 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005951, test:0.000553 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005489, test:0.000302 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005417, test:0.000477 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005256, test:0.000576 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005112, test:0.000365 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.007438, test:0.000371 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006352, test:0.000350 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006619, test:0.000338 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004567, test:0.000403 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004897, test:0.000492 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005215, test:0.000354 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.007445, test:0.000325 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006101, test:0.000340 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005128, test:0.000348 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005297, test:0.000350 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005833, test:0.000345 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004792, test:0.000303 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005597, test:0.000315 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005144, test:0.000316 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005033, test:0.000320 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004618, test:0.000395 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004834, test:0.000342 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005059, test:0.000349 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005288, test:0.000332 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005243, test:0.000319 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005052, test:0.000318 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004672, test:0.000332 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005282, test:0.000300 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005180, test:0.000325 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005036, test:0.000311 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004987, test:0.000318 | lr:0.000100\n",
      "Mean absolute error:  1.677304028705141\n",
      "Root mean squared error:  5.781394283405217\n",
      "Epoch[1/100] | loss train:0.068044, test:0.000933 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012420, test:0.001668 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.020511, test:0.007005 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013212, test:0.004524 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007811, test:0.001348 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010019, test:0.000470 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007904, test:0.000749 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008190, test:0.000893 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009169, test:0.001718 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.020716, test:0.001388 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010963, test:0.004444 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011926, test:0.000867 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008316, test:0.001804 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009747, test:0.002280 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008521, test:0.002434 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008285, test:0.000444 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.011841, test:0.003312 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008645, test:0.000412 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007717, test:0.007864 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008038, test:0.003935 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008565, test:0.000853 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007537, test:0.003442 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008544, test:0.001518 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007889, test:0.000394 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008049, test:0.000697 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006861, test:0.000360 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009043, test:0.003202 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007849, test:0.000393 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008358, test:0.000443 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007753, test:0.000387 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007580, test:0.000921 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007192, test:0.000530 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006969, test:0.000464 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008154, test:0.000583 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008516, test:0.001391 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.018085, test:0.006465 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.010680, test:0.000562 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007017, test:0.001478 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008078, test:0.000544 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008026, test:0.000657 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006313, test:0.000411 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005552, test:0.000452 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005607, test:0.000412 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005791, test:0.000460 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005411, test:0.000570 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.008868, test:0.000388 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005867, test:0.000383 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005753, test:0.000476 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005514, test:0.000863 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005522, test:0.000568 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005697, test:0.000416 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005651, test:0.000394 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005490, test:0.000512 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005350, test:0.000420 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006536, test:0.000443 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005626, test:0.000405 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005822, test:0.000455 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005549, test:0.000454 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.007218, test:0.000481 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006264, test:0.000593 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005972, test:0.000470 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005489, test:0.001070 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005504, test:0.000404 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005639, test:0.000648 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004893, test:0.000541 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005880, test:0.000372 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005249, test:0.000358 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006438, test:0.000413 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[69/100] | loss train:0.005329, test:0.000417 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005570, test:0.000416 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005767, test:0.000399 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005828, test:0.000441 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005035, test:0.000370 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005284, test:0.000542 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006586, test:0.000402 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005960, test:0.000425 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006644, test:0.000395 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.010856, test:0.000482 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005327, test:0.000380 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005232, test:0.000981 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.008096, test:0.000382 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005852, test:0.000359 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005674, test:0.000418 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005818, test:0.000365 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005377, test:0.000341 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005873, test:0.000386 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005684, test:0.000377 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005284, test:0.000383 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005209, test:0.000350 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005337, test:0.000370 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006305, test:0.000360 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005359, test:0.000380 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005620, test:0.000360 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.007925, test:0.000360 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004863, test:0.000347 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005466, test:0.000364 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005603, test:0.000351 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005089, test:0.000337 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.006952, test:0.000373 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005242, test:0.000383 | lr:0.000100\n",
      "Mean absolute error:  1.7960265402936786\n",
      "Root mean squared error:  5.8605990859195485\n",
      "Epoch[1/100] | loss train:0.060212, test:0.002082 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011726, test:0.000314 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011718, test:0.000632 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010988, test:0.000543 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009652, test:0.000960 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011382, test:0.002188 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009036, test:0.000798 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008019, test:0.002160 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007731, test:0.004123 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009280, test:0.001343 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010783, test:0.002908 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009079, test:0.000732 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007928, test:0.001379 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007759, test:0.001477 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008255, test:0.000469 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007673, test:0.001209 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.017434, test:0.001839 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009151, test:0.002216 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009330, test:0.002569 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009125, test:0.002450 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007247, test:0.003353 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.017303, test:0.003785 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008870, test:0.000479 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007188, test:0.000654 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007866, test:0.001069 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006985, test:0.004288 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009756, test:0.000415 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007002, test:0.002294 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007399, test:0.000347 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006737, test:0.000669 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006839, test:0.000847 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009557, test:0.003514 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008090, test:0.000971 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.020059, test:0.000506 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007888, test:0.002694 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007951, test:0.003435 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007498, test:0.000498 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006827, test:0.001147 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007269, test:0.000725 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008179, test:0.001913 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006929, test:0.000347 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005936, test:0.000323 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005478, test:0.000517 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005355, test:0.000507 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005815, test:0.000421 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005648, test:0.000347 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005322, test:0.000516 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005517, test:0.000357 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005547, test:0.000289 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005403, test:0.000497 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005508, test:0.000459 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005104, test:0.000426 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005135, test:0.000306 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005946, test:0.000692 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006018, test:0.000288 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005288, test:0.000346 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005690, test:0.000323 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005900, test:0.000327 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004972, test:0.000400 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005448, test:0.000359 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005388, test:0.000290 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006510, test:0.000390 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005991, test:0.000399 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005512, test:0.000330 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005298, test:0.000318 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005446, test:0.000306 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005318, test:0.000435 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005408, test:0.000314 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005210, test:0.000287 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005375, test:0.000277 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005469, test:0.000342 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005576, test:0.000400 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005994, test:0.000307 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005385, test:0.000281 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005414, test:0.000439 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005186, test:0.000294 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006494, test:0.000340 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005544, test:0.000316 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005323, test:0.000372 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005295, test:0.000479 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005478, test:0.000319 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005440, test:0.000308 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005650, test:0.000293 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.007355, test:0.000323 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005778, test:0.000285 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005070, test:0.000297 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005482, test:0.000313 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005567, test:0.000317 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005743, test:0.000290 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005416, test:0.000285 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005612, test:0.000299 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005187, test:0.000303 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005085, test:0.000307 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[94/100] | loss train:0.005216, test:0.000299 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005469, test:0.000279 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006055, test:0.000282 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005759, test:0.000304 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004997, test:0.000266 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.006550, test:0.000293 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005121, test:0.000282 | lr:0.000100\n",
      "Mean absolute error:  1.7078983237105145\n",
      "Root mean squared error:  5.801159457666768\n",
      "Epoch[1/100] | loss train:0.064845, test:0.002707 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.016146, test:0.000424 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012166, test:0.000699 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011322, test:0.009210 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010279, test:0.000296 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009756, test:0.000307 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007088, test:0.001129 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010168, test:0.001728 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009672, test:0.001046 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008506, test:0.003013 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009389, test:0.003253 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008969, test:0.002992 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008882, test:0.004211 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009232, test:0.000510 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007389, test:0.004722 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007651, test:0.000731 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008448, test:0.000313 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010330, test:0.000400 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007232, test:0.000799 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009417, test:0.000891 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007207, test:0.001988 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009164, test:0.000454 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007818, test:0.000544 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007151, test:0.002341 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007199, test:0.001054 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007261, test:0.000526 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.010293, test:0.000442 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007036, test:0.000458 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008579, test:0.000405 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010911, test:0.009880 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.010380, test:0.000466 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007484, test:0.000440 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008401, test:0.000394 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007166, test:0.000367 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007819, test:0.000380 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006996, test:0.001188 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007303, test:0.000508 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007616, test:0.001240 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007464, test:0.002467 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006944, test:0.001310 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.013729, test:0.000401 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006337, test:0.000462 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005113, test:0.000426 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005823, test:0.000401 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005931, test:0.000684 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005520, test:0.000424 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005266, test:0.000378 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005569, test:0.000347 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005581, test:0.000350 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005648, test:0.000638 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006570, test:0.000409 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005287, test:0.000383 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004886, test:0.000361 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005440, test:0.000377 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005685, test:0.000354 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005046, test:0.000445 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005648, test:0.000422 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005660, test:0.000496 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005688, test:0.000488 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005403, test:0.000395 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005172, test:0.000546 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005748, test:0.000425 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005538, test:0.000353 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005664, test:0.000377 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006471, test:0.000481 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005091, test:0.000455 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005258, test:0.000373 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005979, test:0.000754 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005470, test:0.000652 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005551, test:0.000672 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005515, test:0.000388 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005689, test:0.000352 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005669, test:0.000418 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005107, test:0.000513 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006968, test:0.000356 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006898, test:0.000467 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005350, test:0.000301 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004913, test:0.000383 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005378, test:0.000301 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005358, test:0.000325 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005476, test:0.000320 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005094, test:0.000303 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.007583, test:0.000314 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005965, test:0.000288 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.006718, test:0.000315 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005731, test:0.000311 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004911, test:0.000309 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005178, test:0.000358 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005573, test:0.000321 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.007240, test:0.000323 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006280, test:0.000330 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005360, test:0.000308 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006699, test:0.000327 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005244, test:0.000320 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005457, test:0.000298 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006437, test:0.000310 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004976, test:0.000306 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005349, test:0.000307 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005343, test:0.000315 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006232, test:0.000309 | lr:0.000100\n",
      "Mean absolute error:  1.7116024158697358\n",
      "Root mean squared error:  5.796203910201812\n",
      "Epoch[1/100] | loss train:0.051288, test:0.001974 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013555, test:0.000465 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012191, test:0.005306 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010214, test:0.000729 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009100, test:0.000480 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009951, test:0.004149 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010716, test:0.001181 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007437, test:0.000962 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010998, test:0.002319 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009512, test:0.001073 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008480, test:0.001447 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008531, test:0.000681 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009787, test:0.001914 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007724, test:0.001023 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008200, test:0.000698 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006648, test:0.002880 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007349, test:0.000356 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[18/100] | loss train:0.007775, test:0.000482 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009226, test:0.001171 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007471, test:0.000411 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.012675, test:0.002460 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009508, test:0.001704 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008818, test:0.000985 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007994, test:0.000457 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007339, test:0.001156 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009324, test:0.000525 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008514, test:0.000703 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007919, test:0.000646 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007761, test:0.001085 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009693, test:0.000495 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007479, test:0.000464 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.010215, test:0.000903 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.012258, test:0.000392 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008942, test:0.001497 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007332, test:0.002097 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006512, test:0.000937 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006465, test:0.001284 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006863, test:0.000330 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006870, test:0.000406 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007445, test:0.000708 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006349, test:0.000320 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006477, test:0.000330 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005372, test:0.000394 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005225, test:0.000320 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006858, test:0.000297 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005030, test:0.000301 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005501, test:0.000445 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005336, test:0.000340 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005266, test:0.001166 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006226, test:0.000277 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005515, test:0.000284 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005973, test:0.000336 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005239, test:0.000302 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004988, test:0.000821 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005055, test:0.000294 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.012142, test:0.000318 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005477, test:0.000285 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005225, test:0.000641 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006744, test:0.000305 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005367, test:0.000610 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005080, test:0.000389 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005753, test:0.000315 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004977, test:0.000287 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004804, test:0.000285 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004977, test:0.000572 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006834, test:0.000281 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004703, test:0.000325 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005021, test:0.000306 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.007214, test:0.000284 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004875, test:0.000283 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005226, test:0.000505 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004957, test:0.000270 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004838, test:0.000285 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006143, test:0.000570 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005325, test:0.000339 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004677, test:0.000308 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004910, test:0.000416 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005161, test:0.000299 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004857, test:0.000333 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005896, test:0.000340 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005073, test:0.000276 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005666, test:0.000292 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004943, test:0.000275 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.007608, test:0.000287 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005361, test:0.000287 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004702, test:0.000271 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004781, test:0.000336 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004534, test:0.000296 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004814, test:0.000284 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005038, test:0.000288 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004526, test:0.000315 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004991, test:0.000286 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005245, test:0.000287 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005357, test:0.000312 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004974, test:0.000291 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004859, test:0.000289 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004689, test:0.000254 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004706, test:0.000279 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005007, test:0.000283 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004914, test:0.000282 | lr:0.000100\n",
      "Mean absolute error:  1.6482221192534328\n",
      "Root mean squared error:  5.761447192186343\n",
      "Epoch[1/100] | loss train:0.075186, test:0.001193 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.018729, test:0.002632 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012191, test:0.001610 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009522, test:0.001080 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010241, test:0.000926 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.014667, test:0.002085 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.012793, test:0.000726 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008006, test:0.000636 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009873, test:0.005847 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011431, test:0.001949 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010182, test:0.005919 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007753, test:0.003080 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.011947, test:0.004547 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009765, test:0.007244 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008689, test:0.000528 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007889, test:0.003351 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007899, test:0.003065 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007075, test:0.001822 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.010350, test:0.000866 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007614, test:0.002802 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.010330, test:0.000444 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010597, test:0.004436 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008931, test:0.000751 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007416, test:0.000628 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007821, test:0.000412 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006872, test:0.000417 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007103, test:0.000553 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008367, test:0.003957 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006983, test:0.002271 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006950, test:0.000506 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007150, test:0.001480 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006848, test:0.000397 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008433, test:0.001444 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007471, test:0.000610 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007565, test:0.001076 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009976, test:0.002582 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.010874, test:0.001080 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008388, test:0.000734 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008431, test:0.000906 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006990, test:0.000895 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006065, test:0.000389 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005228, test:0.000343 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[43/100] | loss train:0.005544, test:0.000561 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005551, test:0.000495 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005755, test:0.000344 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005301, test:0.000361 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005439, test:0.000377 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006657, test:0.000541 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006625, test:0.000387 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005137, test:0.000355 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005359, test:0.000558 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005855, test:0.000366 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005615, test:0.000468 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005093, test:0.000350 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005201, test:0.000399 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004985, test:0.000580 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004988, test:0.000394 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005833, test:0.000557 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005387, test:0.000321 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005142, test:0.000552 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.007002, test:0.000437 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.007491, test:0.000350 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005547, test:0.000378 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005724, test:0.000399 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005798, test:0.000327 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005350, test:0.000464 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005402, test:0.000438 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005317, test:0.000456 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006194, test:0.000316 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.009519, test:0.000362 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005080, test:0.000342 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005798, test:0.000334 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006054, test:0.000460 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005703, test:0.000311 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.010029, test:0.000472 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005855, test:0.000324 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005455, test:0.000307 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005417, test:0.000679 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.009029, test:0.000427 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004768, test:0.000301 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006172, test:0.000333 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004992, test:0.000343 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005255, test:0.000349 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005865, test:0.000323 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005381, test:0.000334 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005020, test:0.000331 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006737, test:0.000335 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005672, test:0.000337 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005177, test:0.000335 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005270, test:0.000362 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.007099, test:0.000333 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005823, test:0.000333 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005233, test:0.000328 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004971, test:0.000336 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005000, test:0.000320 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005624, test:0.000309 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004939, test:0.000348 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005518, test:0.000323 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005174, test:0.000304 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004879, test:0.000334 | lr:0.000100\n",
      "Mean absolute error:  1.6721246017434848\n",
      "Root mean squared error:  5.787030022032553\n",
      "Epoch[1/100] | loss train:0.055524, test:0.000677 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010456, test:0.004874 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.023460, test:0.002161 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012521, test:0.004264 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010188, test:0.000455 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008074, test:0.005551 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007980, test:0.000473 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009747, test:0.001680 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007178, test:0.000357 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007411, test:0.000548 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007429, test:0.000404 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010403, test:0.000327 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.006917, test:0.002310 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007720, test:0.006762 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009053, test:0.000481 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008773, test:0.000516 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007727, test:0.000572 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009639, test:0.000859 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008219, test:0.000584 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007279, test:0.000419 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007765, test:0.000446 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007206, test:0.000502 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006854, test:0.000955 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006569, test:0.000758 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007275, test:0.000730 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006693, test:0.000429 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007712, test:0.005897 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.012892, test:0.001293 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007680, test:0.000460 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006180, test:0.000784 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007334, test:0.000822 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006493, test:0.000789 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007375, test:0.000407 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008333, test:0.000789 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007638, test:0.000470 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006930, test:0.001367 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006711, test:0.002087 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007267, test:0.000774 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007178, test:0.000347 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006424, test:0.001168 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006747, test:0.000497 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005175, test:0.000395 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006277, test:0.000422 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005138, test:0.000328 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005325, test:0.000505 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005651, test:0.000349 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005868, test:0.000341 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005263, test:0.000371 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007802, test:0.000370 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004788, test:0.000304 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005498, test:0.000312 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004662, test:0.000395 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005381, test:0.000343 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.009207, test:0.000538 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005335, test:0.000449 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004849, test:0.000341 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005638, test:0.000404 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004700, test:0.000327 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005653, test:0.000373 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004964, test:0.000456 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.007685, test:0.000629 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005445, test:0.000324 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005614, test:0.000363 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004868, test:0.000376 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005093, test:0.000351 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005777, test:0.000340 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005055, test:0.000329 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[68/100] | loss train:0.004802, test:0.000312 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005937, test:0.000487 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005931, test:0.000376 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005103, test:0.000441 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005188, test:0.000442 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004750, test:0.000309 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005600, test:0.000346 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005385, test:0.000391 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005014, test:0.000319 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005079, test:0.000657 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005097, test:0.000396 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005166, test:0.000331 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005520, test:0.000323 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004619, test:0.000328 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004805, test:0.000343 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004588, test:0.000349 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005154, test:0.000301 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005974, test:0.000302 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005278, test:0.000327 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005525, test:0.000300 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004972, test:0.000341 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004696, test:0.000321 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004806, test:0.000322 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004872, test:0.000295 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005243, test:0.000334 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005405, test:0.000334 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005503, test:0.000306 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005346, test:0.000312 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004926, test:0.000306 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005023, test:0.000322 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004902, test:0.000306 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005230, test:0.000348 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004668, test:0.000301 | lr:0.000100\n",
      "Mean absolute error:  1.6640352477689064\n",
      "Root mean squared error:  5.779711868513434\n",
      "Epoch[1/100] | loss train:0.046721, test:0.002291 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011585, test:0.002094 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012207, test:0.001481 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009103, test:0.000320 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.017969, test:0.003362 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011721, test:0.001126 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008806, test:0.000581 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007792, test:0.000598 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.016551, test:0.006817 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009532, test:0.001398 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008779, test:0.000422 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.013350, test:0.000528 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009501, test:0.001166 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009203, test:0.003217 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008152, test:0.000569 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008601, test:0.000974 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010248, test:0.000617 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007839, test:0.000993 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007463, test:0.004129 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007826, test:0.004124 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007013, test:0.000509 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007061, test:0.000356 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009453, test:0.000467 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007822, test:0.002083 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009043, test:0.001367 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007353, test:0.000695 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006674, test:0.001026 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006974, test:0.000623 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007086, test:0.001827 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006140, test:0.005546 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007956, test:0.002544 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006721, test:0.001433 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008272, test:0.001568 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007607, test:0.000610 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006862, test:0.000457 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007993, test:0.000368 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006276, test:0.000787 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006796, test:0.000919 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006180, test:0.001139 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008646, test:0.001111 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005414, test:0.000382 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005442, test:0.000307 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005278, test:0.000311 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005161, test:0.000347 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005624, test:0.000349 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005973, test:0.000742 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005162, test:0.000323 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.007367, test:0.000600 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005354, test:0.000332 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005338, test:0.000383 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004930, test:0.000322 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005181, test:0.000348 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004721, test:0.000295 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005750, test:0.000301 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004990, test:0.000322 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005050, test:0.000276 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005002, test:0.000361 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005033, test:0.000303 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004613, test:0.000367 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005473, test:0.000533 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005739, test:0.000311 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005610, test:0.000332 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005360, test:0.000337 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005332, test:0.000292 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005322, test:0.000352 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005917, test:0.000535 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004816, test:0.000345 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005132, test:0.000303 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005710, test:0.000297 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004986, test:0.000301 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005783, test:0.000295 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.007966, test:0.000317 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004838, test:0.000305 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005783, test:0.000279 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005058, test:0.000453 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006738, test:0.000363 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005655, test:0.000316 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004775, test:0.000335 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004846, test:0.000313 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004852, test:0.000342 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.010555, test:0.000281 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005502, test:0.000262 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004936, test:0.000271 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004857, test:0.000285 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004956, test:0.000284 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004811, test:0.000286 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004802, test:0.000271 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005193, test:0.000254 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006217, test:0.000271 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005004, test:0.000266 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005189, test:0.000274 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004846, test:0.000260 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[93/100] | loss train:0.006206, test:0.000261 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004901, test:0.000307 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005475, test:0.000287 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006953, test:0.000269 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004681, test:0.000270 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004806, test:0.000267 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005543, test:0.000276 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005424, test:0.000294 | lr:0.000100\n",
      "Mean absolute error:  1.668273954138665\n",
      "Root mean squared error:  5.778981348734048\n",
      "Epoch[1/100] | loss train:0.043791, test:0.000402 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012942, test:0.011854 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009978, test:0.008007 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011601, test:0.000660 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008741, test:0.000334 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009671, test:0.003019 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009687, test:0.000399 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.012587, test:0.000433 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010356, test:0.000439 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008605, test:0.004125 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007845, test:0.000503 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009227, test:0.004512 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007849, test:0.001561 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007307, test:0.000456 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007824, test:0.000374 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007451, test:0.000479 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009990, test:0.001810 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007586, test:0.000631 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006589, test:0.000706 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007874, test:0.002012 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008148, test:0.000925 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007032, test:0.001452 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007794, test:0.001776 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006748, test:0.000515 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008045, test:0.000445 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006762, test:0.000504 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007780, test:0.000525 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006885, test:0.002277 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.011346, test:0.004803 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007101, test:0.000693 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006773, test:0.000806 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006605, test:0.000441 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008522, test:0.000784 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007928, test:0.000486 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.018104, test:0.000753 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.010065, test:0.001075 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008332, test:0.001007 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006669, test:0.000345 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007950, test:0.000586 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007625, test:0.000333 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005526, test:0.000384 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006264, test:0.000356 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005132, test:0.000493 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005919, test:0.000337 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005044, test:0.000351 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005335, test:0.000406 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006790, test:0.000408 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004958, test:0.000368 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005476, test:0.000359 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004763, test:0.000425 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005555, test:0.000440 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004911, test:0.000362 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005964, test:0.001019 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005548, test:0.000323 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006039, test:0.000311 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005647, test:0.000386 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005228, test:0.000497 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004883, test:0.000285 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005543, test:0.000338 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004845, test:0.000343 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005615, test:0.000369 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005029, test:0.000420 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005232, test:0.000325 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005862, test:0.000346 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005470, test:0.000325 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005999, test:0.000323 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006019, test:0.000342 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006105, test:0.000294 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.015126, test:0.000452 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005508, test:0.000341 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005487, test:0.000311 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005922, test:0.000356 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005616, test:0.000370 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005764, test:0.000314 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005450, test:0.000469 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005303, test:0.000439 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005605, test:0.000346 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004772, test:0.000421 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005096, test:0.000311 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004845, test:0.000313 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004787, test:0.000371 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005659, test:0.000306 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005191, test:0.000322 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005025, test:0.000384 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005163, test:0.000369 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005083, test:0.000334 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005226, test:0.000341 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005129, test:0.000308 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005101, test:0.000345 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005360, test:0.000331 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005680, test:0.000309 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005229, test:0.000294 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005074, test:0.000311 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004904, test:0.000296 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.012973, test:0.000344 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.020585, test:0.000317 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005034, test:0.000308 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005170, test:0.000334 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004943, test:0.000297 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005663, test:0.000315 | lr:0.000100\n",
      "Mean absolute error:  1.6600433398055907\n",
      "Root mean squared error:  5.780577953892067\n",
      "Epoch[1/100] | loss train:0.051836, test:0.001959 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012216, test:0.000924 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011910, test:0.000385 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010594, test:0.000283 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010283, test:0.000288 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009749, test:0.000422 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009182, test:0.000356 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009219, test:0.000312 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010160, test:0.004405 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010850, test:0.003983 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009824, test:0.003198 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008092, test:0.000680 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007475, test:0.000414 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007929, test:0.001305 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007740, test:0.000613 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007805, test:0.001252 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17/100] | loss train:0.007928, test:0.002070 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007522, test:0.001062 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008729, test:0.000522 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008126, test:0.001281 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009204, test:0.000490 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007975, test:0.001147 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008601, test:0.000395 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007872, test:0.001002 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006823, test:0.000370 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008024, test:0.002250 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006521, test:0.000507 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007028, test:0.003261 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007354, test:0.002361 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006854, test:0.003593 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007284, test:0.000987 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007054, test:0.001008 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007201, test:0.000916 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009398, test:0.009018 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.011459, test:0.000986 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007145, test:0.000319 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006620, test:0.000421 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007845, test:0.000319 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006776, test:0.003748 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006480, test:0.001424 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006855, test:0.000297 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006317, test:0.000357 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005439, test:0.000384 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005040, test:0.000339 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005214, test:0.000322 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005506, test:0.000557 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005413, test:0.000338 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005412, test:0.000337 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006288, test:0.000337 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006169, test:0.000408 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004734, test:0.000285 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004940, test:0.000435 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005474, test:0.000482 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004800, test:0.000279 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004896, test:0.000327 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006300, test:0.000465 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004912, test:0.000293 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004640, test:0.000327 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005615, test:0.000277 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005850, test:0.000290 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005535, test:0.000289 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005833, test:0.000295 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005028, test:0.000356 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.009225, test:0.000490 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005559, test:0.000347 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005117, test:0.000311 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005198, test:0.000311 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005214, test:0.000573 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005320, test:0.000386 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004829, test:0.000284 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005250, test:0.000300 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005170, test:0.000591 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005195, test:0.000351 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005309, test:0.000367 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.007181, test:0.000295 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004987, test:0.000282 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005641, test:0.000280 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004985, test:0.000294 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005013, test:0.000267 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005103, test:0.000304 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006091, test:0.000281 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004916, test:0.000301 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005483, test:0.000293 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004620, test:0.000302 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004839, test:0.000275 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004748, test:0.000277 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005802, test:0.000267 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006299, test:0.000315 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005945, test:0.000272 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.011834, test:0.000278 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005372, test:0.000297 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004606, test:0.000274 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005068, test:0.000298 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005124, test:0.000304 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004993, test:0.000295 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005389, test:0.000294 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005644, test:0.000292 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005070, test:0.000278 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004425, test:0.000288 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005033, test:0.000292 | lr:0.000100\n",
      "Mean absolute error:  1.7204629162742486\n",
      "Root mean squared error:  5.797971524616358\n",
      "Epoch[1/100] | loss train:0.059838, test:0.004212 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013767, test:0.000458 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011378, test:0.000478 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011273, test:0.000730 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008312, test:0.000303 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009236, test:0.000531 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009659, test:0.007803 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009481, test:0.000663 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009163, test:0.003800 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010036, test:0.003040 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008892, test:0.002843 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009929, test:0.002211 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009790, test:0.000482 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009502, test:0.003823 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009711, test:0.010328 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009662, test:0.002573 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008453, test:0.000999 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007726, test:0.000481 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007180, test:0.000335 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008806, test:0.001383 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008815, test:0.000575 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.011264, test:0.002535 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008908, test:0.000427 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009958, test:0.000475 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009185, test:0.003982 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.010303, test:0.000426 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009233, test:0.000471 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007404, test:0.000411 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007864, test:0.000732 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.015913, test:0.002859 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.011790, test:0.000773 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.010092, test:0.000753 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006979, test:0.002405 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.019085, test:0.003125 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.013130, test:0.000574 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008817, test:0.001644 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007630, test:0.000760 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007999, test:0.000457 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007499, test:0.002361 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009631, test:0.000466 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006531, test:0.000434 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[42/100] | loss train:0.006221, test:0.000447 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006649, test:0.000420 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005928, test:0.000447 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006084, test:0.000482 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006213, test:0.000458 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005527, test:0.000527 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.008983, test:0.000444 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005566, test:0.000408 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005898, test:0.000495 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005485, test:0.000381 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.007809, test:0.000946 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006477, test:0.000771 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006693, test:0.000512 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.008129, test:0.000362 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005997, test:0.000372 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005818, test:0.000342 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005513, test:0.000470 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005940, test:0.000374 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.008936, test:0.000340 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005463, test:0.000370 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006446, test:0.000328 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005688, test:0.000405 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005453, test:0.000692 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005953, test:0.000701 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005837, test:0.000318 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006864, test:0.000355 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006381, test:0.000424 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005994, test:0.000416 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005891, test:0.000449 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.007614, test:0.000537 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006006, test:0.000345 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005960, test:0.000336 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005613, test:0.000485 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.012145, test:0.000370 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005707, test:0.000369 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005689, test:0.000352 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006915, test:0.000423 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005632, test:0.000443 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.007332, test:0.000542 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005192, test:0.000358 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005788, test:0.000331 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.009804, test:0.000320 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005238, test:0.000350 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005186, test:0.000337 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005716, test:0.000343 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.015560, test:0.000348 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006103, test:0.000344 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006813, test:0.000357 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006268, test:0.000367 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005744, test:0.000324 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005787, test:0.000345 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005280, test:0.000351 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005559, test:0.000352 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005828, test:0.000365 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005561, test:0.000321 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005287, test:0.000319 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005733, test:0.000346 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.007238, test:0.000329 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005180, test:0.000328 | lr:0.000100\n",
      "Mean absolute error:  1.7223148600388258\n",
      "Root mean squared error:  5.803949368745488\n",
      "Epoch[1/100] | loss train:0.049884, test:0.001849 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011719, test:0.000582 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010516, test:0.003500 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010241, test:0.001325 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009277, test:0.000295 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007242, test:0.003203 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007957, test:0.000417 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.018269, test:0.002614 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009880, test:0.001084 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008565, test:0.000929 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008193, test:0.001740 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008954, test:0.000478 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007263, test:0.004375 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008274, test:0.007748 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.014866, test:0.000398 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009872, test:0.000444 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007083, test:0.000840 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008831, test:0.001883 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009433, test:0.000387 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007737, test:0.000784 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007429, test:0.003933 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007975, test:0.008486 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008331, test:0.000410 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007439, test:0.000695 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006740, test:0.001766 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007417, test:0.000953 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007981, test:0.000417 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007046, test:0.002222 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008064, test:0.000381 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008264, test:0.003199 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006730, test:0.001408 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007294, test:0.000528 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.012908, test:0.003264 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007464, test:0.001149 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007516, test:0.000471 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006562, test:0.000996 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007662, test:0.000415 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007706, test:0.001517 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007218, test:0.000528 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006950, test:0.002001 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005761, test:0.000437 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005790, test:0.000432 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005753, test:0.000449 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005690, test:0.000406 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005545, test:0.000453 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005586, test:0.000359 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005309, test:0.000361 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005993, test:0.000491 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005568, test:0.000535 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005460, test:0.000402 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005202, test:0.000390 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005554, test:0.000347 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006422, test:0.000378 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004963, test:0.000346 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005388, test:0.000517 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004769, test:0.000415 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004802, test:0.000343 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004681, test:0.000682 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005108, test:0.000652 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005291, test:0.000345 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005299, test:0.000468 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005004, test:0.000430 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005239, test:0.000384 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005915, test:0.000374 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005941, test:0.000456 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005671, test:0.000378 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[67/100] | loss train:0.006136, test:0.000334 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005528, test:0.000362 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005349, test:0.000339 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005268, test:0.000506 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.007227, test:0.000349 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005928, test:0.000334 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006928, test:0.000357 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005623, test:0.000416 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005230, test:0.000539 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005285, test:0.000378 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004865, test:0.000342 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005007, test:0.000308 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004934, test:0.000524 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005220, test:0.000308 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004971, test:0.000317 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005265, test:0.000322 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005380, test:0.000311 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004901, test:0.000305 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005178, test:0.000312 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004951, test:0.000304 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004551, test:0.000339 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006100, test:0.000300 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005212, test:0.000300 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005268, test:0.000309 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005988, test:0.000308 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005928, test:0.000290 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005539, test:0.000318 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005028, test:0.000342 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004798, test:0.000307 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006622, test:0.000317 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004866, test:0.000339 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005117, test:0.000304 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005282, test:0.000330 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004902, test:0.000322 | lr:0.000100\n",
      "Mean absolute error:  1.7896047383427303\n",
      "Root mean squared error:  5.858597716292121\n",
      "Epoch[1/100] | loss train:0.057956, test:0.000487 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012934, test:0.000385 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009873, test:0.000279 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011947, test:0.000328 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.015600, test:0.002723 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.018796, test:0.001758 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010856, test:0.001084 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008423, test:0.000396 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008548, test:0.000924 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009040, test:0.009042 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.012305, test:0.000333 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009877, test:0.003468 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.006514, test:0.000513 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008722, test:0.001620 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.013476, test:0.003151 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010034, test:0.001533 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008655, test:0.001988 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007504, test:0.002095 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.010222, test:0.001514 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008277, test:0.000488 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008894, test:0.000624 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008729, test:0.000913 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009944, test:0.000617 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008705, test:0.002037 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007580, test:0.000689 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007324, test:0.000332 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007951, test:0.000382 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006766, test:0.001065 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010987, test:0.001494 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010953, test:0.000745 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008168, test:0.000809 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008372, test:0.001195 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.010167, test:0.000655 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009823, test:0.002583 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009136, test:0.001647 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008466, test:0.000527 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.010558, test:0.001954 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009516, test:0.000990 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007249, test:0.000510 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007704, test:0.003480 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005960, test:0.000399 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005701, test:0.000577 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007130, test:0.000817 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005542, test:0.000451 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005881, test:0.000577 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005572, test:0.000362 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005708, test:0.000350 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006144, test:0.000368 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006171, test:0.000395 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.015335, test:0.000386 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006809, test:0.000381 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005429, test:0.000636 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006497, test:0.000358 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006049, test:0.000328 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006525, test:0.000320 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005378, test:0.000415 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005730, test:0.000954 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005727, test:0.000329 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005083, test:0.000476 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005387, test:0.000334 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005158, test:0.000340 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005481, test:0.000322 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005915, test:0.000338 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005682, test:0.000343 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005829, test:0.000351 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.008512, test:0.000341 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005483, test:0.000322 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005629, test:0.000324 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005688, test:0.000504 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005335, test:0.000633 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005255, test:0.000337 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005194, test:0.000403 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005226, test:0.000390 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005379, test:0.000449 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005811, test:0.000348 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005377, test:0.000507 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005486, test:0.000490 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005367, test:0.000322 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005383, test:0.000337 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004843, test:0.000719 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.008830, test:0.000333 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005628, test:0.000321 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005372, test:0.000308 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005434, test:0.000356 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005527, test:0.000328 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.007966, test:0.000323 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005046, test:0.000299 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005078, test:0.000334 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005962, test:0.000345 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005006, test:0.000314 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005076, test:0.000301 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[92/100] | loss train:0.005209, test:0.000337 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005158, test:0.000344 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005331, test:0.000326 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005540, test:0.000316 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006036, test:0.000319 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005234, test:0.000308 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005666, test:0.000370 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005465, test:0.000325 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006000, test:0.000327 | lr:0.000100\n",
      "Mean absolute error:  1.6661174601283701\n",
      "Root mean squared error:  5.78687574146491\n",
      "Epoch[1/100] | loss train:0.054995, test:0.001450 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011199, test:0.000712 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013511, test:0.000662 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010408, test:0.000744 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009927, test:0.000582 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009233, test:0.000677 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007621, test:0.000691 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009921, test:0.000553 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008711, test:0.004220 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008763, test:0.001578 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007516, test:0.004578 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009992, test:0.000610 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.012254, test:0.001126 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008850, test:0.000365 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007986, test:0.000349 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008381, test:0.000918 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008605, test:0.000539 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009355, test:0.000356 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008680, test:0.000860 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008224, test:0.002836 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007325, test:0.000460 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006882, test:0.000425 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009409, test:0.000952 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009947, test:0.002344 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007769, test:0.003458 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007535, test:0.001334 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008483, test:0.000468 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007083, test:0.001228 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007527, test:0.000621 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006883, test:0.000731 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009048, test:0.000880 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.010478, test:0.001915 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007598, test:0.000369 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008512, test:0.000508 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006952, test:0.000349 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007095, test:0.003786 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006815, test:0.001761 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007266, test:0.000303 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008139, test:0.002320 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008472, test:0.000931 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006120, test:0.000453 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005736, test:0.000367 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005361, test:0.000347 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005487, test:0.000463 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004864, test:0.000404 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005996, test:0.000318 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005470, test:0.000345 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005543, test:0.000532 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005499, test:0.000569 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005248, test:0.000351 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005311, test:0.000391 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006337, test:0.000357 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005064, test:0.000507 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005203, test:0.000339 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005522, test:0.000398 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005570, test:0.000702 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004703, test:0.000504 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006801, test:0.000358 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006632, test:0.000889 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.007368, test:0.000394 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005473, test:0.000370 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005447, test:0.000368 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.010574, test:0.000351 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005236, test:0.000404 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005045, test:0.000542 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005232, test:0.000346 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006160, test:0.000390 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005510, test:0.000319 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004884, test:0.000385 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004902, test:0.000330 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004885, test:0.000326 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005360, test:0.000341 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005329, test:0.000404 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006923, test:0.000393 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005228, test:0.000358 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005299, test:0.000322 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006000, test:0.000389 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005112, test:0.000312 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005262, test:0.000384 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005063, test:0.000320 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005130, test:0.000344 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005054, test:0.000350 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004901, test:0.000336 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005044, test:0.000321 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005131, test:0.000347 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005171, test:0.000334 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005147, test:0.000323 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004776, test:0.000346 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006139, test:0.000339 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.011767, test:0.000307 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005430, test:0.000332 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004959, test:0.000322 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004613, test:0.000337 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005885, test:0.000332 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004558, test:0.000302 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005058, test:0.000319 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005670, test:0.000306 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004698, test:0.000315 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004893, test:0.000311 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004838, test:0.000337 | lr:0.000100\n",
      "Mean absolute error:  1.694511772886931\n",
      "Root mean squared error:  5.790091660406437\n",
      "Epoch[1/100] | loss train:0.055579, test:0.000973 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.016609, test:0.002478 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010710, test:0.000401 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.018844, test:0.006094 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010875, test:0.000537 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010280, test:0.001216 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010736, test:0.000691 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008854, test:0.003530 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008103, test:0.000730 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010680, test:0.000493 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008438, test:0.002597 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008337, test:0.000575 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007885, test:0.000343 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008713, test:0.009579 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008501, test:0.001709 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/100] | loss train:0.007695, test:0.002043 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008326, test:0.000367 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007130, test:0.001333 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008587, test:0.000484 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007758, test:0.000472 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008160, test:0.000480 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007701, test:0.000396 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006487, test:0.003400 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007295, test:0.001763 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007525, test:0.000618 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008029, test:0.006260 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007641, test:0.000335 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007160, test:0.000970 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007769, test:0.000348 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006551, test:0.001005 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008760, test:0.000568 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007208, test:0.003497 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008572, test:0.001472 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006489, test:0.000513 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007865, test:0.005894 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008756, test:0.001915 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007244, test:0.000514 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.005971, test:0.000891 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006510, test:0.001091 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007539, test:0.004325 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005455, test:0.000439 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005160, test:0.000477 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005547, test:0.000399 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005153, test:0.000438 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005686, test:0.000379 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004886, test:0.000576 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005089, test:0.000402 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004775, test:0.000477 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004816, test:0.000448 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004985, test:0.000519 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005495, test:0.000393 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005540, test:0.000423 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004824, test:0.000361 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005767, test:0.000392 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005547, test:0.000387 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004847, test:0.000342 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005339, test:0.000335 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006986, test:0.000406 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004954, test:0.000337 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004988, test:0.000564 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005920, test:0.000303 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006260, test:0.000365 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005281, test:0.000417 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005076, test:0.000425 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005840, test:0.000339 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.008360, test:0.000421 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005011, test:0.000303 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005234, test:0.000360 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004865, test:0.000305 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004953, test:0.000522 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005526, test:0.000350 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005102, test:0.000684 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005631, test:0.000360 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005759, test:0.000386 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004971, test:0.000504 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006552, test:0.000350 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005527, test:0.000538 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005653, test:0.000339 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004968, test:0.000330 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005331, test:0.000347 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005224, test:0.000331 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004605, test:0.000302 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004893, test:0.000313 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004695, test:0.000328 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005230, test:0.000320 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005470, test:0.000340 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004998, test:0.000302 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004606, test:0.000351 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004733, test:0.000312 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004908, test:0.000296 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004934, test:0.000388 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004788, test:0.000319 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005199, test:0.000317 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005060, test:0.000304 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005627, test:0.000344 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005822, test:0.000352 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004923, test:0.000305 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004528, test:0.000307 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005369, test:0.000318 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004834, test:0.000326 | lr:0.000100\n",
      "Mean absolute error:  1.6646236836060202\n",
      "Root mean squared error:  5.779199432466746\n",
      "Epoch[1/100] | loss train:0.049745, test:0.000466 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.017991, test:0.001946 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012073, test:0.005717 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009688, test:0.001141 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010582, test:0.002465 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010289, test:0.003331 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010040, test:0.011985 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010691, test:0.001687 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008575, test:0.000623 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009679, test:0.000593 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009403, test:0.000454 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008174, test:0.001297 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008862, test:0.001347 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007001, test:0.002431 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008439, test:0.001350 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007683, test:0.000605 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007816, test:0.002024 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009966, test:0.003541 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008837, test:0.001120 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.012565, test:0.002151 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007926, test:0.000741 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009003, test:0.000893 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009265, test:0.003350 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008409, test:0.000884 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006976, test:0.001141 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007644, test:0.000573 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009439, test:0.000998 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007665, test:0.000358 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007792, test:0.000414 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008035, test:0.000722 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006161, test:0.001055 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007816, test:0.000333 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006975, test:0.000744 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008476, test:0.001256 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007864, test:0.000494 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007372, test:0.002677 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007292, test:0.000362 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006676, test:0.001118 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007216, test:0.001881 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007292, test:0.000941 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[41/100] | loss train:0.005819, test:0.000431 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005420, test:0.000322 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006478, test:0.000356 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005483, test:0.000769 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005321, test:0.000374 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005957, test:0.000341 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005263, test:0.000342 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005330, test:0.000346 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004885, test:0.000347 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005432, test:0.000364 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006122, test:0.000323 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005101, test:0.000310 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005016, test:0.000299 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005152, test:0.000378 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005304, test:0.000409 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005359, test:0.000452 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005405, test:0.000364 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005576, test:0.000327 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006391, test:0.000325 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005926, test:0.000386 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005273, test:0.000316 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005079, test:0.000330 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005058, test:0.000461 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004995, test:0.000372 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005394, test:0.000368 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004917, test:0.000277 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004960, test:0.000306 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004954, test:0.000336 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005436, test:0.000323 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005770, test:0.000274 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005544, test:0.000288 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005633, test:0.000322 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.010221, test:0.000290 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006065, test:0.000296 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004810, test:0.000318 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005041, test:0.000306 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005269, test:0.000307 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005255, test:0.000341 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004930, test:0.000411 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005175, test:0.000301 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004860, test:0.000294 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004858, test:0.000298 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005440, test:0.000342 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005425, test:0.000360 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004805, test:0.000346 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004758, test:0.000311 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005036, test:0.000306 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004848, test:0.000340 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005333, test:0.000308 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004765, test:0.000295 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004611, test:0.000330 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005071, test:0.000290 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005046, test:0.000324 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005090, test:0.000352 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.007482, test:0.000316 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005555, test:0.000302 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004631, test:0.000340 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005441, test:0.000318 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005774, test:0.000280 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006742, test:0.000284 | lr:0.000100\n",
      "Mean absolute error:  1.682423090576811\n",
      "Root mean squared error:  5.78208428600543\n",
      "Epoch[1/100] | loss train:0.046620, test:0.006528 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014361, test:0.002207 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012285, test:0.000385 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008346, test:0.000453 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009862, test:0.000358 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008905, test:0.003818 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009590, test:0.000820 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009672, test:0.000396 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008575, test:0.001560 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007945, test:0.002629 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007569, test:0.002467 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008175, test:0.001648 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008248, test:0.000414 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007237, test:0.003133 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008889, test:0.001433 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008722, test:0.000707 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008155, test:0.001952 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007633, test:0.000455 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009007, test:0.000405 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008346, test:0.002109 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007847, test:0.000460 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008132, test:0.000433 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006898, test:0.000544 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007040, test:0.000354 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006640, test:0.000419 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007628, test:0.000365 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008689, test:0.000561 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008436, test:0.002028 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007292, test:0.001700 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006665, test:0.000399 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006539, test:0.000480 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007915, test:0.001397 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007848, test:0.000455 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007493, test:0.002072 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007757, test:0.000396 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007102, test:0.000700 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006562, test:0.000423 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007034, test:0.000921 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007838, test:0.001109 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006296, test:0.000713 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005929, test:0.000323 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005516, test:0.000304 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006949, test:0.000379 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006850, test:0.000452 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005833, test:0.000317 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005307, test:0.000318 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006061, test:0.000330 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005247, test:0.000543 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005297, test:0.000312 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005120, test:0.000315 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005026, test:0.000418 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005496, test:0.000297 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004906, test:0.000324 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005647, test:0.000330 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006201, test:0.000311 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.007126, test:0.000359 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006559, test:0.000300 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005602, test:0.000323 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006594, test:0.000280 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005615, test:0.000295 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006557, test:0.000312 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005456, test:0.000339 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005066, test:0.000293 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005125, test:0.000472 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004689, test:0.000330 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[66/100] | loss train:0.005310, test:0.001028 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005391, test:0.000553 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.007276, test:0.000281 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005279, test:0.000347 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004657, test:0.000580 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005437, test:0.000449 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005808, test:0.000392 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005365, test:0.000308 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005377, test:0.000342 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006675, test:0.000307 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006133, test:0.000314 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004985, test:0.000299 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005019, test:0.000378 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004837, test:0.000371 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005152, test:0.000328 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005023, test:0.000312 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005718, test:0.000326 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004914, test:0.000295 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004905, test:0.000333 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004806, test:0.000365 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005177, test:0.000302 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006008, test:0.000291 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004507, test:0.000324 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004790, test:0.000330 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004890, test:0.000297 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004770, test:0.000306 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005226, test:0.000313 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005327, test:0.000291 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005073, test:0.000313 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005210, test:0.000324 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004891, test:0.000319 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005070, test:0.000292 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005077, test:0.000307 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.007276, test:0.000328 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005017, test:0.000356 | lr:0.000100\n",
      "Mean absolute error:  1.7892778325168397\n",
      "Root mean squared error:  5.858950885971017\n",
      "Epoch[1/100] | loss train:0.055478, test:0.013951 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.015430, test:0.001468 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009915, test:0.001711 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008962, test:0.000317 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010751, test:0.000658 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011093, test:0.002192 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009283, test:0.000480 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009409, test:0.001663 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009455, test:0.001700 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010281, test:0.000560 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009044, test:0.002005 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007919, test:0.000429 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008002, test:0.003179 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007386, test:0.000563 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007664, test:0.001013 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009026, test:0.001048 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007501, test:0.000377 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008821, test:0.000777 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008844, test:0.005680 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009040, test:0.003636 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009530, test:0.003718 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008396, test:0.001282 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009358, test:0.000488 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008410, test:0.000346 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.014090, test:0.001775 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008841, test:0.000527 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006468, test:0.000380 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007130, test:0.000344 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008178, test:0.000386 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007054, test:0.000320 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007442, test:0.000519 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009161, test:0.000541 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006615, test:0.002066 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008569, test:0.001073 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007673, test:0.000515 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.010737, test:0.000552 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.010238, test:0.003612 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007420, test:0.000500 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006805, test:0.000578 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007271, test:0.000723 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005992, test:0.000557 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007428, test:0.000849 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006158, test:0.000838 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005254, test:0.000403 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006052, test:0.000398 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005578, test:0.000374 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005409, test:0.000406 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005770, test:0.000597 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005189, test:0.000404 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006956, test:0.000504 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005150, test:0.000369 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.008289, test:0.000366 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006511, test:0.000444 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006177, test:0.000371 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006636, test:0.000583 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006009, test:0.000343 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005440, test:0.000340 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005644, test:0.000366 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.008256, test:0.000376 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005360, test:0.000351 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005409, test:0.000405 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005242, test:0.000361 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005405, test:0.000354 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005185, test:0.000443 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005427, test:0.000353 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006212, test:0.000358 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005133, test:0.000341 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005852, test:0.000335 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005570, test:0.000414 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005701, test:0.000329 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005646, test:0.000399 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005757, test:0.000399 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005374, test:0.000364 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005025, test:0.000368 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005257, test:0.000909 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005345, test:0.000414 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006116, test:0.000367 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006596, test:0.000366 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.009625, test:0.000428 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005933, test:0.000319 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005314, test:0.000356 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005446, test:0.000319 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005878, test:0.000328 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005783, test:0.000315 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005359, test:0.000358 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005316, test:0.000326 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005417, test:0.000312 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004939, test:0.000318 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.007457, test:0.000311 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006556, test:0.000308 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[91/100] | loss train:0.005125, test:0.000363 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005533, test:0.000333 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006304, test:0.000340 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004840, test:0.000318 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005345, test:0.000368 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005729, test:0.000325 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005313, test:0.000326 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005584, test:0.000356 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005017, test:0.000352 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004801, test:0.000337 | lr:0.000100\n",
      "Mean absolute error:  1.7226743388287138\n",
      "Root mean squared error:  5.809953597630273\n",
      "Epoch[1/100] | loss train:0.045459, test:0.006818 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.015562, test:0.000477 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010387, test:0.001259 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009648, test:0.003475 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011408, test:0.001174 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012271, test:0.002775 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.013909, test:0.000347 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008204, test:0.010238 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009814, test:0.002460 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007622, test:0.000986 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009615, test:0.000540 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009162, test:0.001013 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009458, test:0.000580 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008250, test:0.001197 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008825, test:0.000444 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008244, test:0.004112 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007337, test:0.000679 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008492, test:0.001032 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009210, test:0.002648 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007436, test:0.002976 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008557, test:0.000394 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009379, test:0.000395 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009350, test:0.000344 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007889, test:0.000532 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008151, test:0.000419 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007445, test:0.000609 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007537, test:0.000995 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008460, test:0.001845 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008194, test:0.000404 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010677, test:0.000664 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008718, test:0.000560 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007271, test:0.001359 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007791, test:0.000855 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006583, test:0.000955 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008241, test:0.001626 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007350, test:0.000707 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007285, test:0.001474 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008373, test:0.000558 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007595, test:0.001911 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008728, test:0.001933 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006190, test:0.000367 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005781, test:0.000331 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005593, test:0.000342 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005970, test:0.000341 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005626, test:0.000296 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005423, test:0.000327 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005555, test:0.000372 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006279, test:0.000451 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004939, test:0.000693 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005072, test:0.000319 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005365, test:0.000321 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.007542, test:0.000333 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004997, test:0.000298 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005941, test:0.000363 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.008661, test:0.000415 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005105, test:0.000435 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005194, test:0.000312 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005821, test:0.000307 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004960, test:0.000426 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005244, test:0.000856 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005071, test:0.000304 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005611, test:0.000397 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006870, test:0.000300 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005418, test:0.000335 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006636, test:0.000346 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005661, test:0.000334 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006280, test:0.000322 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005896, test:0.000417 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005939, test:0.000518 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006384, test:0.000290 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005052, test:0.000502 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005575, test:0.000318 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005357, test:0.000379 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006640, test:0.000319 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005609, test:0.000372 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005574, test:0.000620 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005541, test:0.000500 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005571, test:0.000310 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005296, test:0.000390 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006322, test:0.000399 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005046, test:0.000358 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005926, test:0.000346 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005257, test:0.000349 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005067, test:0.000386 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005148, test:0.000326 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004881, test:0.000321 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005759, test:0.000313 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.009032, test:0.000345 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004959, test:0.000318 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005551, test:0.000339 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006571, test:0.000320 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005881, test:0.000316 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005665, test:0.000291 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004873, test:0.000302 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.006717, test:0.000319 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004971, test:0.000300 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005384, test:0.000316 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.007643, test:0.000334 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005354, test:0.000304 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005655, test:0.000308 | lr:0.000100\n",
      "Mean absolute error:  1.6971241448148244\n",
      "Root mean squared error:  5.795154649776935\n",
      "Epoch[1/100] | loss train:0.047548, test:0.001392 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009860, test:0.007402 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010378, test:0.000550 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011321, test:0.001308 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012861, test:0.000338 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010159, test:0.000932 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010759, test:0.001407 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008509, test:0.001398 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.021608, test:0.003159 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010776, test:0.000443 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007911, test:0.001218 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008980, test:0.000488 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008829, test:0.001181 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008849, test:0.000533 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/100] | loss train:0.009064, test:0.000473 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007947, test:0.003538 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008604, test:0.003734 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008221, test:0.000456 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009116, test:0.000756 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009950, test:0.003003 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008029, test:0.000658 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010006, test:0.002033 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009551, test:0.000417 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.012711, test:0.000843 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.011748, test:0.003234 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009838, test:0.000588 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007657, test:0.000382 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007143, test:0.001308 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007898, test:0.005278 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008442, test:0.000533 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007987, test:0.000501 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007395, test:0.001908 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007181, test:0.000557 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008127, test:0.003695 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007243, test:0.000877 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007876, test:0.000697 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006986, test:0.001088 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007757, test:0.000351 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007270, test:0.001214 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008196, test:0.000678 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005835, test:0.000463 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006383, test:0.000426 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005001, test:0.000418 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005326, test:0.000748 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005637, test:0.000430 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005112, test:0.000413 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007883, test:0.000367 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005975, test:0.000448 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005614, test:0.000368 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005440, test:0.000368 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006317, test:0.000338 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005354, test:0.000460 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005630, test:0.000743 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005367, test:0.000425 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.008051, test:0.000659 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005345, test:0.000361 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006544, test:0.000556 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005175, test:0.000330 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005242, test:0.000575 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005813, test:0.000361 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005305, test:0.000648 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005422, test:0.000592 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005391, test:0.000335 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005670, test:0.000305 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005783, test:0.000441 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004982, test:0.000343 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.012208, test:0.000581 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005623, test:0.000342 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.007177, test:0.000334 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005135, test:0.000362 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004858, test:0.000347 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005570, test:0.000443 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005359, test:0.000362 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005888, test:0.000529 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005518, test:0.000356 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005853, test:0.000474 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005114, test:0.000519 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004920, test:0.000395 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004876, test:0.000310 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005255, test:0.000315 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005720, test:0.000335 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004642, test:0.000346 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006317, test:0.000317 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.006632, test:0.000318 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005169, test:0.000317 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004630, test:0.000315 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005645, test:0.000322 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005003, test:0.000370 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005593, test:0.000345 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005137, test:0.000310 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005346, test:0.000309 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005048, test:0.000318 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004739, test:0.000342 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005104, test:0.000343 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005089, test:0.000312 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005427, test:0.000320 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.010394, test:0.000353 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005165, test:0.000345 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005667, test:0.000310 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005817, test:0.000303 | lr:0.000100\n",
      "Mean absolute error:  1.6802095247893534\n",
      "Root mean squared error:  5.806809174052072\n",
      "Epoch[1/100] | loss train:0.058036, test:0.000981 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.019554, test:0.000472 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013594, test:0.000316 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012575, test:0.000368 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011330, test:0.000331 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011857, test:0.007278 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009475, test:0.000384 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008725, test:0.000544 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007950, test:0.003223 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008633, test:0.002443 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007750, test:0.001727 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009020, test:0.009774 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.013781, test:0.001839 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009078, test:0.000405 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007866, test:0.000468 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006872, test:0.001502 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.011939, test:0.019114 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009694, test:0.002160 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.011997, test:0.005576 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008808, test:0.000577 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007678, test:0.000563 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008873, test:0.002254 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008023, test:0.003048 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007422, test:0.003433 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008453, test:0.000542 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007322, test:0.001190 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007212, test:0.000626 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007823, test:0.000867 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008209, test:0.001981 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008051, test:0.000615 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007833, test:0.000372 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007576, test:0.001576 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006717, test:0.000805 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007360, test:0.000489 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006716, test:0.000390 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007828, test:0.000519 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007664, test:0.001273 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008062, test:0.000765 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006967, test:0.002089 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/100] | loss train:0.008545, test:0.005095 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006648, test:0.000351 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005215, test:0.000609 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005619, test:0.000389 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005268, test:0.000410 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004833, test:0.000442 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006527, test:0.000332 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005258, test:0.000370 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005416, test:0.000429 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006483, test:0.000437 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005298, test:0.000680 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005465, test:0.000350 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005496, test:0.000468 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005551, test:0.000382 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005076, test:0.000793 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005775, test:0.000372 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005393, test:0.000422 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005385, test:0.000355 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005158, test:0.000369 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005554, test:0.000371 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005568, test:0.000425 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005060, test:0.000419 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005290, test:0.000375 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005125, test:0.000407 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006165, test:0.000454 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006568, test:0.000794 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005038, test:0.000337 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005365, test:0.000307 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005615, test:0.000581 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005439, test:0.000366 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005237, test:0.000321 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005965, test:0.000323 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005001, test:0.000387 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005543, test:0.000376 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004754, test:0.000754 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006248, test:0.000582 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005392, test:0.000387 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005080, test:0.000502 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005576, test:0.000478 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005536, test:0.000373 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.007350, test:0.000372 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005464, test:0.000322 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004917, test:0.000343 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005270, test:0.000344 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005534, test:0.000364 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005299, test:0.000351 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005087, test:0.000357 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005542, test:0.000343 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006720, test:0.000333 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005000, test:0.000319 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005754, test:0.000332 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005811, test:0.000287 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005226, test:0.000348 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.007299, test:0.000373 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004843, test:0.000332 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004781, test:0.000323 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005714, test:0.000305 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004852, test:0.000331 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005988, test:0.000346 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.008115, test:0.000354 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005793, test:0.000342 | lr:0.000100\n",
      "Mean absolute error:  1.6877274053195332\n",
      "Root mean squared error:  5.796930942552144\n",
      "Epoch[1/100] | loss train:0.058714, test:0.000623 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011713, test:0.000347 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012748, test:0.000372 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011375, test:0.000750 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009744, test:0.002594 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011189, test:0.001622 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009816, test:0.004136 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007866, test:0.001310 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007470, test:0.001051 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010769, test:0.001516 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008141, test:0.002842 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008995, test:0.001261 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008364, test:0.001461 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007545, test:0.000707 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007320, test:0.000343 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006888, test:0.000513 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009477, test:0.000654 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008436, test:0.000460 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.013111, test:0.002625 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008882, test:0.000527 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007828, test:0.000393 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.016878, test:0.000904 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009783, test:0.009872 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007863, test:0.002032 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007582, test:0.002783 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007518, test:0.000717 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006930, test:0.000427 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006903, test:0.003191 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007956, test:0.001028 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006646, test:0.000472 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007255, test:0.000955 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007471, test:0.001701 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007020, test:0.001041 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007257, test:0.000638 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009190, test:0.003700 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007678, test:0.001165 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007363, test:0.000437 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006993, test:0.000544 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006509, test:0.000904 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009616, test:0.002168 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006537, test:0.000376 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005968, test:0.000369 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005552, test:0.000339 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005706, test:0.000448 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005223, test:0.000700 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005856, test:0.000322 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004976, test:0.000345 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005277, test:0.000331 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005626, test:0.000570 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005203, test:0.000517 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005206, test:0.000408 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005030, test:0.000358 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.007724, test:0.000436 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005311, test:0.000334 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005098, test:0.000379 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005388, test:0.000614 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.007343, test:0.000363 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005196, test:0.000367 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005454, test:0.000313 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.007157, test:0.000317 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006244, test:0.000299 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005039, test:0.000313 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004842, test:0.000374 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006532, test:0.000810 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[65/100] | loss train:0.006484, test:0.000419 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005732, test:0.000330 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005731, test:0.000340 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004942, test:0.000396 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005301, test:0.000321 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005489, test:0.000612 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005520, test:0.000352 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005090, test:0.000708 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.009509, test:0.000414 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005401, test:0.000342 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005363, test:0.000377 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005116, test:0.000474 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006114, test:0.000327 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005219, test:0.000326 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005378, test:0.000414 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005297, test:0.000492 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006196, test:0.000329 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006086, test:0.000364 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004935, test:0.000324 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004868, test:0.000308 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004944, test:0.000322 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004614, test:0.000359 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005080, test:0.000387 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005302, test:0.000329 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005734, test:0.000348 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004712, test:0.000320 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005042, test:0.000351 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005102, test:0.000360 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004764, test:0.000344 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.007701, test:0.000328 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005463, test:0.000312 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005680, test:0.000321 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005704, test:0.000324 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004477, test:0.000340 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.006050, test:0.000367 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005055, test:0.000304 | lr:0.000100\n",
      "Mean absolute error:  1.758324587599815\n",
      "Root mean squared error:  5.80454294692799\n",
      "Epoch[1/100] | loss train:0.047521, test:0.003496 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014577, test:0.003589 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010800, test:0.000684 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009676, test:0.001364 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009169, test:0.000460 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009012, test:0.000316 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.012880, test:0.010028 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009911, test:0.001345 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009345, test:0.002896 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009482, test:0.000436 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007135, test:0.000339 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.006568, test:0.002308 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007455, test:0.000312 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007264, test:0.001512 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007575, test:0.002659 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009379, test:0.000812 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007442, test:0.001576 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008711, test:0.000381 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006627, test:0.000478 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006077, test:0.002022 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008028, test:0.001911 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009244, test:0.002439 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007413, test:0.001653 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006716, test:0.000393 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007022, test:0.000530 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.005744, test:0.000950 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009654, test:0.002757 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006836, test:0.000386 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007807, test:0.002328 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008347, test:0.003841 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006888, test:0.000634 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006956, test:0.003680 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007542, test:0.000377 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009209, test:0.002626 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008285, test:0.000505 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006678, test:0.001286 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009402, test:0.000527 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.010547, test:0.000405 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.009035, test:0.000414 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006151, test:0.000895 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007881, test:0.000307 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005214, test:0.000281 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005346, test:0.000318 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005659, test:0.000385 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005164, test:0.000431 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004944, test:0.000315 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006307, test:0.000277 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005041, test:0.000555 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005156, test:0.000283 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005831, test:0.000381 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004782, test:0.000315 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005125, test:0.000318 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006816, test:0.000446 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004925, test:0.000383 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005792, test:0.000294 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004918, test:0.000291 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004802, test:0.000532 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004646, test:0.000320 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005294, test:0.000283 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005865, test:0.000281 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005290, test:0.000327 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004529, test:0.000360 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004774, test:0.000551 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004871, test:0.000290 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004902, test:0.000353 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005108, test:0.000279 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006420, test:0.000296 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004705, test:0.000306 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005685, test:0.000415 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005767, test:0.000488 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004787, test:0.000287 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005913, test:0.000305 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004801, test:0.000275 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005087, test:0.000410 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005002, test:0.000267 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005091, test:0.000296 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005260, test:0.000308 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005026, test:0.000352 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.007170, test:0.000354 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005409, test:0.000316 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005918, test:0.000307 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005886, test:0.000313 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005093, test:0.000280 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005029, test:0.000280 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004618, test:0.000288 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005060, test:0.000300 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004758, test:0.000284 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004993, test:0.000280 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004697, test:0.000314 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[90/100] | loss train:0.004794, test:0.000300 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004758, test:0.000320 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005389, test:0.000295 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004667, test:0.000287 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004767, test:0.000299 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005694, test:0.000298 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006529, test:0.000332 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005201, test:0.000282 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004498, test:0.000293 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004917, test:0.000289 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005141, test:0.000329 | lr:0.000100\n",
      "Mean absolute error:  1.7264733187523882\n",
      "Root mean squared error:  5.794043012336733\n",
      "Epoch[1/100] | loss train:0.049850, test:0.000672 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009988, test:0.001753 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011833, test:0.002980 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008747, test:0.000863 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.016179, test:0.002503 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009870, test:0.000365 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008161, test:0.000404 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007971, test:0.000566 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010595, test:0.000458 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011658, test:0.003525 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011361, test:0.000334 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007733, test:0.000830 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.012926, test:0.000401 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008217, test:0.001690 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008638, test:0.000641 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007128, test:0.000437 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007002, test:0.001399 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006832, test:0.002009 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009657, test:0.000692 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007258, test:0.001446 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006459, test:0.000672 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008335, test:0.000986 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007374, test:0.000341 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008029, test:0.000417 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.005759, test:0.000293 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006727, test:0.000655 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008445, test:0.005075 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007334, test:0.004524 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007134, test:0.000412 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008342, test:0.002003 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007741, test:0.003504 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006486, test:0.000405 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006534, test:0.000439 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006947, test:0.000845 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009857, test:0.001239 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007398, test:0.000521 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006674, test:0.000723 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006743, test:0.000951 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006076, test:0.001184 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007093, test:0.001346 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005779, test:0.000364 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.009034, test:0.000586 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005211, test:0.000318 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006321, test:0.000314 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005041, test:0.000349 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005288, test:0.000452 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005231, test:0.000333 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004922, test:0.000297 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005175, test:0.000355 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.007856, test:0.001427 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005437, test:0.000329 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006368, test:0.000354 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.007635, test:0.000317 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005429, test:0.000303 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005021, test:0.000354 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006069, test:0.000309 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006897, test:0.000352 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005777, test:0.000408 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006329, test:0.000305 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005429, test:0.000415 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005605, test:0.000314 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004675, test:0.000306 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004629, test:0.000355 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005281, test:0.000298 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005470, test:0.000309 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005054, test:0.000344 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005533, test:0.000290 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006992, test:0.000318 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004839, test:0.000298 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005561, test:0.000327 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005255, test:0.000499 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004875, test:0.000323 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004983, test:0.000323 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005775, test:0.000341 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004810, test:0.000461 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005499, test:0.000538 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004780, test:0.000313 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004873, test:0.000324 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004812, test:0.000661 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005191, test:0.000284 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005650, test:0.000297 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004455, test:0.000311 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005229, test:0.000312 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004671, test:0.000322 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004722, test:0.000302 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004602, test:0.000324 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005036, test:0.000282 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005290, test:0.000289 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005100, test:0.000275 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004772, test:0.000355 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005318, test:0.000285 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005182, test:0.000312 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004639, test:0.000295 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004647, test:0.000292 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004829, test:0.000295 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004859, test:0.000294 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004807, test:0.000303 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005564, test:0.000325 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.006097, test:0.000287 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005553, test:0.000292 | lr:0.000100\n",
      "Mean absolute error:  1.699301589708376\n",
      "Root mean squared error:  5.774994575270166\n",
      "Epoch[1/100] | loss train:0.051436, test:0.001522 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013784, test:0.001038 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011196, test:0.000950 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009764, test:0.002873 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008389, test:0.004415 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008793, test:0.000625 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008705, test:0.001835 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009861, test:0.002699 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008904, test:0.001690 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011789, test:0.005121 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009347, test:0.000739 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007094, test:0.000573 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008029, test:0.000433 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14/100] | loss train:0.008418, test:0.001157 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.016817, test:0.002444 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.011219, test:0.000415 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007184, test:0.001167 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009346, test:0.000384 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007306, test:0.001709 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009272, test:0.001375 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007134, test:0.001278 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006767, test:0.000471 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006651, test:0.001089 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007052, test:0.001199 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006940, test:0.000704 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007794, test:0.005797 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007510, test:0.000318 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008257, test:0.001762 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008189, test:0.001794 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006398, test:0.000873 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008157, test:0.000387 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006697, test:0.000379 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007748, test:0.001453 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006796, test:0.001159 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007155, test:0.002256 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006818, test:0.002018 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007994, test:0.000754 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006310, test:0.000379 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007836, test:0.000752 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006041, test:0.000352 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007290, test:0.000351 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005339, test:0.000463 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005537, test:0.000327 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005834, test:0.000363 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005401, test:0.000446 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005515, test:0.000355 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005344, test:0.000390 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006574, test:0.000435 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004913, test:0.000371 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004851, test:0.000348 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005035, test:0.000373 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005255, test:0.000499 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005606, test:0.000476 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005979, test:0.000634 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004940, test:0.000338 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004898, test:0.000504 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005605, test:0.000362 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005056, test:0.000360 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.007075, test:0.000358 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005074, test:0.000486 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005318, test:0.000353 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006341, test:0.000499 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005098, test:0.000331 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005886, test:0.000392 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005134, test:0.000401 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005040, test:0.000461 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005334, test:0.000319 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006191, test:0.000335 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005186, test:0.000318 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004796, test:0.000390 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004945, test:0.000354 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005805, test:0.000304 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005042, test:0.000374 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005685, test:0.000295 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005033, test:0.000338 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005008, test:0.000310 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005002, test:0.000335 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006404, test:0.000687 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004906, test:0.000558 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005143, test:0.000470 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005006, test:0.000338 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005018, test:0.000305 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.013165, test:0.000312 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005392, test:0.000345 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004868, test:0.000309 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005234, test:0.000316 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006165, test:0.000317 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004845, test:0.000294 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004752, test:0.000314 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005061, test:0.000334 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004761, test:0.000324 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005220, test:0.000310 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004811, test:0.000316 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004980, test:0.000310 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004884, test:0.000320 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004925, test:0.000328 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005053, test:0.000312 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005898, test:0.000310 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004914, test:0.000304 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005462, test:0.000304 | lr:0.000100\n",
      "Mean absolute error:  1.8243185124036634\n",
      "Root mean squared error:  5.862952321585757\n",
      "Epoch[1/100] | loss train:0.041892, test:0.002910 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011811, test:0.003213 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008734, test:0.000556 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009501, test:0.004163 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009961, test:0.000770 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009038, test:0.005351 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009059, test:0.000524 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010765, test:0.000962 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011155, test:0.001898 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008523, test:0.000336 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007316, test:0.000455 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.006320, test:0.000399 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010006, test:0.000551 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008731, test:0.003941 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008893, test:0.000363 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007381, test:0.000490 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008147, test:0.001628 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010125, test:0.002236 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008284, test:0.000631 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006756, test:0.003154 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007534, test:0.000683 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008550, test:0.001450 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007677, test:0.000832 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007551, test:0.002628 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008601, test:0.000581 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006973, test:0.000981 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007584, test:0.000425 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008213, test:0.000811 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010425, test:0.000597 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008195, test:0.000859 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007621, test:0.001892 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006631, test:0.000413 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008042, test:0.000308 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007090, test:0.000292 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006788, test:0.000747 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007615, test:0.000525 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009558, test:0.000745 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007246, test:0.001554 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[39/100] | loss train:0.006769, test:0.001566 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007079, test:0.000521 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005582, test:0.000369 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005031, test:0.000367 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005617, test:0.000311 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006407, test:0.000317 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005204, test:0.000350 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006182, test:0.000330 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007445, test:0.000405 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005337, test:0.000597 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005075, test:0.000347 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005043, test:0.000370 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005685, test:0.000314 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005580, test:0.000369 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005353, test:0.000447 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006048, test:0.000317 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.008694, test:0.000342 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006418, test:0.000430 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005072, test:0.000299 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006543, test:0.000340 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006072, test:0.000475 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005453, test:0.000373 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005525, test:0.000338 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005897, test:0.000532 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004667, test:0.000386 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006055, test:0.000296 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005104, test:0.000348 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004985, test:0.000329 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004923, test:0.000448 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004882, test:0.000345 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005290, test:0.000305 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005743, test:0.000339 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005052, test:0.000303 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004960, test:0.000311 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004962, test:0.000299 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005210, test:0.000433 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005533, test:0.000288 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.008291, test:0.000350 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005102, test:0.000363 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.007181, test:0.000354 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005617, test:0.000346 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005254, test:0.000461 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004781, test:0.000270 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005019, test:0.000317 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004519, test:0.000274 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.008160, test:0.000305 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005022, test:0.000279 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005378, test:0.000282 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.009149, test:0.000293 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004908, test:0.000295 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004848, test:0.000280 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004760, test:0.000294 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005065, test:0.000345 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004424, test:0.000305 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005037, test:0.000320 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005522, test:0.000300 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005350, test:0.000301 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005418, test:0.000375 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005596, test:0.000307 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004992, test:0.000327 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005486, test:0.000321 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.007473, test:0.000292 | lr:0.000100\n",
      "Mean absolute error:  1.7257621521183308\n",
      "Root mean squared error:  5.791538141650061\n",
      "Epoch[1/100] | loss train:0.045570, test:0.000732 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009835, test:0.003507 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008891, test:0.000361 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008830, test:0.000399 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008854, test:0.000311 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008026, test:0.000655 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008321, test:0.001274 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009664, test:0.000707 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008451, test:0.003876 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009120, test:0.000370 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007872, test:0.001190 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008951, test:0.007202 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010460, test:0.000353 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008811, test:0.000447 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007418, test:0.000472 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008527, test:0.000776 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007928, test:0.002266 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008264, test:0.002110 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007067, test:0.000350 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007510, test:0.000465 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007763, test:0.000797 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007648, test:0.000483 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007933, test:0.000600 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006726, test:0.003186 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006861, test:0.001336 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009957, test:0.000487 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008490, test:0.000563 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006667, test:0.000877 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007067, test:0.000345 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009183, test:0.000479 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006393, test:0.000828 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007841, test:0.002191 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007369, test:0.000513 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008100, test:0.001341 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006445, test:0.000485 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007765, test:0.000557 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007017, test:0.000893 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006334, test:0.002936 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.010689, test:0.000827 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007970, test:0.000883 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006357, test:0.000479 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005167, test:0.000456 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006915, test:0.000382 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004812, test:0.000409 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004952, test:0.000310 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005313, test:0.000299 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007098, test:0.000476 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006417, test:0.000314 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005119, test:0.000357 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005056, test:0.000551 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005119, test:0.000387 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004872, test:0.000513 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004634, test:0.000344 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006358, test:0.000326 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004654, test:0.000328 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004926, test:0.000554 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005070, test:0.000294 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005595, test:0.000320 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004887, test:0.000346 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004993, test:0.000327 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005753, test:0.000340 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004662, test:0.000301 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004882, test:0.000440 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[64/100] | loss train:0.005177, test:0.000383 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004776, test:0.000317 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005157, test:0.000266 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004762, test:0.000401 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005301, test:0.000418 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005105, test:0.000278 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005517, test:0.000290 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004918, test:0.000324 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005094, test:0.000299 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004958, test:0.000320 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005368, test:0.000316 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005205, test:0.000318 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004718, test:0.000298 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004972, test:0.000279 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005851, test:0.000283 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004852, test:0.000285 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005476, test:0.000335 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004827, test:0.000300 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004422, test:0.000289 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004426, test:0.000298 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004770, test:0.000292 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004869, test:0.000310 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004624, test:0.000270 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005460, test:0.000343 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004856, test:0.000342 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005810, test:0.000285 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004872, test:0.000321 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004881, test:0.000296 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005016, test:0.000298 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005161, test:0.000305 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004803, test:0.000287 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005588, test:0.000308 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005066, test:0.000315 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005631, test:0.000268 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004638, test:0.000284 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005276, test:0.000319 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.009253, test:0.000287 | lr:0.000100\n",
      "Mean absolute error:  1.6845102786530608\n",
      "Root mean squared error:  5.770720760266244\n",
      "Epoch[1/100] | loss train:0.074257, test:0.000958 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011705, test:0.006571 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011681, test:0.000438 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010878, test:0.000321 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007797, test:0.001911 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008734, test:0.001030 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009022, test:0.000357 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008567, test:0.002155 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008320, test:0.000574 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007734, test:0.000546 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009250, test:0.001239 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008894, test:0.003497 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008004, test:0.000464 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008049, test:0.002092 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007906, test:0.000680 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009156, test:0.002874 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006884, test:0.001572 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008504, test:0.000567 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007386, test:0.000605 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009352, test:0.000345 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007411, test:0.000375 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008603, test:0.001265 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007603, test:0.000412 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.018504, test:0.001165 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010404, test:0.000636 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007682, test:0.000398 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007009, test:0.005967 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008061, test:0.001252 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007071, test:0.000789 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008880, test:0.000403 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007019, test:0.000697 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006162, test:0.000521 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007169, test:0.000780 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.020704, test:0.000797 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008349, test:0.000355 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.012539, test:0.005705 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008289, test:0.000399 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007699, test:0.000352 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007453, test:0.000398 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009971, test:0.004493 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006517, test:0.000556 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005916, test:0.000368 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005992, test:0.000372 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004919, test:0.000389 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004990, test:0.000462 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005331, test:0.000355 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005646, test:0.000443 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005593, test:0.000466 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005987, test:0.000366 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005738, test:0.000424 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004898, test:0.000365 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005479, test:0.000456 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005529, test:0.000366 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004776, test:0.000412 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005806, test:0.000370 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005998, test:0.000457 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005329, test:0.000416 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005563, test:0.000570 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004772, test:0.000501 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005844, test:0.000360 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005004, test:0.000361 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005535, test:0.000339 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005076, test:0.000532 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005963, test:0.000355 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.008073, test:0.000357 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005483, test:0.000428 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005266, test:0.000326 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004805, test:0.000334 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005601, test:0.000512 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005113, test:0.000603 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005402, test:0.000380 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.008375, test:0.000359 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006808, test:0.000340 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005290, test:0.000313 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005854, test:0.000461 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005455, test:0.000666 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005167, test:0.000394 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005017, test:0.000317 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.008495, test:0.000304 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005633, test:0.000364 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004968, test:0.000369 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005124, test:0.000368 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004896, test:0.000339 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005315, test:0.000317 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004863, test:0.000322 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005088, test:0.000331 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004910, test:0.000314 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005948, test:0.000315 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[89/100] | loss train:0.006844, test:0.000321 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005116, test:0.000327 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004648, test:0.000313 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.006234, test:0.000317 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004895, test:0.000328 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005482, test:0.000441 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004811, test:0.000322 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005120, test:0.000389 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005410, test:0.000324 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006071, test:0.000312 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005173, test:0.000324 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004978, test:0.000334 | lr:0.000100\n",
      "Mean absolute error:  1.6820894109435827\n",
      "Root mean squared error:  5.7981110629930885\n",
      "Epoch[1/100] | loss train:0.067625, test:0.001263 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013043, test:0.000544 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010306, test:0.003300 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008864, test:0.000665 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007957, test:0.004977 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010053, test:0.000319 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010688, test:0.000521 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.014386, test:0.000513 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008717, test:0.002015 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008346, test:0.001494 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007547, test:0.003069 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008233, test:0.000533 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007557, test:0.000724 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.012769, test:0.001738 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008160, test:0.000994 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006939, test:0.002229 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010307, test:0.005677 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008564, test:0.002232 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007578, test:0.002209 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006715, test:0.000521 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008163, test:0.000722 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006839, test:0.002157 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007583, test:0.001181 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.012426, test:0.003137 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.011168, test:0.000679 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008487, test:0.000571 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006596, test:0.000497 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.010498, test:0.001881 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.009927, test:0.001160 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007839, test:0.001951 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007037, test:0.000678 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008446, test:0.000384 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006789, test:0.000370 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007313, test:0.001717 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009050, test:0.000461 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006805, test:0.000961 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007102, test:0.001419 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009149, test:0.001079 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007561, test:0.000885 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007172, test:0.000307 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005487, test:0.000471 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005967, test:0.000367 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007223, test:0.000378 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005000, test:0.000371 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005102, test:0.000289 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005676, test:0.000386 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005365, test:0.000280 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005666, test:0.000292 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005213, test:0.000398 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004916, test:0.000355 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005255, test:0.000328 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005188, test:0.000353 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005604, test:0.000667 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005043, test:0.000307 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005342, test:0.000320 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004863, test:0.000304 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005856, test:0.000316 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.009208, test:0.000322 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005517, test:0.000328 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006740, test:0.000278 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005437, test:0.000325 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004960, test:0.000349 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.009374, test:0.000311 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005219, test:0.000293 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006691, test:0.000401 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005032, test:0.000335 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005994, test:0.000287 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005457, test:0.000554 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005106, test:0.000380 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006479, test:0.000307 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005264, test:0.000389 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005119, test:0.000293 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005579, test:0.000421 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005723, test:0.000390 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005328, test:0.000445 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005414, test:0.000403 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005149, test:0.000331 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.008377, test:0.000317 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004594, test:0.000531 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006043, test:0.000496 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004778, test:0.000292 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.012605, test:0.000308 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004750, test:0.000295 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005604, test:0.000296 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005367, test:0.000326 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004751, test:0.000303 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004637, test:0.000288 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.007871, test:0.000312 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005025, test:0.000299 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004823, test:0.000287 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004900, test:0.000315 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004841, test:0.000319 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004944, test:0.000303 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.009610, test:0.000277 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005048, test:0.000293 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006530, test:0.000277 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005274, test:0.000307 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006001, test:0.000289 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005606, test:0.000298 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004803, test:0.000303 | lr:0.000100\n",
      "Mean absolute error:  1.678038975052078\n",
      "Root mean squared error:  5.771076069860987\n",
      "Epoch[1/100] | loss train:0.055379, test:0.000821 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013612, test:0.011290 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009884, test:0.013765 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009879, test:0.000470 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011097, test:0.000905 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009821, test:0.000279 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009472, test:0.000341 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009186, test:0.000389 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008567, test:0.000439 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.016960, test:0.004057 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011009, test:0.002131 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008039, test:0.000533 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/100] | loss train:0.009004, test:0.000390 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010794, test:0.001383 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008549, test:0.002802 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.013618, test:0.003205 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008425, test:0.000362 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.012293, test:0.004718 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009253, test:0.000878 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007879, test:0.000397 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006918, test:0.000390 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007235, test:0.001090 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.013314, test:0.000973 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008234, test:0.000349 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006869, test:0.001635 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007801, test:0.000885 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008148, test:0.000460 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006863, test:0.000716 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.011236, test:0.003709 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010491, test:0.000784 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007434, test:0.000527 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008545, test:0.000968 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006750, test:0.000360 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007041, test:0.000450 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008158, test:0.000594 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007991, test:0.003502 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008338, test:0.001122 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007074, test:0.000993 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008569, test:0.000794 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006284, test:0.000351 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006144, test:0.000623 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.004890, test:0.000442 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005537, test:0.000369 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005284, test:0.000373 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005408, test:0.000482 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005375, test:0.000385 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005593, test:0.000349 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.007695, test:0.000414 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005496, test:0.000658 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005163, test:0.000344 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006417, test:0.000337 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005052, test:0.000345 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004542, test:0.000337 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005245, test:0.000575 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005777, test:0.000312 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.008512, test:0.000325 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005464, test:0.000329 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005135, test:0.000320 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006267, test:0.000315 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.007070, test:0.000315 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005028, test:0.000400 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005385, test:0.000310 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004859, test:0.000298 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004710, test:0.000320 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005281, test:0.000361 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005026, test:0.000351 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004917, test:0.000348 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006485, test:0.000369 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005307, test:0.000328 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004934, test:0.000394 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005127, test:0.000358 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006122, test:0.000336 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004784, test:0.000337 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005633, test:0.000331 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005212, test:0.000291 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004837, test:0.000345 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005070, test:0.000332 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005982, test:0.000311 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005799, test:0.000463 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006740, test:0.000306 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005541, test:0.000307 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005250, test:0.000297 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005472, test:0.000301 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004979, test:0.000286 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.017197, test:0.000321 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005195, test:0.000334 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005118, test:0.000301 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004560, test:0.000315 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.008884, test:0.000314 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004723, test:0.000291 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004994, test:0.000303 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005533, test:0.000298 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004723, test:0.000356 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004719, test:0.000304 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005032, test:0.000333 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004784, test:0.000298 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.006889, test:0.000315 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005695, test:0.000301 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004562, test:0.000315 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006142, test:0.000333 | lr:0.000100\n",
      "Mean absolute error:  1.726828668267992\n",
      "Root mean squared error:  5.831732247404756\n",
      "Epoch[1/100] | loss train:0.042437, test:0.001519 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011179, test:0.000506 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010991, test:0.008228 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013942, test:0.000424 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009261, test:0.003846 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008411, test:0.001147 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008351, test:0.002223 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007865, test:0.000433 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007343, test:0.001339 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009567, test:0.000653 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.025910, test:0.000854 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008625, test:0.003842 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007822, test:0.001244 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.014583, test:0.001568 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009963, test:0.000410 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007344, test:0.000936 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.011210, test:0.000731 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007745, test:0.003047 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007334, test:0.000384 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007081, test:0.000646 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006734, test:0.000499 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007141, test:0.000643 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007704, test:0.002585 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006885, test:0.001134 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006895, test:0.002405 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008853, test:0.002286 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008536, test:0.001972 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007335, test:0.000694 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007437, test:0.000678 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007103, test:0.000609 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007337, test:0.000470 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007601, test:0.000775 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007634, test:0.000775 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.005966, test:0.000632 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006996, test:0.000591 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006868, test:0.002072 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008053, test:0.000621 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[38/100] | loss train:0.006154, test:0.000443 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006749, test:0.000786 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006925, test:0.000408 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005896, test:0.000305 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005850, test:0.000649 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005078, test:0.000312 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005199, test:0.000341 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004797, test:0.000322 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005914, test:0.000354 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005500, test:0.000358 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005738, test:0.000333 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005340, test:0.000328 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005565, test:0.000272 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.007431, test:0.000340 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005027, test:0.000483 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004856, test:0.000309 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005557, test:0.000313 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004779, test:0.000316 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004822, test:0.000594 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.008250, test:0.000408 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004775, test:0.000359 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005432, test:0.000482 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005163, test:0.000269 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004810, test:0.000290 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.012644, test:0.000375 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005008, test:0.000305 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004789, test:0.000455 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005008, test:0.000323 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005564, test:0.000322 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004861, test:0.000301 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005455, test:0.000358 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006730, test:0.000647 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005151, test:0.000274 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005209, test:0.000328 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005264, test:0.000302 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005903, test:0.000509 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.007680, test:0.000296 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.007182, test:0.000336 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005242, test:0.000340 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004956, test:0.000296 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005850, test:0.000279 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005261, test:0.000285 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004897, test:0.000481 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004757, test:0.000293 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005255, test:0.000300 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004925, test:0.000283 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005230, test:0.000301 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005027, test:0.000310 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005423, test:0.000281 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004675, test:0.000296 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005025, test:0.000333 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005075, test:0.000332 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005301, test:0.000285 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005429, test:0.000310 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004977, test:0.000289 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005352, test:0.000310 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004844, test:0.000301 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.006447, test:0.000304 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004545, test:0.000284 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.006435, test:0.000297 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004891, test:0.000294 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004542, test:0.000282 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006014, test:0.000306 | lr:0.000100\n",
      "Mean absolute error:  1.6907274325700963\n",
      "Root mean squared error:  5.773667223857236\n",
      "Epoch[1/100] | loss train:0.061442, test:0.003295 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.017346, test:0.012796 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011475, test:0.000757 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008333, test:0.000759 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011873, test:0.000516 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010481, test:0.000569 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007411, test:0.000295 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008786, test:0.000369 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008539, test:0.000546 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009381, test:0.000510 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.006724, test:0.000339 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008081, test:0.001043 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007161, test:0.001733 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007720, test:0.000725 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009085, test:0.000823 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009664, test:0.000899 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006198, test:0.000422 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007058, test:0.000378 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006605, test:0.001225 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007891, test:0.000403 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008627, test:0.000671 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006830, test:0.000438 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007430, test:0.002872 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007407, test:0.000690 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006872, test:0.000811 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009905, test:0.000593 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007506, test:0.000460 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008224, test:0.001269 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.016590, test:0.000754 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008003, test:0.000336 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007033, test:0.000563 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007912, test:0.000663 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007869, test:0.000377 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006201, test:0.000604 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009629, test:0.002575 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.021330, test:0.000823 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008990, test:0.000518 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006433, test:0.000334 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006976, test:0.000573 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006678, test:0.002074 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006141, test:0.000741 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006410, test:0.000491 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005351, test:0.000319 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005193, test:0.000437 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005169, test:0.000530 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005879, test:0.000313 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.008827, test:0.000616 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005566, test:0.000411 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007100, test:0.000373 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.007168, test:0.000323 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005494, test:0.000278 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006384, test:0.000280 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005063, test:0.000358 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005551, test:0.000286 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005113, test:0.000292 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005050, test:0.000362 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004957, test:0.000416 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005410, test:0.000357 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.007573, test:0.000442 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005724, test:0.000305 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004607, test:0.000291 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005433, test:0.000343 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[63/100] | loss train:0.005619, test:0.000367 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004664, test:0.000266 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.008144, test:0.000549 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.007897, test:0.000287 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004895, test:0.000470 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005616, test:0.000461 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004819, test:0.000385 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005130, test:0.000395 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005129, test:0.000270 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005678, test:0.000491 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005804, test:0.000490 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006822, test:0.000279 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005081, test:0.000318 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005834, test:0.000516 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005408, test:0.000286 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005511, test:0.000332 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004987, test:0.000273 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004839, test:0.000322 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004837, test:0.000312 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004910, test:0.000308 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004796, test:0.000275 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004746, test:0.000287 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004914, test:0.000307 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004895, test:0.000298 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004617, test:0.000286 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005362, test:0.000273 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004890, test:0.000298 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004776, test:0.000277 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005149, test:0.000359 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004805, test:0.000292 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004926, test:0.000285 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005048, test:0.000282 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004557, test:0.000268 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005087, test:0.000283 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004903, test:0.000289 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006613, test:0.000303 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004712, test:0.000291 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005009, test:0.000326 | lr:0.000100\n",
      "Mean absolute error:  1.7194473008545954\n",
      "Root mean squared error:  5.816978807205084\n",
      "Epoch[1/100] | loss train:0.049650, test:0.000513 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013547, test:0.000654 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010683, test:0.000607 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010074, test:0.004282 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008880, test:0.000333 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011644, test:0.004433 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.013597, test:0.004904 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011244, test:0.000326 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009314, test:0.003005 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011227, test:0.000651 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008885, test:0.005786 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009250, test:0.001279 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010390, test:0.000684 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008823, test:0.000451 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008963, test:0.003512 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010430, test:0.000453 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008231, test:0.001522 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008435, test:0.000623 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008794, test:0.001659 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007055, test:0.000483 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007598, test:0.000352 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006440, test:0.000499 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007275, test:0.000945 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007374, test:0.002100 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007656, test:0.000576 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007677, test:0.001379 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.013859, test:0.000673 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008601, test:0.000384 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007604, test:0.000360 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007824, test:0.003481 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007433, test:0.000905 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007743, test:0.005562 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008232, test:0.001238 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007933, test:0.001823 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007547, test:0.000373 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009141, test:0.000968 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007825, test:0.000401 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006553, test:0.000571 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006842, test:0.001686 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007026, test:0.000597 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005712, test:0.000294 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005425, test:0.000318 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005034, test:0.000300 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006091, test:0.000358 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005494, test:0.000415 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005323, test:0.000296 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006359, test:0.000338 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005454, test:0.000300 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006308, test:0.000339 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005079, test:0.000325 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006269, test:0.000522 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005811, test:0.000364 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005968, test:0.000375 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006579, test:0.000313 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004914, test:0.000341 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005507, test:0.000412 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004964, test:0.000633 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005460, test:0.000476 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.007009, test:0.000304 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006173, test:0.000295 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006290, test:0.000655 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005695, test:0.000272 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005948, test:0.000319 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005087, test:0.000316 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005088, test:0.000346 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005329, test:0.000311 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005156, test:0.000298 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005140, test:0.000347 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005448, test:0.000596 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005116, test:0.000289 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.010482, test:0.000320 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005273, test:0.000365 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005185, test:0.000297 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005078, test:0.000513 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005364, test:0.000318 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005230, test:0.000317 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005006, test:0.000293 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005259, test:0.000324 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005400, test:0.000296 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005108, test:0.000309 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005321, test:0.000302 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005131, test:0.000290 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005742, test:0.000283 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005424, test:0.000281 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.006572, test:0.000345 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004971, test:0.000325 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006354, test:0.000328 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[88/100] | loss train:0.006036, test:0.000299 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005251, test:0.000305 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005501, test:0.000298 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006660, test:0.000292 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005421, test:0.000302 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006198, test:0.000302 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.006886, test:0.000279 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004910, test:0.000298 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005080, test:0.000283 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004913, test:0.000307 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.007547, test:0.000305 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005842, test:0.000257 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005243, test:0.000286 | lr:0.000100\n",
      "Mean absolute error:  1.6554039248619408\n",
      "Root mean squared error:  5.76900952171042\n",
      "Epoch[1/100] | loss train:0.043572, test:0.005141 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010929, test:0.000910 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009343, test:0.000671 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009690, test:0.001001 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008396, test:0.000316 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009844, test:0.003579 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009218, test:0.000273 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007819, test:0.005008 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011131, test:0.000710 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008058, test:0.000735 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008284, test:0.000600 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008361, test:0.000905 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010013, test:0.000559 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.014713, test:0.001908 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008995, test:0.000775 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007151, test:0.000682 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008759, test:0.002163 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007672, test:0.000840 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009809, test:0.000386 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008527, test:0.000882 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007926, test:0.002569 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007239, test:0.001575 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007860, test:0.000816 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009497, test:0.000437 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007355, test:0.001036 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006728, test:0.000942 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.012329, test:0.000482 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006773, test:0.000486 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007585, test:0.002279 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.021367, test:0.000410 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.016088, test:0.003573 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007188, test:0.000549 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006409, test:0.002935 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008218, test:0.003119 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007859, test:0.000586 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007164, test:0.000454 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007363, test:0.000805 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007849, test:0.000626 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007301, test:0.000600 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006957, test:0.001613 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005558, test:0.000525 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005377, test:0.000488 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005684, test:0.000530 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005246, test:0.000453 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006008, test:0.000403 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005275, test:0.000822 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005354, test:0.000422 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005450, test:0.000450 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.008088, test:0.000457 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005819, test:0.000396 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005398, test:0.000386 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005919, test:0.000463 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005387, test:0.000472 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005037, test:0.000503 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005277, test:0.000474 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005591, test:0.000361 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005488, test:0.000372 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006093, test:0.000354 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005409, test:0.000602 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005743, test:0.000360 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.009826, test:0.000344 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005713, test:0.000385 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004953, test:0.000356 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005638, test:0.000389 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005885, test:0.000431 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006177, test:0.000403 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.013186, test:0.000658 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005537, test:0.000354 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.008346, test:0.000378 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005430, test:0.000360 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006084, test:0.000501 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005967, test:0.000379 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005281, test:0.000476 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006645, test:0.000480 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005278, test:0.000365 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006300, test:0.000360 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.007265, test:0.000336 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006288, test:0.000319 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005363, test:0.000718 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005176, test:0.000423 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005483, test:0.000368 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005371, test:0.000364 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004808, test:0.000333 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005035, test:0.000362 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004775, test:0.000346 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005168, test:0.000322 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006623, test:0.000339 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005462, test:0.000311 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004961, test:0.000329 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005156, test:0.000345 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005069, test:0.000327 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005236, test:0.000324 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005239, test:0.000355 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005004, test:0.000329 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005105, test:0.000346 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005266, test:0.000318 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004932, test:0.000331 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006168, test:0.000328 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004925, test:0.000359 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004746, test:0.000332 | lr:0.000100\n",
      "Mean absolute error:  1.6702605510891684\n",
      "Root mean squared error:  5.79517598089658\n",
      "Epoch[1/100] | loss train:0.035722, test:0.005134 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014412, test:0.008186 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.028000, test:0.010046 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013066, test:0.001780 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008512, test:0.000651 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008918, test:0.002017 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008393, test:0.000403 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007165, test:0.000404 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007623, test:0.000313 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007964, test:0.000860 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009463, test:0.003934 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12/100] | loss train:0.008770, test:0.003311 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010102, test:0.001950 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008909, test:0.000450 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007831, test:0.000644 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006939, test:0.001713 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007571, test:0.001698 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007751, test:0.000839 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007243, test:0.001579 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008466, test:0.000855 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006874, test:0.000839 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007491, test:0.000348 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008485, test:0.001251 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.010864, test:0.000743 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008012, test:0.000378 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007308, test:0.010267 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009584, test:0.000803 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007619, test:0.000693 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006885, test:0.000430 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007649, test:0.000610 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007421, test:0.000390 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007919, test:0.000470 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007433, test:0.000361 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006157, test:0.000438 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006279, test:0.000571 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007074, test:0.001461 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006610, test:0.000389 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006751, test:0.004633 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007190, test:0.000520 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006444, test:0.000504 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006064, test:0.000396 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005094, test:0.000521 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005888, test:0.000380 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005139, test:0.000442 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005433, test:0.000401 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004875, test:0.000424 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005313, test:0.000414 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005029, test:0.000431 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005751, test:0.000396 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005385, test:0.000357 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005594, test:0.000397 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004660, test:0.000357 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006019, test:0.000426 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006040, test:0.000393 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005095, test:0.000342 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005330, test:0.000452 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004945, test:0.000378 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005151, test:0.000367 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006241, test:0.000327 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004820, test:0.000338 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004872, test:0.000420 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005469, test:0.000467 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005231, test:0.000325 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005596, test:0.000332 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004719, test:0.000376 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005927, test:0.000351 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.009540, test:0.000479 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004858, test:0.000339 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005122, test:0.000340 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006713, test:0.000401 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005155, test:0.000432 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005343, test:0.000383 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005226, test:0.000330 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005005, test:0.000322 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005471, test:0.000439 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005305, test:0.000328 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006095, test:0.000569 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005446, test:0.000344 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004902, test:0.000494 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005763, test:0.000437 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.009836, test:0.000315 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005040, test:0.000306 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004814, test:0.000322 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004679, test:0.000287 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005007, test:0.000300 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004857, test:0.000312 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005070, test:0.000292 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.008831, test:0.000347 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004789, test:0.000323 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005924, test:0.000309 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004799, test:0.000309 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004938, test:0.000291 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006030, test:0.000343 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004684, test:0.000304 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004970, test:0.000301 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004488, test:0.000329 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005163, test:0.000293 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004728, test:0.000312 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004913, test:0.000322 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004487, test:0.000334 | lr:0.000100\n",
      "Mean absolute error:  1.6657304088174563\n",
      "Root mean squared error:  5.7910954676929824\n",
      "Epoch[1/100] | loss train:0.053198, test:0.002005 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013134, test:0.000501 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012160, test:0.000666 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009584, test:0.001284 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008765, test:0.011227 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012308, test:0.000365 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008089, test:0.000450 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008430, test:0.000953 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007776, test:0.000981 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010339, test:0.000342 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007534, test:0.000428 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007914, test:0.001003 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008444, test:0.001105 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008338, test:0.001167 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008376, test:0.001035 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009554, test:0.000488 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008418, test:0.002785 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008170, test:0.003279 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007266, test:0.001395 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009973, test:0.001486 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006604, test:0.001676 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008694, test:0.000452 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010864, test:0.001007 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008192, test:0.000430 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007395, test:0.002113 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008724, test:0.000392 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006846, test:0.000327 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008124, test:0.001741 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007824, test:0.001643 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006635, test:0.000706 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.011573, test:0.000539 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007587, test:0.001552 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006792, test:0.000423 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007895, test:0.000523 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007800, test:0.000851 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007306, test:0.001355 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/100] | loss train:0.006934, test:0.000387 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009253, test:0.000574 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007385, test:0.000777 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008248, test:0.000394 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006637, test:0.000351 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006351, test:0.000292 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.004981, test:0.000357 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004922, test:0.000302 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.008644, test:0.000327 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005042, test:0.000318 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005970, test:0.000268 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005369, test:0.000287 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005663, test:0.000638 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.007766, test:0.000316 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005033, test:0.000348 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005619, test:0.000286 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004753, test:0.000366 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005587, test:0.000424 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005328, test:0.000342 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005346, test:0.000298 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006248, test:0.000277 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005495, test:0.000506 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005812, test:0.000335 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006112, test:0.000302 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005290, test:0.000372 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004911, test:0.000359 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005876, test:0.000307 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004867, test:0.000366 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005084, test:0.000417 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.007925, test:0.000286 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005148, test:0.000308 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005148, test:0.000357 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005482, test:0.000348 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005086, test:0.000284 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005143, test:0.000285 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005020, test:0.000279 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004980, test:0.000299 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005904, test:0.000302 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005134, test:0.000310 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005510, test:0.000294 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004940, test:0.000461 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004971, test:0.000414 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005301, test:0.000513 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005165, test:0.000319 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004730, test:0.000290 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005031, test:0.000318 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004875, test:0.000289 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004552, test:0.000300 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005648, test:0.000297 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005947, test:0.000268 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005097, test:0.000273 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004772, test:0.000296 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004501, test:0.000308 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004922, test:0.000280 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005991, test:0.000294 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004875, test:0.000284 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004961, test:0.000279 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004669, test:0.000285 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005097, test:0.000292 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004723, test:0.000302 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004715, test:0.000295 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006118, test:0.000278 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004715, test:0.000283 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004827, test:0.000290 | lr:0.000100\n",
      "Mean absolute error:  1.6975447617099662\n",
      "Root mean squared error:  5.771037349504739\n",
      "Epoch[1/100] | loss train:0.073398, test:0.005504 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012251, test:0.004019 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011658, test:0.001885 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009740, test:0.000292 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009512, test:0.002731 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008233, test:0.001032 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008299, test:0.001217 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008084, test:0.000644 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008295, test:0.001235 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.013780, test:0.000397 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.022734, test:0.000464 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008536, test:0.001855 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009575, test:0.000384 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008228, test:0.001017 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009928, test:0.000430 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.013658, test:0.001892 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008685, test:0.001438 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008571, test:0.001368 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.011537, test:0.001284 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009701, test:0.000527 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007642, test:0.000752 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009059, test:0.001625 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008198, test:0.000514 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007995, test:0.000764 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007687, test:0.000451 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008165, test:0.000674 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008010, test:0.000804 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008761, test:0.000703 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008812, test:0.000535 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008085, test:0.001506 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008491, test:0.000595 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009396, test:0.000564 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008829, test:0.000611 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.012090, test:0.007393 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008508, test:0.000350 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.010026, test:0.000416 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007551, test:0.000748 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006835, test:0.001369 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007767, test:0.003252 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008154, test:0.000414 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006141, test:0.000361 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005539, test:0.000384 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005587, test:0.000468 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005481, test:0.000544 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006056, test:0.000373 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004907, test:0.000387 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005519, test:0.000458 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005437, test:0.000629 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007200, test:0.000714 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006824, test:0.000524 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005637, test:0.000716 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005577, test:0.000462 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005758, test:0.000302 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005383, test:0.000296 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005861, test:0.000363 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006120, test:0.000317 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005693, test:0.000366 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005255, test:0.000514 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005040, test:0.000613 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005799, test:0.000306 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005251, test:0.000430 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[62/100] | loss train:0.005436, test:0.000348 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006244, test:0.000292 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006865, test:0.000360 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005806, test:0.000663 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005613, test:0.000342 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005598, test:0.000449 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005220, test:0.000338 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005425, test:0.000751 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005367, test:0.000292 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005163, test:0.000359 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005065, test:0.000332 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005310, test:0.000302 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005042, test:0.000326 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005401, test:0.000325 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005833, test:0.000327 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005658, test:0.000358 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006876, test:0.000330 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005301, test:0.000506 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005743, test:0.000671 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005748, test:0.000297 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004985, test:0.000291 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004944, test:0.000308 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004927, test:0.000295 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005204, test:0.000295 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.007575, test:0.000286 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005796, test:0.000284 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.010077, test:0.000339 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005248, test:0.000295 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005079, test:0.000316 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004578, test:0.000291 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005072, test:0.000304 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005432, test:0.000340 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005397, test:0.000327 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004688, test:0.000329 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.007796, test:0.000314 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005122, test:0.000293 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005397, test:0.000297 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.006871, test:0.000279 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004998, test:0.000295 | lr:0.000100\n",
      "Mean absolute error:  1.7072599052697734\n",
      "Root mean squared error:  5.797411589795346\n",
      "Epoch[1/100] | loss train:0.047229, test:0.001677 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011227, test:0.003084 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010782, test:0.000347 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012145, test:0.003160 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009870, test:0.000300 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010130, test:0.002068 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008448, test:0.000952 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008532, test:0.003611 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010591, test:0.000354 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008913, test:0.000629 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010404, test:0.000397 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009514, test:0.000451 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008050, test:0.002396 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.011782, test:0.000535 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007165, test:0.000477 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008194, test:0.000452 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009347, test:0.000510 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008240, test:0.004353 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008653, test:0.000530 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007509, test:0.000965 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007094, test:0.001230 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008635, test:0.000704 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007166, test:0.000522 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.012782, test:0.001499 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009040, test:0.000413 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007520, test:0.000399 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008540, test:0.000735 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.016951, test:0.000547 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008373, test:0.000384 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008634, test:0.000737 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009490, test:0.001414 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008491, test:0.000522 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.010120, test:0.004244 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008642, test:0.000493 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006647, test:0.000753 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006618, test:0.000515 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007057, test:0.000528 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006884, test:0.000634 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008019, test:0.000542 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008953, test:0.000389 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007017, test:0.000374 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006156, test:0.000394 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005372, test:0.000399 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006228, test:0.000492 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005925, test:0.000395 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005141, test:0.000628 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005320, test:0.000427 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006520, test:0.000590 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005940, test:0.000402 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005184, test:0.000540 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005424, test:0.000389 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005160, test:0.000484 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005109, test:0.000419 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005664, test:0.000349 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005637, test:0.000391 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005652, test:0.000348 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005700, test:0.000378 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004878, test:0.000370 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005046, test:0.000465 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006243, test:0.000369 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005574, test:0.000348 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005719, test:0.000448 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005603, test:0.000384 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005867, test:0.000320 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005308, test:0.000367 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005300, test:0.000497 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.007541, test:0.000340 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005524, test:0.000350 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006814, test:0.000368 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004946, test:0.000373 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005167, test:0.000379 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006298, test:0.000604 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005611, test:0.000331 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004859, test:0.000456 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005503, test:0.000352 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005285, test:0.000359 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005340, test:0.000359 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006754, test:0.000334 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005903, test:0.000748 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006376, test:0.000424 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005273, test:0.000355 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006221, test:0.000332 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005823, test:0.000338 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004856, test:0.000362 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005354, test:0.000360 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005034, test:0.000355 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[87/100] | loss train:0.005320, test:0.000326 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005156, test:0.000341 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005117, test:0.000344 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004926, test:0.000335 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005664, test:0.000329 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004712, test:0.000325 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.007891, test:0.000365 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005232, test:0.000343 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005036, test:0.000316 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005254, test:0.000354 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005143, test:0.000319 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005066, test:0.000334 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004857, test:0.000327 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005612, test:0.000334 | lr:0.000100\n",
      "Mean absolute error:  1.6763130637909676\n",
      "Root mean squared error:  5.794045794050165\n",
      "Epoch[1/100] | loss train:0.055924, test:0.000489 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.017758, test:0.003234 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010436, test:0.000491 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008914, test:0.001468 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011160, test:0.003873 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010485, test:0.002500 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.015969, test:0.000570 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011676, test:0.000889 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008242, test:0.002058 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007770, test:0.004628 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009011, test:0.004056 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009379, test:0.000355 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007739, test:0.000466 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007839, test:0.000473 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007535, test:0.000553 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007526, test:0.000428 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008529, test:0.000394 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007669, test:0.000465 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008645, test:0.001655 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006616, test:0.000488 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007303, test:0.000476 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008170, test:0.000421 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006621, test:0.000488 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006458, test:0.000783 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007698, test:0.001096 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007271, test:0.000401 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006936, test:0.000676 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006116, test:0.007922 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007075, test:0.000815 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007882, test:0.000280 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008423, test:0.000586 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007166, test:0.000291 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006689, test:0.001331 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006142, test:0.000642 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007626, test:0.000985 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006601, test:0.001131 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007137, test:0.001415 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007077, test:0.000977 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007152, test:0.000376 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007182, test:0.001534 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005387, test:0.000295 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005655, test:0.000286 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005040, test:0.000300 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005233, test:0.000277 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005508, test:0.000309 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006839, test:0.000464 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005471, test:0.000277 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005221, test:0.000279 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005072, test:0.000714 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005432, test:0.000285 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.007164, test:0.000552 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005476, test:0.000349 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005746, test:0.000296 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005919, test:0.000522 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004948, test:0.000322 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005508, test:0.000552 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004867, test:0.000381 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004841, test:0.000279 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005552, test:0.000285 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005052, test:0.000461 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004673, test:0.000294 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005273, test:0.000344 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005670, test:0.000584 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005113, test:0.000350 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005071, test:0.000350 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004920, test:0.000419 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005229, test:0.000354 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.007874, test:0.000290 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006142, test:0.000281 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004998, test:0.000326 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005161, test:0.000576 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005363, test:0.000296 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004970, test:0.000380 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.011155, test:0.000362 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005710, test:0.000398 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004835, test:0.000380 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005238, test:0.000299 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004883, test:0.000311 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005208, test:0.000288 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005275, test:0.000325 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004612, test:0.000316 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005267, test:0.000282 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.010300, test:0.000291 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004383, test:0.000288 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005169, test:0.000299 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005660, test:0.000319 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004720, test:0.000264 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005373, test:0.000279 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004909, test:0.000285 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004990, test:0.000293 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004922, test:0.000277 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005125, test:0.000312 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004584, test:0.000295 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004908, test:0.000264 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004998, test:0.000288 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005005, test:0.000278 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004559, test:0.000298 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004590, test:0.000309 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005635, test:0.000272 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005083, test:0.000267 | lr:0.000100\n",
      "Mean absolute error:  1.6575548631507295\n",
      "Root mean squared error:  5.764665993872872\n",
      "Epoch[1/100] | loss train:0.054013, test:0.000527 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013612, test:0.000389 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011191, test:0.000416 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009444, test:0.000764 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011210, test:0.000865 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008932, test:0.001552 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008531, test:0.002405 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008687, test:0.001031 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009244, test:0.000303 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008980, test:0.002567 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11/100] | loss train:0.011652, test:0.000641 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007583, test:0.003144 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008704, test:0.000441 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008566, test:0.000388 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008510, test:0.006649 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008126, test:0.003210 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008767, test:0.000337 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007619, test:0.001890 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007779, test:0.000569 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008035, test:0.000364 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.019770, test:0.001796 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008282, test:0.000438 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.012255, test:0.000564 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.010924, test:0.000909 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007460, test:0.001707 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007064, test:0.000426 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008217, test:0.004820 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.011230, test:0.000804 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008213, test:0.000534 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006964, test:0.000556 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009379, test:0.001011 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008281, test:0.000759 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008238, test:0.001536 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007855, test:0.000831 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008030, test:0.001513 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007201, test:0.001271 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007645, test:0.000686 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.016404, test:0.004321 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.011964, test:0.000522 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007041, test:0.000555 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005844, test:0.000427 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.008244, test:0.000461 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005335, test:0.000497 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005890, test:0.000440 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006073, test:0.000525 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005311, test:0.000676 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006213, test:0.000685 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006899, test:0.000409 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005149, test:0.000544 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005556, test:0.000389 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005187, test:0.000544 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005704, test:0.000428 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005264, test:0.000622 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005976, test:0.000430 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005482, test:0.000400 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005400, test:0.000457 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005726, test:0.000409 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005300, test:0.000418 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004955, test:0.000445 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005821, test:0.000595 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005604, test:0.000422 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.013947, test:0.000382 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005173, test:0.000407 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005572, test:0.000398 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005497, test:0.000363 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005141, test:0.000438 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005208, test:0.000368 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005907, test:0.000415 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005370, test:0.000353 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005333, test:0.000633 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005680, test:0.000432 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005428, test:0.000435 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005066, test:0.000357 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005481, test:0.000347 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005428, test:0.000452 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006051, test:0.000324 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005568, test:0.000401 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005478, test:0.000794 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005088, test:0.000460 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005269, test:0.000347 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005308, test:0.000327 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005405, test:0.000345 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004468, test:0.000336 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005670, test:0.000348 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.006240, test:0.000350 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005028, test:0.000365 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.008637, test:0.000355 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005458, test:0.000317 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.007103, test:0.000332 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005340, test:0.000367 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005258, test:0.000358 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004729, test:0.000336 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004986, test:0.000408 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005446, test:0.000352 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005265, test:0.000331 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006044, test:0.000369 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004572, test:0.000361 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006662, test:0.000332 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005344, test:0.000331 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005235, test:0.000354 | lr:0.000100\n",
      "Mean absolute error:  1.7107081202335281\n",
      "Root mean squared error:  5.812043114199945\n",
      "Epoch[1/100] | loss train:0.045796, test:0.000393 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011119, test:0.000440 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010005, test:0.004035 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009913, test:0.000352 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010928, test:0.002891 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009611, test:0.000428 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009987, test:0.001632 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010518, test:0.000317 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007991, test:0.005153 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007963, test:0.002172 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007298, test:0.001791 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010377, test:0.002900 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007821, test:0.006787 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007216, test:0.000839 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006806, test:0.000313 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006640, test:0.000355 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006672, test:0.004983 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006997, test:0.000781 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008026, test:0.005523 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007137, test:0.001181 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.012273, test:0.000563 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009903, test:0.005642 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007690, test:0.000369 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007835, test:0.000336 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008913, test:0.000473 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006797, test:0.001555 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007385, test:0.000733 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007223, test:0.000459 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008319, test:0.001085 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006731, test:0.001040 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008604, test:0.000354 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007572, test:0.000464 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008266, test:0.000366 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006287, test:0.000500 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006765, test:0.000505 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[36/100] | loss train:0.011627, test:0.001857 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006966, test:0.003019 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006697, test:0.000494 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007971, test:0.000567 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.005954, test:0.001660 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006392, test:0.000348 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006101, test:0.000333 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005097, test:0.000563 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004752, test:0.000357 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006640, test:0.000417 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005611, test:0.000393 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006087, test:0.000526 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.008498, test:0.000326 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005210, test:0.000301 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006699, test:0.000350 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.007089, test:0.000408 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004747, test:0.000454 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005643, test:0.000302 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005692, test:0.000291 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005034, test:0.000295 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005990, test:0.000373 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005403, test:0.000463 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005375, test:0.000288 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006014, test:0.000856 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005621, test:0.000309 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005336, test:0.000448 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005300, test:0.000321 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005646, test:0.000565 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005195, test:0.000291 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005242, test:0.000329 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004862, test:0.000311 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005544, test:0.000281 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005236, test:0.000320 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004733, test:0.000268 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004787, test:0.000318 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005519, test:0.000290 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005117, test:0.000267 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005269, test:0.000308 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006158, test:0.000501 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006106, test:0.000312 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004869, test:0.000282 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004923, test:0.000312 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004981, test:0.000624 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.008000, test:0.000337 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005655, test:0.000402 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005500, test:0.000293 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005083, test:0.000307 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004908, test:0.000296 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004478, test:0.000315 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004645, test:0.000315 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004784, test:0.000298 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004828, test:0.000283 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.007010, test:0.000291 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005024, test:0.000294 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006441, test:0.000299 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004598, test:0.000274 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.006354, test:0.000294 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004901, test:0.000313 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004493, test:0.000267 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004954, test:0.000297 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004907, test:0.000289 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004564, test:0.000295 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005164, test:0.000286 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005970, test:0.000290 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006546, test:0.000289 | lr:0.000100\n",
      "Mean absolute error:  1.7214033064001597\n",
      "Root mean squared error:  5.8044744382717415\n",
      "Epoch[1/100] | loss train:0.064820, test:0.000453 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011577, test:0.000579 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011254, test:0.001554 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013183, test:0.001106 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010899, test:0.001864 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007827, test:0.000660 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008420, test:0.002799 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008587, test:0.000317 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009734, test:0.000972 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008817, test:0.001122 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010121, test:0.000363 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007954, test:0.003477 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007923, test:0.007612 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007527, test:0.000503 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008494, test:0.000377 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006811, test:0.000492 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007865, test:0.000591 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007339, test:0.002065 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008706, test:0.002799 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007358, test:0.000762 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007537, test:0.001561 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008082, test:0.000369 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007732, test:0.000416 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007310, test:0.000626 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007997, test:0.001426 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007032, test:0.001742 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007868, test:0.000460 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.010645, test:0.000923 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008410, test:0.007922 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007505, test:0.000531 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008231, test:0.000328 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007794, test:0.000516 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009055, test:0.003335 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007168, test:0.000682 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008264, test:0.001242 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007068, test:0.001044 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008394, test:0.000412 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008362, test:0.000494 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008110, test:0.000380 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006512, test:0.000385 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005815, test:0.000478 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005722, test:0.000518 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005886, test:0.000454 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005822, test:0.000502 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005754, test:0.000562 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006545, test:0.000414 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006177, test:0.001091 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005926, test:0.000491 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006338, test:0.000489 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006199, test:0.000383 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005525, test:0.000547 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005706, test:0.000372 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005660, test:0.000435 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005569, test:0.000526 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005805, test:0.000495 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006008, test:0.000391 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005580, test:0.000456 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005330, test:0.000467 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005630, test:0.000359 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005528, test:0.000387 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[61/100] | loss train:0.006377, test:0.000355 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005214, test:0.000406 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005629, test:0.000326 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.008030, test:0.000335 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005398, test:0.000361 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005580, test:0.000744 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006159, test:0.000328 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005416, test:0.000513 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006053, test:0.000441 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005591, test:0.000352 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005331, test:0.000348 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006899, test:0.000401 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005406, test:0.000698 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005722, test:0.000359 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005385, test:0.000590 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005851, test:0.000394 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005170, test:0.000391 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006040, test:0.000333 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005162, test:0.000571 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006075, test:0.000382 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005657, test:0.000401 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006209, test:0.000373 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005501, test:0.000388 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.006337, test:0.000372 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.006008, test:0.000354 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.007639, test:0.000376 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005637, test:0.000352 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005198, test:0.000374 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006294, test:0.000365 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006923, test:0.000359 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005886, test:0.000340 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005396, test:0.000327 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006039, test:0.000356 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005761, test:0.000330 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.006959, test:0.000339 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005344, test:0.000349 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005680, test:0.000377 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005518, test:0.000340 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005179, test:0.000388 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005199, test:0.000326 | lr:0.000100\n",
      "Mean absolute error:  1.6602603204444388\n",
      "Root mean squared error:  5.7957962899499575\n",
      "Epoch[1/100] | loss train:0.049500, test:0.000608 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013175, test:0.002593 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011798, test:0.001694 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009370, test:0.003704 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009229, test:0.004694 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009014, test:0.000614 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008735, test:0.000582 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009075, test:0.000374 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007296, test:0.000605 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008701, test:0.001159 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009073, test:0.009718 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009800, test:0.002549 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007561, test:0.000357 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007077, test:0.000869 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008309, test:0.000598 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007211, test:0.000623 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007636, test:0.001318 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.011961, test:0.001986 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008916, test:0.000426 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008633, test:0.005905 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008951, test:0.001805 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007686, test:0.001388 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007889, test:0.000550 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.011251, test:0.002054 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010015, test:0.000495 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008029, test:0.001834 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007334, test:0.004916 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008122, test:0.000756 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.013091, test:0.000438 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007435, test:0.001059 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008318, test:0.000483 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007246, test:0.003163 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008782, test:0.000723 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007286, test:0.000994 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007681, test:0.002004 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008082, test:0.000726 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007534, test:0.000895 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006732, test:0.000930 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007070, test:0.000417 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006326, test:0.000431 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005357, test:0.000406 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005676, test:0.000431 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.004962, test:0.000455 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005521, test:0.000465 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005271, test:0.000430 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004997, test:0.000462 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005285, test:0.000412 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.007038, test:0.000394 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005059, test:0.000451 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005293, test:0.000747 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006097, test:0.000417 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005395, test:0.000370 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.007639, test:0.000500 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.008473, test:0.000449 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005984, test:0.000378 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004766, test:0.000422 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.006857, test:0.000458 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005034, test:0.000475 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005313, test:0.000615 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006133, test:0.000409 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005086, test:0.000367 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004947, test:0.000618 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005379, test:0.000400 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005214, test:0.000401 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005002, test:0.000385 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005383, test:0.001204 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006759, test:0.000512 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005642, test:0.000354 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005302, test:0.000573 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004937, test:0.000341 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006627, test:0.000357 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004843, test:0.000372 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005292, test:0.000412 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004948, test:0.000350 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005050, test:0.000373 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006697, test:0.000428 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005497, test:0.000442 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006201, test:0.000540 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.006564, test:0.000391 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006417, test:0.000348 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005159, test:0.000399 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004692, test:0.000349 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004596, test:0.000361 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.006429, test:0.000355 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005388, test:0.000329 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[86/100] | loss train:0.005274, test:0.000341 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005018, test:0.000342 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005006, test:0.000367 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004832, test:0.000356 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004747, test:0.000342 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004976, test:0.000317 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005416, test:0.000323 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004932, test:0.000326 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004759, test:0.000354 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005432, test:0.000324 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004725, test:0.000339 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005441, test:0.000383 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005122, test:0.000343 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005271, test:0.000409 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004857, test:0.000382 | lr:0.000100\n",
      "Mean absolute error:  1.7053116810077633\n",
      "Root mean squared error:  5.807261450979899\n",
      "Epoch[1/100] | loss train:0.054071, test:0.000485 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012659, test:0.000996 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009968, test:0.000276 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010202, test:0.000395 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009406, test:0.000278 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010882, test:0.000271 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008265, test:0.000364 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007513, test:0.002865 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008091, test:0.001167 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009964, test:0.007217 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008617, test:0.000781 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007780, test:0.002727 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008925, test:0.002499 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009277, test:0.000315 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009222, test:0.000836 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006892, test:0.005035 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008070, test:0.002285 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007936, test:0.001133 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007979, test:0.000548 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007659, test:0.000470 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007615, test:0.000441 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007257, test:0.001840 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006383, test:0.000896 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006770, test:0.000391 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007062, test:0.001116 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007354, test:0.000386 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007095, test:0.001307 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007395, test:0.001369 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007697, test:0.000462 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007628, test:0.000351 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008691, test:0.004743 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007721, test:0.001148 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006739, test:0.002395 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007613, test:0.000348 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006723, test:0.000751 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006564, test:0.002194 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007320, test:0.000917 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006892, test:0.000421 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007316, test:0.000526 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007095, test:0.002885 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005661, test:0.000385 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005416, test:0.000395 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005403, test:0.000310 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005346, test:0.000341 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005438, test:0.000391 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005717, test:0.000518 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004767, test:0.000379 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005135, test:0.000393 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007433, test:0.000312 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005383, test:0.000326 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004897, test:0.000342 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004956, test:0.000385 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004899, test:0.000336 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004997, test:0.000368 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005491, test:0.000338 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005098, test:0.000471 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005061, test:0.000499 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005045, test:0.000316 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005319, test:0.000302 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004654, test:0.000305 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005059, test:0.000434 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006482, test:0.000507 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005700, test:0.000313 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006316, test:0.000381 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006007, test:0.000314 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005378, test:0.000315 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005009, test:0.000322 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004819, test:0.000679 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004744, test:0.000324 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005349, test:0.000378 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004859, test:0.000288 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006021, test:0.000509 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005232, test:0.000290 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004977, test:0.000301 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005211, test:0.000320 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005275, test:0.000320 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004714, test:0.000363 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005290, test:0.000425 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005498, test:0.000279 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005014, test:0.000328 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004710, test:0.000301 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006137, test:0.000298 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005194, test:0.000344 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004734, test:0.000296 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004993, test:0.000278 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005133, test:0.000312 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004977, test:0.000310 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004737, test:0.000289 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004991, test:0.000292 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005803, test:0.000288 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004850, test:0.000321 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005158, test:0.000368 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005022, test:0.000361 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004474, test:0.000294 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004918, test:0.000290 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004693, test:0.000303 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004828, test:0.000291 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004653, test:0.000290 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005315, test:0.000282 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006031, test:0.000315 | lr:0.000100\n",
      "Mean absolute error:  1.7231897282975508\n",
      "Root mean squared error:  5.8095550270750715\n",
      "Epoch[1/100] | loss train:0.057862, test:0.004355 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013911, test:0.001160 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010638, test:0.000918 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009087, test:0.000333 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011045, test:0.000427 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007740, test:0.001104 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010906, test:0.001491 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008236, test:0.003425 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010556, test:0.005504 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/100] | loss train:0.017439, test:0.001129 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.012258, test:0.006345 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009681, test:0.000620 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007642, test:0.000400 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008658, test:0.001662 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008772, test:0.004045 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009210, test:0.000567 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007893, test:0.000834 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006861, test:0.000744 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008353, test:0.005531 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.010179, test:0.000406 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006891, test:0.000918 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007378, test:0.002222 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008077, test:0.000339 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007223, test:0.001136 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007363, test:0.000538 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007606, test:0.000569 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006764, test:0.000469 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007584, test:0.002202 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006776, test:0.000339 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007534, test:0.001416 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007888, test:0.001635 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007054, test:0.000305 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008475, test:0.003207 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006854, test:0.001615 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007793, test:0.001449 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006422, test:0.002060 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007108, test:0.000932 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006556, test:0.000399 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008896, test:0.000433 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007183, test:0.000508 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005734, test:0.000390 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006017, test:0.000352 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005249, test:0.000408 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005576, test:0.000500 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.009718, test:0.000309 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005759, test:0.000356 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005641, test:0.000336 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005046, test:0.000401 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005496, test:0.000442 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004700, test:0.000343 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006269, test:0.000302 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005083, test:0.000309 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004936, test:0.000319 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005296, test:0.000445 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005151, test:0.000407 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.007042, test:0.000372 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005620, test:0.000332 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004906, test:0.000315 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005521, test:0.000342 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005302, test:0.000309 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006519, test:0.000292 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005508, test:0.000282 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005361, test:0.000300 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005286, test:0.000300 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004759, test:0.000302 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005342, test:0.000276 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005270, test:0.000340 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005268, test:0.000317 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005259, test:0.000384 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004962, test:0.000307 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004836, test:0.000371 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004765, test:0.000312 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004913, test:0.000544 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005044, test:0.000314 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004949, test:0.000312 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004485, test:0.000347 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005626, test:0.000419 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004944, test:0.000328 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005234, test:0.000377 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005196, test:0.000309 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004900, test:0.000290 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005022, test:0.000277 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004997, test:0.000332 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004816, test:0.000302 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005811, test:0.000278 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004689, test:0.000290 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006775, test:0.000281 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004897, test:0.000280 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005095, test:0.000277 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005067, test:0.000304 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005225, test:0.000300 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004839, test:0.000277 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006266, test:0.000282 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005518, test:0.000317 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004342, test:0.000275 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006212, test:0.000289 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004589, test:0.000298 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004830, test:0.000384 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005021, test:0.000324 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004633, test:0.000288 | lr:0.000100\n",
      "Mean absolute error:  1.6555544095951258\n",
      "Root mean squared error:  5.776104729288991\n",
      "Epoch[1/100] | loss train:0.058426, test:0.002219 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.016837, test:0.000721 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011876, test:0.004433 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009870, test:0.001842 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009020, test:0.003285 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008195, test:0.000309 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009160, test:0.004706 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010723, test:0.003548 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008751, test:0.003987 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009323, test:0.000408 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007852, test:0.004803 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008499, test:0.004247 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007972, test:0.000333 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008242, test:0.000667 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007199, test:0.000344 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008189, test:0.000690 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008128, test:0.000427 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007658, test:0.002463 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006975, test:0.000420 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008866, test:0.001104 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006712, test:0.000399 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007029, test:0.001045 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007368, test:0.000395 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007161, test:0.001346 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007614, test:0.000935 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007124, test:0.000780 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007441, test:0.000635 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007745, test:0.002497 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007201, test:0.000614 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008255, test:0.002302 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007446, test:0.000339 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006818, test:0.001091 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006779, test:0.002292 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007085, test:0.000315 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[35/100] | loss train:0.006379, test:0.000327 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007213, test:0.000411 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006738, test:0.000933 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006633, test:0.000409 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008559, test:0.002789 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006884, test:0.002401 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005779, test:0.000373 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.009595, test:0.000317 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005248, test:0.000386 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005262, test:0.000392 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006025, test:0.000290 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006667, test:0.000348 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005537, test:0.000290 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005151, test:0.000322 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005463, test:0.000433 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004895, test:0.000327 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.010939, test:0.000384 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.007164, test:0.000353 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005156, test:0.000349 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005962, test:0.000335 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005334, test:0.000293 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005273, test:0.000641 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005223, test:0.000351 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005549, test:0.000367 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004767, test:0.000316 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.007023, test:0.000284 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005780, test:0.000455 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005109, test:0.000282 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.004912, test:0.000391 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005053, test:0.000302 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004921, test:0.000280 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005310, test:0.000505 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005311, test:0.000271 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005111, test:0.000287 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005213, test:0.000301 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006949, test:0.000288 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005162, test:0.000322 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004867, test:0.000329 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004957, test:0.000332 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004966, test:0.000323 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005022, test:0.000314 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005032, test:0.000362 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004883, test:0.000278 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004935, test:0.000271 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.006368, test:0.000406 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005050, test:0.000277 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004789, test:0.000260 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004737, test:0.000276 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004965, test:0.000275 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005000, test:0.000287 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004822, test:0.000283 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004946, test:0.000300 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004807, test:0.000304 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006095, test:0.000266 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005126, test:0.000300 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004792, test:0.000275 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004985, test:0.000311 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.006380, test:0.000287 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.007173, test:0.000279 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005086, test:0.000275 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004859, test:0.000284 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004909, test:0.000284 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005145, test:0.000285 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005427, test:0.000300 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005620, test:0.000281 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004977, test:0.000271 | lr:0.000100\n",
      "Mean absolute error:  1.653710297568039\n",
      "Root mean squared error:  5.760455940197763\n",
      "Epoch[1/100] | loss train:0.060037, test:0.002288 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013794, test:0.001783 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013347, test:0.002044 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011566, test:0.005150 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010760, test:0.001858 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010122, test:0.000390 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.012555, test:0.000324 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011912, test:0.005001 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.012885, test:0.000367 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009057, test:0.001800 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009148, test:0.008670 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011606, test:0.000434 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008675, test:0.006872 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010464, test:0.004441 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.011846, test:0.001955 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010198, test:0.003743 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008076, test:0.003463 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009296, test:0.000872 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009213, test:0.000974 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009413, test:0.001288 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007849, test:0.003862 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008164, test:0.000384 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007280, test:0.000715 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007754, test:0.000444 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007813, test:0.000551 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007480, test:0.000369 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007067, test:0.000420 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007153, test:0.002082 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006836, test:0.001978 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008266, test:0.000768 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.011025, test:0.000566 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007078, test:0.000804 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008019, test:0.001130 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008541, test:0.002955 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008477, test:0.000918 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006784, test:0.000649 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008774, test:0.000439 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007486, test:0.000474 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008846, test:0.001069 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006709, test:0.000964 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005979, test:0.000455 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006049, test:0.000427 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007972, test:0.000412 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006285, test:0.000585 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005468, test:0.000372 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005501, test:0.000578 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005553, test:0.000446 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005948, test:0.000468 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005852, test:0.000408 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.007484, test:0.000407 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005420, test:0.000348 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006155, test:0.000751 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005609, test:0.000455 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005219, test:0.000596 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005636, test:0.000471 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005428, test:0.000440 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005467, test:0.000475 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005169, test:0.000335 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005829, test:0.000345 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[60/100] | loss train:0.005144, test:0.000340 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006409, test:0.000439 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005863, test:0.000559 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005493, test:0.000433 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.007717, test:0.000400 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005895, test:0.000459 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005815, test:0.000382 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005256, test:0.000600 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006313, test:0.000332 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005341, test:0.000344 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005842, test:0.000491 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005528, test:0.000339 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.007247, test:0.000372 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.009225, test:0.000367 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005429, test:0.000317 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.007084, test:0.000398 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006054, test:0.000882 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005482, test:0.000383 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005651, test:0.000367 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005196, test:0.000356 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005196, test:0.000393 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005476, test:0.000339 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005370, test:0.000340 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005548, test:0.000372 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005085, test:0.000325 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005127, test:0.000341 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005394, test:0.000354 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006675, test:0.000350 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005406, test:0.000335 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.006191, test:0.000351 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.006961, test:0.000328 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004975, test:0.000326 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005459, test:0.000323 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004970, test:0.000321 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.006656, test:0.000318 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005027, test:0.000359 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004922, test:0.000396 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.008215, test:0.000393 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005099, test:0.000325 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005091, test:0.000308 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005001, test:0.000321 | lr:0.000100\n",
      "Mean absolute error:  1.6770634164855176\n",
      "Root mean squared error:  5.80101834389753\n",
      "Epoch[1/100] | loss train:0.052948, test:0.002820 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011885, test:0.000371 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010346, test:0.008188 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009950, test:0.005189 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009532, test:0.000325 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009803, test:0.000642 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008893, test:0.001054 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007444, test:0.002670 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.012379, test:0.009495 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008756, test:0.000470 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008223, test:0.001919 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009870, test:0.001387 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008783, test:0.001751 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009791, test:0.004495 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008039, test:0.000504 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007292, test:0.000472 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006752, test:0.000665 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007226, test:0.001120 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007453, test:0.001819 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007360, test:0.001700 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.012664, test:0.001580 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007652, test:0.000431 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008385, test:0.001159 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007142, test:0.000720 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007680, test:0.000626 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008593, test:0.001388 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008469, test:0.000505 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006611, test:0.000815 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008295, test:0.000650 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008589, test:0.001387 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008315, test:0.001137 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007050, test:0.000646 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007193, test:0.002248 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007438, test:0.000559 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007481, test:0.000430 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008416, test:0.000359 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.015023, test:0.000690 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007915, test:0.000615 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006663, test:0.002333 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007003, test:0.000382 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006405, test:0.000352 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007021, test:0.000406 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005076, test:0.000377 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006630, test:0.000414 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005570, test:0.000509 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005641, test:0.000346 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005110, test:0.000401 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005089, test:0.000326 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005281, test:0.000334 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004813, test:0.000834 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006479, test:0.000553 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005329, test:0.000388 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004790, test:0.000355 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004913, test:0.000343 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004962, test:0.000388 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004820, test:0.000348 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004928, test:0.000428 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004527, test:0.000382 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005588, test:0.000333 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004941, test:0.000368 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006056, test:0.000355 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005116, test:0.000363 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005183, test:0.000312 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004671, test:0.000390 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.007533, test:0.000340 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005071, test:0.000361 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004874, test:0.000370 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005546, test:0.000393 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004885, test:0.000749 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006433, test:0.000510 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005137, test:0.000332 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004607, test:0.000317 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005114, test:0.000404 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006135, test:0.000339 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005170, test:0.000321 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005523, test:0.000354 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005177, test:0.000304 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006189, test:0.000314 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005516, test:0.000347 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005210, test:0.000387 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004756, test:0.000344 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.008211, test:0.000349 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004753, test:0.000363 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004901, test:0.000301 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[85/100] | loss train:0.004647, test:0.000318 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.006029, test:0.000310 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004926, test:0.000349 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004775, test:0.000313 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004863, test:0.000315 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004794, test:0.000344 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.008826, test:0.000331 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004928, test:0.000309 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.011024, test:0.000338 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.008443, test:0.000341 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004737, test:0.000327 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005196, test:0.000398 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004901, test:0.000361 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005480, test:0.000310 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004956, test:0.000330 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004827, test:0.000338 | lr:0.000100\n",
      "Mean absolute error:  1.6943344504142563\n",
      "Root mean squared error:  5.801528794769808\n",
      "Epoch[1/100] | loss train:0.060817, test:0.000988 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012112, test:0.007646 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011334, test:0.000853 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011120, test:0.000461 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009962, test:0.007049 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011171, test:0.002346 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008744, test:0.002891 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.015904, test:0.002614 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009851, test:0.000382 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007448, test:0.000767 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009526, test:0.003175 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007535, test:0.001976 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008207, test:0.001806 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007664, test:0.000571 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008043, test:0.001964 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007629, test:0.000567 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009775, test:0.000756 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007550, test:0.000984 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007252, test:0.000412 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007664, test:0.000525 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009708, test:0.000739 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006878, test:0.000632 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006942, test:0.000447 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007483, test:0.002083 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008924, test:0.001182 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.011008, test:0.000577 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007724, test:0.001361 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007364, test:0.000691 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007528, test:0.001231 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007236, test:0.003685 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008752, test:0.000343 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007537, test:0.000377 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006683, test:0.003942 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006796, test:0.000347 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006855, test:0.001396 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007308, test:0.001299 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.005945, test:0.002035 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008337, test:0.002251 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.009944, test:0.001231 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008193, test:0.000300 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005569, test:0.000305 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.008305, test:0.000310 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005197, test:0.000615 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005145, test:0.000371 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005196, test:0.000374 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006973, test:0.000469 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005629, test:0.000358 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005440, test:0.000307 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006021, test:0.000349 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005194, test:0.000416 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006504, test:0.000370 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.006031, test:0.000347 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005128, test:0.000319 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005124, test:0.000335 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005239, test:0.000326 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005137, test:0.000296 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005983, test:0.000309 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006815, test:0.000344 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005589, test:0.000339 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004731, test:0.000813 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004866, test:0.000302 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005811, test:0.000590 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.009220, test:0.001297 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005275, test:0.000358 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005384, test:0.000428 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005462, test:0.000282 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.004918, test:0.000355 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005075, test:0.000327 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005131, test:0.000362 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.008191, test:0.000278 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.009975, test:0.000321 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006800, test:0.000326 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006116, test:0.000283 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.006012, test:0.000513 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005596, test:0.000305 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.008558, test:0.000364 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004893, test:0.000310 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005621, test:0.000299 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005862, test:0.000297 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005907, test:0.000342 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006100, test:0.000307 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005246, test:0.000298 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004765, test:0.000305 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004571, test:0.000300 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005034, test:0.000294 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004745, test:0.000361 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004932, test:0.000298 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.007202, test:0.000319 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005175, test:0.000274 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005190, test:0.000289 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004872, test:0.000308 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005159, test:0.000271 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004996, test:0.000286 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005090, test:0.000287 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.007385, test:0.000309 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004887, test:0.000295 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005564, test:0.000314 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006766, test:0.000295 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005093, test:0.000326 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004935, test:0.000325 | lr:0.000100\n",
      "Mean absolute error:  1.694617441498977\n",
      "Root mean squared error:  5.774745876604393\n",
      "Epoch[1/100] | loss train:0.055706, test:0.001988 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.015089, test:0.003667 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010930, test:0.000348 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011395, test:0.000434 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008212, test:0.001171 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008978, test:0.000299 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009945, test:0.000386 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008406, test:0.000638 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/100] | loss train:0.008811, test:0.000374 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007832, test:0.000327 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008839, test:0.000707 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011385, test:0.005746 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008254, test:0.002424 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008491, test:0.000421 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007401, test:0.005969 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008968, test:0.002404 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007479, test:0.003606 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008356, test:0.000370 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007428, test:0.000463 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007517, test:0.000640 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008117, test:0.000379 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007810, test:0.000728 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007495, test:0.001404 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008141, test:0.001107 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007062, test:0.001424 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008220, test:0.000464 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006882, test:0.000860 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006812, test:0.002476 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007441, test:0.001401 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010403, test:0.001158 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008875, test:0.000409 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009711, test:0.000888 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007125, test:0.000865 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007834, test:0.000684 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007345, test:0.001052 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008836, test:0.000632 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007377, test:0.000776 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006971, test:0.000777 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007873, test:0.000350 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007055, test:0.001857 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007031, test:0.000493 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005268, test:0.000371 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005838, test:0.000455 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005009, test:0.000368 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005578, test:0.000367 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005192, test:0.000337 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005052, test:0.000418 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004983, test:0.000455 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007258, test:0.000362 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006288, test:0.000348 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005270, test:0.000335 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005081, test:0.000460 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005556, test:0.000336 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005691, test:0.000429 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004481, test:0.000373 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004949, test:0.000339 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005250, test:0.000465 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.010331, test:0.000330 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005296, test:0.000344 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005251, test:0.000524 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006534, test:0.000340 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004721, test:0.000339 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005067, test:0.000325 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006468, test:0.000321 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005291, test:0.000330 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005115, test:0.000338 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006076, test:0.000358 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005015, test:0.000354 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005277, test:0.000324 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.008998, test:0.000380 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005007, test:0.000354 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005034, test:0.000397 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005594, test:0.000366 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004583, test:0.000342 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006948, test:0.000337 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005119, test:0.000404 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004971, test:0.000340 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004839, test:0.000291 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005285, test:0.000310 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004790, test:0.000312 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006263, test:0.000302 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.006286, test:0.000283 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006098, test:0.000303 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004407, test:0.000314 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005243, test:0.000318 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005303, test:0.000325 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004660, test:0.000309 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005428, test:0.000322 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004520, test:0.000315 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005059, test:0.000314 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005027, test:0.000293 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005414, test:0.000303 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004553, test:0.000295 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005044, test:0.000304 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004713, test:0.000286 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004946, test:0.000311 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004830, test:0.000332 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004592, test:0.000291 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004909, test:0.000307 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004800, test:0.000295 | lr:0.000100\n",
      "Mean absolute error:  1.7264906361895482\n",
      "Root mean squared error:  5.787964268003769\n",
      "Epoch[1/100] | loss train:0.075759, test:0.003520 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014205, test:0.007630 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.016757, test:0.000945 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009759, test:0.004043 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009785, test:0.004380 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009953, test:0.002142 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008409, test:0.003296 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010324, test:0.000585 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009951, test:0.001365 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011385, test:0.000386 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009302, test:0.001574 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011871, test:0.001768 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.011343, test:0.003097 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008018, test:0.000554 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008658, test:0.002159 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010825, test:0.000400 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008222, test:0.000464 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007748, test:0.001845 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009196, test:0.001623 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008602, test:0.001709 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008484, test:0.001415 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008720, test:0.000550 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008069, test:0.003362 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007676, test:0.000568 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007276, test:0.000588 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007684, test:0.000353 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008105, test:0.001722 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008240, test:0.000407 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007695, test:0.000949 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006815, test:0.000352 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006865, test:0.000418 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007499, test:0.000357 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008414, test:0.000350 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/100] | loss train:0.008002, test:0.005763 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008368, test:0.001785 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007908, test:0.000339 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009960, test:0.002533 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008685, test:0.000412 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007938, test:0.001357 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007355, test:0.000770 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006604, test:0.000396 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005838, test:0.000371 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005866, test:0.000314 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005957, test:0.000356 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005623, test:0.000357 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005179, test:0.000381 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006549, test:0.000310 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005317, test:0.000317 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005157, test:0.000532 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005500, test:0.000317 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.007467, test:0.000340 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005745, test:0.000322 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004949, test:0.000297 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006009, test:0.000416 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005462, test:0.000499 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005332, test:0.000344 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005427, test:0.000368 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006508, test:0.000709 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005283, test:0.000417 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.006712, test:0.000307 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005572, test:0.000285 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005786, test:0.000745 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006212, test:0.000446 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005290, test:0.000339 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005618, test:0.000382 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005708, test:0.000905 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005404, test:0.000327 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005415, test:0.000405 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005186, test:0.000426 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005712, test:0.000787 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006501, test:0.000496 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005311, test:0.000486 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005380, test:0.000309 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005129, test:0.000307 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.004874, test:0.000332 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005671, test:0.000608 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005185, test:0.000305 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005356, test:0.000362 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005886, test:0.000306 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005703, test:0.000363 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005245, test:0.000319 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005354, test:0.000360 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005914, test:0.000325 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.008237, test:0.000304 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005773, test:0.000338 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005486, test:0.000349 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005669, test:0.000314 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004961, test:0.000318 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005676, test:0.000318 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.007629, test:0.000296 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005206, test:0.000297 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004739, test:0.000370 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006072, test:0.000364 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005204, test:0.000300 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005019, test:0.000306 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005516, test:0.000304 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.006681, test:0.000350 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005119, test:0.000300 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005044, test:0.000339 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.007167, test:0.000316 | lr:0.000100\n",
      "Mean absolute error:  1.6446456980128732\n",
      "Root mean squared error:  5.775171047633428\n",
      "Epoch[1/100] | loss train:0.051833, test:0.001191 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010375, test:0.000340 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011323, test:0.000405 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008901, test:0.006943 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009440, test:0.002161 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008908, test:0.000440 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008488, test:0.006141 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008731, test:0.000347 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007754, test:0.000304 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010339, test:0.000346 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009026, test:0.000580 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008798, test:0.000883 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010419, test:0.000694 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008124, test:0.001679 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007173, test:0.008251 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007781, test:0.007213 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008409, test:0.005189 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007662, test:0.000976 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006490, test:0.001198 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008090, test:0.002940 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009197, test:0.001235 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008917, test:0.000402 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007947, test:0.000718 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008332, test:0.000486 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008016, test:0.000796 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008335, test:0.000479 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007390, test:0.001692 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006515, test:0.000586 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007639, test:0.000546 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007061, test:0.001035 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007366, test:0.000445 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006107, test:0.000797 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009478, test:0.000646 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.012180, test:0.000750 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007403, test:0.000629 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007098, test:0.003084 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009368, test:0.000479 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007067, test:0.000440 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007705, test:0.000520 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006955, test:0.000700 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.009127, test:0.000415 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005962, test:0.000595 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006254, test:0.000404 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005487, test:0.000384 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006426, test:0.000502 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005958, test:0.000414 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005544, test:0.000401 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004924, test:0.000395 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005522, test:0.000408 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005829, test:0.000414 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005409, test:0.000380 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005023, test:0.000347 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005569, test:0.000357 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005284, test:0.000385 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005746, test:0.000326 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005145, test:0.000349 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005341, test:0.000433 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005376, test:0.000359 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[59/100] | loss train:0.004779, test:0.000383 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.007326, test:0.000422 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005046, test:0.000385 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005105, test:0.000361 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005231, test:0.000353 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005942, test:0.000419 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006580, test:0.000335 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006755, test:0.000380 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005603, test:0.000419 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005675, test:0.000351 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006499, test:0.000308 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005944, test:0.000613 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005274, test:0.000380 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005104, test:0.000952 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.009664, test:0.000508 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005560, test:0.000378 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005838, test:0.000416 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005040, test:0.000317 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005046, test:0.000535 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.004632, test:0.000342 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005078, test:0.000354 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005516, test:0.000329 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005325, test:0.000333 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004801, test:0.000330 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005368, test:0.000319 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005304, test:0.000328 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004640, test:0.000295 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005432, test:0.000341 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006005, test:0.000334 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005232, test:0.000340 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005146, test:0.000314 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005001, test:0.000342 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005054, test:0.000325 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.007592, test:0.000323 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005357, test:0.000321 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005123, test:0.000361 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005900, test:0.000335 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006013, test:0.000307 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004830, test:0.000354 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005236, test:0.000324 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005557, test:0.000303 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004621, test:0.000335 | lr:0.000100\n",
      "Mean absolute error:  1.7119719114467389\n",
      "Root mean squared error:  5.800787269869845\n",
      "Epoch[1/100] | loss train:0.062045, test:0.004278 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012155, test:0.002930 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011130, test:0.001403 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009860, test:0.001009 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.020121, test:0.014240 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012735, test:0.000566 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007855, test:0.001561 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009603, test:0.007891 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008923, test:0.002247 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007659, test:0.000302 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.024884, test:0.004750 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.012535, test:0.000568 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007300, test:0.000386 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009157, test:0.000310 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007677, test:0.003997 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009253, test:0.000420 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008658, test:0.000467 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008491, test:0.002003 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008082, test:0.002128 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007676, test:0.000461 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007599, test:0.001469 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007801, test:0.000524 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007289, test:0.001399 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008210, test:0.000846 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007632, test:0.000449 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006760, test:0.000407 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006399, test:0.000528 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.016351, test:0.005755 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008603, test:0.001878 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007370, test:0.000436 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007836, test:0.000468 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007622, test:0.000321 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006818, test:0.000502 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006258, test:0.000503 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006919, test:0.000934 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007265, test:0.004222 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006761, test:0.000335 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007317, test:0.000420 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006711, test:0.000378 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.012669, test:0.002147 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007304, test:0.000526 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006193, test:0.000297 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007577, test:0.000301 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005400, test:0.000303 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005498, test:0.000312 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005521, test:0.000449 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005494, test:0.000316 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006393, test:0.000344 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005372, test:0.000329 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005131, test:0.000373 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005544, test:0.000501 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005520, test:0.000383 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005710, test:0.000297 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005813, test:0.000617 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005283, test:0.000334 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006271, test:0.000286 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005150, test:0.000398 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.006385, test:0.000386 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.008178, test:0.000318 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005259, test:0.000339 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006195, test:0.000330 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.011813, test:0.000300 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006284, test:0.000422 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005565, test:0.000323 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005067, test:0.000322 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.009303, test:0.000378 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005456, test:0.000346 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.007092, test:0.000289 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.006535, test:0.000383 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005132, test:0.000298 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004811, test:0.000401 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006047, test:0.000326 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005700, test:0.000280 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005508, test:0.000335 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006972, test:0.000312 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006942, test:0.000456 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005442, test:0.000506 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005150, test:0.000304 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.006506, test:0.000550 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006444, test:0.000290 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004980, test:0.000299 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.007383, test:0.000313 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005340, test:0.000284 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[84/100] | loss train:0.004901, test:0.000278 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005389, test:0.000335 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005428, test:0.000287 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.006220, test:0.000282 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005023, test:0.000287 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004988, test:0.000273 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005068, test:0.000287 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005001, test:0.000289 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005335, test:0.000282 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005309, test:0.000291 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005161, test:0.000279 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004800, test:0.000290 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005250, test:0.000268 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004942, test:0.000279 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004930, test:0.000277 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004910, test:0.000260 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.007094, test:0.000264 | lr:0.000100\n",
      "Mean absolute error:  1.7479213494659471\n",
      "Root mean squared error:  5.801096699322876\n",
      "Epoch[1/100] | loss train:0.058369, test:0.001482 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011405, test:0.000768 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011675, test:0.003513 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009147, test:0.000884 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010906, test:0.000317 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010182, test:0.000338 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008006, test:0.000295 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009072, test:0.000963 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.006807, test:0.001464 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009179, test:0.001477 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010925, test:0.006989 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010156, test:0.003784 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008128, test:0.000723 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007531, test:0.000855 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009392, test:0.001921 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007383, test:0.000476 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007294, test:0.000532 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007299, test:0.000658 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006845, test:0.001244 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007053, test:0.001609 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008015, test:0.000370 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006778, test:0.000844 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007957, test:0.001054 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007397, test:0.000706 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008274, test:0.000433 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007904, test:0.000643 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008528, test:0.004660 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006868, test:0.001007 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006864, test:0.001945 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007573, test:0.000458 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007097, test:0.000334 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007455, test:0.000344 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006631, test:0.000452 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007915, test:0.000811 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006969, test:0.000424 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006924, test:0.000383 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006766, test:0.001148 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007135, test:0.000740 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006965, test:0.002876 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007120, test:0.000465 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005409, test:0.000546 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005387, test:0.000390 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005883, test:0.000373 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006664, test:0.000362 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005534, test:0.000543 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006801, test:0.000414 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006674, test:0.000503 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005099, test:0.000391 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005301, test:0.000367 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005357, test:0.000396 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006057, test:0.000338 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005286, test:0.000425 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005879, test:0.000395 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005438, test:0.000397 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.004864, test:0.000378 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.006587, test:0.000317 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005699, test:0.000351 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004997, test:0.000473 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005177, test:0.000413 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005604, test:0.000412 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005240, test:0.000503 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006075, test:0.000355 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005190, test:0.000598 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006811, test:0.000550 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005761, test:0.000383 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004899, test:0.000313 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005235, test:0.000341 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005091, test:0.000523 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005808, test:0.000516 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.007113, test:0.000351 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005210, test:0.000614 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005117, test:0.000376 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005260, test:0.000390 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005216, test:0.000396 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.007673, test:0.000340 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005601, test:0.000301 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005129, test:0.000374 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005851, test:0.000413 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005295, test:0.000935 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005992, test:0.000327 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004817, test:0.000323 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005451, test:0.000342 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005645, test:0.000318 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005884, test:0.000356 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005102, test:0.000326 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005796, test:0.000339 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004933, test:0.000325 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005418, test:0.000312 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005384, test:0.000338 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005210, test:0.000338 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005323, test:0.000331 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004842, test:0.000329 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.006125, test:0.000325 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004961, test:0.000353 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004674, test:0.000325 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004876, test:0.000318 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.006154, test:0.000304 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.006340, test:0.000311 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004849, test:0.000314 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.006665, test:0.000326 | lr:0.000100\n",
      "Mean absolute error:  1.663835071497667\n",
      "Root mean squared error:  5.791158372015208\n",
      "Epoch[1/100] | loss train:0.051868, test:0.001459 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.021124, test:0.004095 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.014685, test:0.001300 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009953, test:0.000715 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009104, test:0.000298 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007495, test:0.001565 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009053, test:0.000313 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/100] | loss train:0.008468, test:0.004350 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008493, test:0.000641 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008011, test:0.001133 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008570, test:0.003283 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009805, test:0.002275 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007419, test:0.000747 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008868, test:0.000467 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007182, test:0.000548 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007399, test:0.000515 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008528, test:0.004003 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009946, test:0.000350 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007611, test:0.001069 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006721, test:0.001042 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007368, test:0.001904 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008983, test:0.000452 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007499, test:0.000749 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007750, test:0.000542 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007416, test:0.004631 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007194, test:0.000856 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008341, test:0.000462 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007488, test:0.001974 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008852, test:0.000596 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008521, test:0.000574 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007418, test:0.000371 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008030, test:0.000910 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007924, test:0.000742 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006872, test:0.001569 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007912, test:0.000461 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008297, test:0.000672 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006917, test:0.002417 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008664, test:0.000669 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006820, test:0.001651 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007278, test:0.002572 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007634, test:0.000410 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006385, test:0.000414 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006204, test:0.000358 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006400, test:0.000518 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006522, test:0.000367 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005713, test:0.000368 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005478, test:0.000456 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006189, test:0.000389 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005154, test:0.000375 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005020, test:0.001062 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006447, test:0.000640 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004936, test:0.000379 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006388, test:0.000420 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005905, test:0.000630 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005361, test:0.000383 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005652, test:0.000314 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005266, test:0.000339 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005793, test:0.000339 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005180, test:0.000669 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005020, test:0.000595 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004977, test:0.000632 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.006841, test:0.000541 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.007681, test:0.000581 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005357, test:0.000482 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005933, test:0.000433 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005084, test:0.000356 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005613, test:0.000506 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005221, test:0.000325 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005477, test:0.000369 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.004894, test:0.000582 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006127, test:0.000821 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004992, test:0.000374 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005284, test:0.000599 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005331, test:0.000386 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005209, test:0.000477 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005387, test:0.000399 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005758, test:0.000566 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.007149, test:0.000348 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005265, test:0.000502 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.006127, test:0.000331 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005608, test:0.000365 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004949, test:0.000370 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006216, test:0.000370 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005062, test:0.000332 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005402, test:0.000414 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004642, test:0.000352 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005843, test:0.000332 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.007045, test:0.000329 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004796, test:0.000354 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.008141, test:0.000326 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006009, test:0.000380 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005051, test:0.000369 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005792, test:0.000365 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005595, test:0.000334 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.006061, test:0.000362 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005779, test:0.000338 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004912, test:0.000370 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004978, test:0.000332 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005285, test:0.000348 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004898, test:0.000316 | lr:0.000100\n",
      "Mean absolute error:  1.6604485081007017\n",
      "Root mean squared error:  5.791922480675064\n",
      "Epoch[1/100] | loss train:0.047180, test:0.010709 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.018622, test:0.005928 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013637, test:0.002823 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009362, test:0.000874 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.017311, test:0.000517 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012529, test:0.000362 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008240, test:0.012610 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.012372, test:0.000571 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009132, test:0.002560 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008859, test:0.001670 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.012056, test:0.004371 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010285, test:0.000617 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008156, test:0.000758 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009028, test:0.001455 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008922, test:0.000456 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009281, test:0.001791 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009105, test:0.000421 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009967, test:0.006513 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.010500, test:0.001670 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.013847, test:0.000437 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007766, test:0.000367 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009579, test:0.000455 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008610, test:0.005443 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008346, test:0.000570 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.011262, test:0.002951 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007396, test:0.006245 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007421, test:0.000425 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006995, test:0.000966 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008119, test:0.000875 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008523, test:0.002291 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008022, test:0.000413 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006842, test:0.001116 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[33/100] | loss train:0.009052, test:0.000507 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007387, test:0.000383 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007841, test:0.003050 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007623, test:0.000423 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008067, test:0.002310 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008181, test:0.000709 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.009403, test:0.001993 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007379, test:0.001121 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006913, test:0.000412 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005722, test:0.000387 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.009403, test:0.000427 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.007294, test:0.000462 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005966, test:0.000377 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005535, test:0.000554 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005676, test:0.000358 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005561, test:0.000419 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005497, test:0.000386 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005205, test:0.000512 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005603, test:0.000517 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005458, test:0.000347 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005601, test:0.000501 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005427, test:0.000325 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.012100, test:0.000355 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.008181, test:0.000576 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005866, test:0.000393 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005620, test:0.000379 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006024, test:0.000406 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005545, test:0.000391 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006134, test:0.000430 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005667, test:0.000376 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006087, test:0.000460 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005508, test:0.000365 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005550, test:0.000461 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005641, test:0.000471 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005800, test:0.000471 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.006172, test:0.000340 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005791, test:0.000328 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005543, test:0.000447 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004934, test:0.000333 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006854, test:0.000488 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.006043, test:0.000479 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005995, test:0.000391 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005481, test:0.000394 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006413, test:0.000366 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005414, test:0.000335 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005154, test:0.000343 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005407, test:0.000309 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005379, test:0.000392 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005271, test:0.000357 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004964, test:0.000346 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005299, test:0.000333 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005036, test:0.000302 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004988, test:0.000344 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005225, test:0.000329 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005125, test:0.000323 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005401, test:0.000360 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005571, test:0.000328 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004957, test:0.000350 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006036, test:0.000331 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005230, test:0.000317 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005381, test:0.000310 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004924, test:0.000363 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005266, test:0.000306 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005488, test:0.000341 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005603, test:0.000342 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005430, test:0.000344 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005597, test:0.000350 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005293, test:0.000343 | lr:0.000100\n",
      "Mean absolute error:  1.8006179391913024\n",
      "Root mean squared error:  5.849739366009332\n",
      "Epoch[1/100] | loss train:0.073290, test:0.002375 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.019106, test:0.000958 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.014586, test:0.001218 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010054, test:0.001579 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008505, test:0.001187 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008741, test:0.000306 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009903, test:0.001241 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008790, test:0.000681 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007715, test:0.001546 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008212, test:0.004565 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008702, test:0.000571 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007832, test:0.000320 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007342, test:0.001720 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009202, test:0.000348 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008264, test:0.000558 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009878, test:0.001475 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009935, test:0.002527 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007990, test:0.001350 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007014, test:0.000735 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007082, test:0.000412 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007672, test:0.000669 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007305, test:0.001879 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008298, test:0.000438 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.010676, test:0.000370 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007431, test:0.000932 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007347, test:0.001275 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007308, test:0.000797 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007536, test:0.001980 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008519, test:0.000788 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007548, test:0.000450 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008343, test:0.002277 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006585, test:0.002180 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006639, test:0.000359 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007577, test:0.000491 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006400, test:0.000834 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007583, test:0.001059 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007051, test:0.001375 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007294, test:0.000372 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007222, test:0.000414 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007000, test:0.000402 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005692, test:0.000546 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005622, test:0.000406 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006018, test:0.000477 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005216, test:0.000474 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005492, test:0.000391 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005587, test:0.000419 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005617, test:0.000419 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006206, test:0.000350 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005381, test:0.000368 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004916, test:0.000430 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006864, test:0.000376 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.010105, test:0.000431 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005819, test:0.000363 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.006084, test:0.000326 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006497, test:0.000439 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.004853, test:0.000391 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005479, test:0.000372 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[58/100] | loss train:0.005214, test:0.000362 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005176, test:0.000390 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.009140, test:0.000448 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005410, test:0.000347 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005468, test:0.000354 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005442, test:0.000338 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005365, test:0.000456 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005042, test:0.000486 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005779, test:0.000551 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005338, test:0.000407 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005022, test:0.000452 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004890, test:0.000299 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005186, test:0.000385 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005193, test:0.000357 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.004958, test:0.000476 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.013918, test:0.000351 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005147, test:0.000327 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.006107, test:0.000520 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004975, test:0.000469 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005158, test:0.000345 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.008954, test:0.000351 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004916, test:0.000308 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005964, test:0.000404 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004632, test:0.000275 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004876, test:0.000317 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005347, test:0.000333 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.007336, test:0.000306 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004817, test:0.000340 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.009028, test:0.000333 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005045, test:0.000304 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005051, test:0.000299 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005264, test:0.000279 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005374, test:0.000316 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.009902, test:0.000307 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004860, test:0.000320 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004653, test:0.000303 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005175, test:0.000322 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.006417, test:0.000316 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.005867, test:0.000311 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005350, test:0.000319 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.010993, test:0.000384 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.004821, test:0.000306 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004866, test:0.000308 | lr:0.000100\n",
      "Mean absolute error:  1.6746776221342048\n",
      "Root mean squared error:  5.78898190929653\n",
      "Epoch[1/100] | loss train:0.048904, test:0.000358 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009738, test:0.000360 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009437, test:0.001546 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010545, test:0.001067 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.014932, test:0.000589 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010958, test:0.000570 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008245, test:0.000384 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008073, test:0.007333 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009441, test:0.001531 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007433, test:0.003784 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007815, test:0.002208 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007747, test:0.001587 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007447, test:0.001075 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007743, test:0.000902 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006776, test:0.000498 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007178, test:0.000372 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008609, test:0.000580 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007117, test:0.002691 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007695, test:0.001127 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006883, test:0.000885 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008754, test:0.000336 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007156, test:0.000887 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007451, test:0.000378 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007284, test:0.000451 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007798, test:0.002942 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008143, test:0.000993 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006421, test:0.000478 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007129, test:0.000366 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.009099, test:0.001659 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007847, test:0.000379 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007149, test:0.001669 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006121, test:0.000491 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007737, test:0.000602 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006890, test:0.000712 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007114, test:0.000448 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007150, test:0.000488 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006960, test:0.001656 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006205, test:0.004433 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007226, test:0.000399 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006217, test:0.002260 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006619, test:0.000472 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007002, test:0.000429 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005555, test:0.000373 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006030, test:0.000388 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006355, test:0.000360 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005156, test:0.000380 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005410, test:0.000328 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006609, test:0.000402 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007179, test:0.000472 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005313, test:0.000309 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004861, test:0.000312 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005414, test:0.000475 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006049, test:0.000321 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005668, test:0.000524 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005133, test:0.000639 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005253, test:0.000462 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005438, test:0.000348 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.004849, test:0.000358 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005208, test:0.000430 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004995, test:0.000382 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.006069, test:0.000533 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005985, test:0.000349 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005775, test:0.000283 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005411, test:0.000332 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004945, test:0.000356 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.004990, test:0.000387 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005964, test:0.000547 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005021, test:0.000462 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.004600, test:0.000310 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005789, test:0.000308 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.006449, test:0.000270 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005623, test:0.000335 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005296, test:0.000315 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.004811, test:0.000529 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005422, test:0.000338 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004934, test:0.000296 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005124, test:0.000434 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005055, test:0.000330 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004805, test:0.000316 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005258, test:0.000588 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.004603, test:0.000322 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005063, test:0.000311 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[83/100] | loss train:0.004930, test:0.000330 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005776, test:0.000312 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.004698, test:0.000316 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004799, test:0.000339 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005410, test:0.000362 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004980, test:0.000301 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004767, test:0.000278 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005185, test:0.000316 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005767, test:0.000333 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004776, test:0.000307 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005355, test:0.000311 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005062, test:0.000297 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005385, test:0.000322 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004823, test:0.000289 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005160, test:0.000320 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005111, test:0.000294 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005919, test:0.000295 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004806, test:0.000302 | lr:0.000100\n",
      "Mean absolute error:  1.6633209786084213\n",
      "Root mean squared error:  5.772059114049527\n",
      "Epoch[1/100] | loss train:0.055466, test:0.000971 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012811, test:0.001463 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010278, test:0.001217 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010458, test:0.000343 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010572, test:0.000500 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008632, test:0.000290 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008069, test:0.000385 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010308, test:0.000477 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007626, test:0.000401 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007471, test:0.000352 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008954, test:0.003831 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009663, test:0.002086 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008089, test:0.005702 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.011684, test:0.003824 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.015869, test:0.004258 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010275, test:0.001417 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008388, test:0.000519 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007585, test:0.001418 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007928, test:0.001995 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009906, test:0.004782 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007969, test:0.000476 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007562, test:0.000922 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.013099, test:0.001257 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.014632, test:0.005039 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008893, test:0.001357 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007367, test:0.003218 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008181, test:0.001708 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007057, test:0.000466 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006946, test:0.001445 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007020, test:0.001583 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008039, test:0.000468 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007143, test:0.004135 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008330, test:0.002902 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007823, test:0.000406 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006897, test:0.000955 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008235, test:0.000543 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007529, test:0.000983 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006678, test:0.000411 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008139, test:0.001009 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007025, test:0.000335 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005645, test:0.000374 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005555, test:0.000502 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005436, test:0.000355 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005032, test:0.000364 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005561, test:0.000356 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004868, test:0.000342 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005270, test:0.000362 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005667, test:0.000313 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005069, test:0.000449 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005432, test:0.000461 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005130, test:0.000424 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005436, test:0.000539 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005363, test:0.000495 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005911, test:0.000307 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005081, test:0.000319 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005215, test:0.000339 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004979, test:0.000749 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005447, test:0.000362 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004619, test:0.000380 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.004813, test:0.000345 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005135, test:0.000326 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.004904, test:0.000339 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005792, test:0.000362 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.010877, test:0.000368 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005377, test:0.000362 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005800, test:0.000441 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005843, test:0.000315 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005007, test:0.000378 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005441, test:0.000384 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005291, test:0.000330 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.007670, test:0.000419 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006225, test:0.000437 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005364, test:0.000383 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005522, test:0.000334 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005869, test:0.000644 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005868, test:0.000430 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004898, test:0.000389 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006065, test:0.000360 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.004828, test:0.000413 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005077, test:0.000305 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005184, test:0.000327 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005525, test:0.000391 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005473, test:0.000336 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.008877, test:0.000332 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005005, test:0.000315 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005107, test:0.000314 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004782, test:0.000334 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005511, test:0.000301 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005350, test:0.000366 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004797, test:0.000328 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.004983, test:0.000317 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.004937, test:0.000317 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005180, test:0.000324 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005169, test:0.000346 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.009398, test:0.000326 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004853, test:0.000338 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004771, test:0.000311 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005249, test:0.000323 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.006622, test:0.000312 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005411, test:0.000307 | lr:0.000100\n",
      "Mean absolute error:  1.721611515701413\n",
      "Root mean squared error:  5.803099439918004\n",
      "Epoch[1/100] | loss train:0.050293, test:0.001859 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.019784, test:0.008650 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.014105, test:0.000329 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012933, test:0.001554 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009676, test:0.000382 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010275, test:0.000421 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/100] | loss train:0.012114, test:0.000366 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008924, test:0.001367 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008802, test:0.000390 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011352, test:0.000403 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007507, test:0.000786 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008478, test:0.006711 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009904, test:0.000376 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009906, test:0.001233 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008900, test:0.000375 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007554, test:0.001691 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008170, test:0.001215 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009086, test:0.002005 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007551, test:0.000417 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008797, test:0.000356 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008648, test:0.001123 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007027, test:0.000390 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008736, test:0.000376 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007113, test:0.001859 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.011225, test:0.000984 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007694, test:0.001002 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007839, test:0.000723 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007770, test:0.000513 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007643, test:0.000876 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007820, test:0.000548 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007160, test:0.000827 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007036, test:0.000928 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008176, test:0.007141 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008271, test:0.001509 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007525, test:0.000461 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007583, test:0.000385 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006672, test:0.002319 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007735, test:0.000807 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007019, test:0.000450 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007345, test:0.000464 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007025, test:0.000413 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006398, test:0.000404 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005979, test:0.000397 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006204, test:0.000440 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.018285, test:0.000416 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005638, test:0.000400 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006540, test:0.000449 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005305, test:0.000401 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005666, test:0.000417 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005483, test:0.000425 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.006461, test:0.000361 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004932, test:0.000350 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.004922, test:0.000389 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.004907, test:0.000346 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005353, test:0.000526 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005309, test:0.000422 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.004925, test:0.000367 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005604, test:0.000362 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.004945, test:0.000358 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005018, test:0.000557 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005455, test:0.000365 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.009287, test:0.000363 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005567, test:0.000361 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005706, test:0.000386 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.006128, test:0.000514 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.006033, test:0.000372 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005619, test:0.000389 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005221, test:0.000370 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005517, test:0.000789 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005361, test:0.000343 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.004920, test:0.000503 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005160, test:0.000721 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005507, test:0.000350 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.007100, test:0.000346 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005467, test:0.000484 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005586, test:0.000323 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.006030, test:0.000800 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005387, test:0.000450 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005406, test:0.000319 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.004916, test:0.000502 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005333, test:0.000344 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005759, test:0.000346 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.004988, test:0.000362 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005242, test:0.000312 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005102, test:0.000411 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005195, test:0.000336 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005513, test:0.000321 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.005478, test:0.000333 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005035, test:0.000338 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004831, test:0.000358 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005250, test:0.000329 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005167, test:0.000343 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005658, test:0.000333 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.004663, test:0.000319 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005031, test:0.000388 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.006230, test:0.000311 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.006571, test:0.000350 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.005099, test:0.000311 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005104, test:0.000334 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004993, test:0.000360 | lr:0.000100\n",
      "Mean absolute error:  1.7327181472965854\n",
      "Root mean squared error:  5.834129178548407\n",
      "Epoch[1/100] | loss train:0.064602, test:0.001170 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012595, test:0.000366 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011010, test:0.003124 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010096, test:0.000372 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012492, test:0.001271 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009939, test:0.006125 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009156, test:0.002365 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009423, test:0.000860 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008680, test:0.000609 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009646, test:0.003968 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010839, test:0.004200 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008868, test:0.000423 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008587, test:0.001014 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007412, test:0.000340 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.010059, test:0.001731 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008484, test:0.002492 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008394, test:0.002001 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008085, test:0.000392 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.010650, test:0.000388 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008302, test:0.000907 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008670, test:0.001267 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.015758, test:0.003656 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009965, test:0.000555 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.017957, test:0.001178 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010303, test:0.000667 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007794, test:0.000410 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008527, test:0.001195 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009435, test:0.000406 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007718, test:0.000676 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007705, test:0.000614 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007950, test:0.000801 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[32/100] | loss train:0.007937, test:0.003009 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009044, test:0.001085 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007197, test:0.003219 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007150, test:0.001203 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007717, test:0.000364 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006799, test:0.004025 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007962, test:0.001179 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008418, test:0.000510 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008857, test:0.002694 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006862, test:0.000368 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006118, test:0.000416 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006629, test:0.000342 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005123, test:0.000414 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005562, test:0.000390 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005591, test:0.000847 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006116, test:0.000393 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005859, test:0.000490 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005681, test:0.000477 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006324, test:0.000546 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.005962, test:0.000483 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005968, test:0.000370 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005649, test:0.000337 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005946, test:0.000615 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.006031, test:0.000377 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005480, test:0.000435 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.005985, test:0.000941 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005357, test:0.000357 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.005526, test:0.000331 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005999, test:0.000371 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005889, test:0.000317 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005313, test:0.000391 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.006559, test:0.000327 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.005726, test:0.000368 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005762, test:0.000488 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005952, test:0.000387 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.005965, test:0.000358 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005906, test:0.000332 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005540, test:0.000580 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.007863, test:0.000344 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.007338, test:0.000297 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.006881, test:0.000349 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005870, test:0.000384 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005189, test:0.000347 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005597, test:0.000732 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.005844, test:0.000336 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005892, test:0.000371 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005408, test:0.000309 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005525, test:0.000333 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005861, test:0.000611 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.006786, test:0.000316 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.005291, test:0.000312 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005880, test:0.000308 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004968, test:0.000331 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005980, test:0.000302 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.005937, test:0.000315 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.004917, test:0.000295 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.006868, test:0.000361 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005225, test:0.000329 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005225, test:0.000305 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.005396, test:0.000303 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.005304, test:0.000294 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.005529, test:0.000288 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005587, test:0.000343 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.005457, test:0.000334 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004877, test:0.000308 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005167, test:0.000322 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.007102, test:0.000321 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005628, test:0.000344 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.005111, test:0.000304 | lr:0.000100\n",
      "Mean absolute error:  1.6852798756406784\n",
      "Root mean squared error:  5.786906221562268\n",
      "Epoch[1/100] | loss train:0.057189, test:0.000390 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012922, test:0.000333 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011916, test:0.000514 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009655, test:0.004321 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009488, test:0.004196 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008697, test:0.000451 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008976, test:0.004358 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011951, test:0.001664 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008933, test:0.004594 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009511, test:0.000990 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010236, test:0.001723 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007597, test:0.000417 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010131, test:0.007936 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008136, test:0.000588 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007280, test:0.000472 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008927, test:0.000685 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007723, test:0.003097 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010847, test:0.004932 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007684, test:0.000530 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008958, test:0.001012 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008024, test:0.000421 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007970, test:0.000386 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007025, test:0.000637 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007174, test:0.003964 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007473, test:0.001718 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007348, test:0.000470 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007127, test:0.002240 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006937, test:0.000413 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007549, test:0.000607 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010414, test:0.000423 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007075, test:0.000526 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006342, test:0.000812 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007552, test:0.000612 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.010444, test:0.000854 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008291, test:0.000585 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006857, test:0.000758 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006743, test:0.000638 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009822, test:0.000936 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007838, test:0.001464 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006737, test:0.000428 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005670, test:0.000422 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005457, test:0.000467 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005883, test:0.000431 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.008046, test:0.000379 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006282, test:0.000437 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005301, test:0.000479 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007813, test:0.000417 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005145, test:0.000474 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006999, test:0.000332 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005684, test:0.000394 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004797, test:0.000397 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.005330, test:0.000394 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.005806, test:0.000466 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005379, test:0.000433 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005198, test:0.000420 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005475, test:0.000571 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[57/100] | loss train:0.005234, test:0.000440 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005507, test:0.000409 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.006053, test:0.000378 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.007210, test:0.000359 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.004764, test:0.000460 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005341, test:0.000358 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005224, test:0.000425 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.004770, test:0.000354 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.005044, test:0.000450 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005494, test:0.000420 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.006475, test:0.000502 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.005657, test:0.000365 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.005257, test:0.000360 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.005546, test:0.000403 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005219, test:0.000360 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005700, test:0.000402 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.005164, test:0.000724 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005037, test:0.000319 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005349, test:0.000501 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.006778, test:0.000396 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.005334, test:0.000348 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.006292, test:0.000359 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005189, test:0.000573 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005656, test:0.000320 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.007058, test:0.000335 | lr:0.000100\n",
      "Epoch[82/100] | loss train:0.004867, test:0.000314 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.006629, test:0.000340 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.005184, test:0.000322 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005305, test:0.000330 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.004850, test:0.000356 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005023, test:0.000312 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004851, test:0.000348 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.004770, test:0.000335 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.005744, test:0.000353 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.006227, test:0.000336 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.008217, test:0.000387 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004959, test:0.000343 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005118, test:0.000341 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004836, test:0.000324 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004677, test:0.000394 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.005875, test:0.000347 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004983, test:0.000340 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.007884, test:0.000356 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004770, test:0.000327 | lr:0.000100\n",
      "Mean absolute error:  1.7306303953495883\n",
      "Root mean squared error:  5.808008303806931\n",
      "Epoch[1/100] | loss train:0.054161, test:0.002479 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010651, test:0.003047 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011769, test:0.005875 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009510, test:0.000333 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009949, test:0.006383 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008153, test:0.002274 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011232, test:0.003084 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.012396, test:0.001471 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011544, test:0.000682 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009465, test:0.000659 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008112, test:0.000705 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009428, test:0.000721 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008249, test:0.001055 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006447, test:0.000556 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008100, test:0.002385 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010093, test:0.001701 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007529, test:0.002302 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007547, test:0.000366 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.011199, test:0.002138 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008339, test:0.000509 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006482, test:0.000531 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008258, test:0.000676 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006804, test:0.001239 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008246, test:0.000962 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007544, test:0.000540 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007424, test:0.000483 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.012934, test:0.006434 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.010238, test:0.000477 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.009499, test:0.002422 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006678, test:0.000577 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006360, test:0.000852 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007570, test:0.000862 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006105, test:0.000971 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007088, test:0.000562 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006564, test:0.000624 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006661, test:0.001306 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006122, test:0.001360 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007889, test:0.001136 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006606, test:0.000501 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007159, test:0.000339 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005709, test:0.000289 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005045, test:0.000334 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.004732, test:0.000329 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005020, test:0.000503 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005011, test:0.000312 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005549, test:0.000319 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004671, test:0.000530 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004569, test:0.000330 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004823, test:0.000441 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005038, test:0.000303 | lr:0.001000\n",
      "Epoch[51/100] | loss train:0.004853, test:0.000343 | lr:0.001000\n",
      "Epoch[52/100] | loss train:0.004738, test:0.000281 | lr:0.001000\n",
      "Epoch[53/100] | loss train:0.006189, test:0.000324 | lr:0.001000\n",
      "Epoch[54/100] | loss train:0.005496, test:0.000408 | lr:0.001000\n",
      "Epoch[55/100] | loss train:0.005357, test:0.000377 | lr:0.001000\n",
      "Epoch[56/100] | loss train:0.005837, test:0.000448 | lr:0.001000\n",
      "Epoch[57/100] | loss train:0.010178, test:0.000335 | lr:0.001000\n",
      "Epoch[58/100] | loss train:0.005276, test:0.000439 | lr:0.001000\n",
      "Epoch[59/100] | loss train:0.009394, test:0.000280 | lr:0.001000\n",
      "Epoch[60/100] | loss train:0.005312, test:0.000307 | lr:0.001000\n",
      "Epoch[61/100] | loss train:0.005210, test:0.000287 | lr:0.001000\n",
      "Epoch[62/100] | loss train:0.005074, test:0.000303 | lr:0.001000\n",
      "Epoch[63/100] | loss train:0.005401, test:0.000315 | lr:0.001000\n",
      "Epoch[64/100] | loss train:0.006074, test:0.000311 | lr:0.001000\n",
      "Epoch[65/100] | loss train:0.004840, test:0.000477 | lr:0.001000\n",
      "Epoch[66/100] | loss train:0.005368, test:0.000294 | lr:0.001000\n",
      "Epoch[67/100] | loss train:0.009131, test:0.000396 | lr:0.001000\n",
      "Epoch[68/100] | loss train:0.004876, test:0.000321 | lr:0.001000\n",
      "Epoch[69/100] | loss train:0.008120, test:0.000313 | lr:0.001000\n",
      "Epoch[70/100] | loss train:0.006413, test:0.000382 | lr:0.001000\n",
      "Epoch[71/100] | loss train:0.005064, test:0.000346 | lr:0.001000\n",
      "Epoch[72/100] | loss train:0.005635, test:0.000288 | lr:0.001000\n",
      "Epoch[73/100] | loss train:0.004823, test:0.000324 | lr:0.001000\n",
      "Epoch[74/100] | loss train:0.005964, test:0.000488 | lr:0.001000\n",
      "Epoch[75/100] | loss train:0.005208, test:0.000356 | lr:0.001000\n",
      "Epoch[76/100] | loss train:0.004986, test:0.000384 | lr:0.001000\n",
      "Epoch[77/100] | loss train:0.004836, test:0.000340 | lr:0.001000\n",
      "Epoch[78/100] | loss train:0.005565, test:0.000279 | lr:0.001000\n",
      "Epoch[79/100] | loss train:0.005145, test:0.000263 | lr:0.001000\n",
      "Epoch[80/100] | loss train:0.005861, test:0.000270 | lr:0.001000\n",
      "Epoch[81/100] | loss train:0.005123, test:0.000274 | lr:0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[82/100] | loss train:0.005804, test:0.000301 | lr:0.000100\n",
      "Epoch[83/100] | loss train:0.005452, test:0.000280 | lr:0.000100\n",
      "Epoch[84/100] | loss train:0.004770, test:0.000281 | lr:0.000100\n",
      "Epoch[85/100] | loss train:0.005010, test:0.000280 | lr:0.000100\n",
      "Epoch[86/100] | loss train:0.006352, test:0.000319 | lr:0.000100\n",
      "Epoch[87/100] | loss train:0.005810, test:0.000305 | lr:0.000100\n",
      "Epoch[88/100] | loss train:0.004621, test:0.000281 | lr:0.000100\n",
      "Epoch[89/100] | loss train:0.005499, test:0.000286 | lr:0.000100\n",
      "Epoch[90/100] | loss train:0.004952, test:0.000335 | lr:0.000100\n",
      "Epoch[91/100] | loss train:0.008766, test:0.000301 | lr:0.000100\n",
      "Epoch[92/100] | loss train:0.007880, test:0.000266 | lr:0.000100\n",
      "Epoch[93/100] | loss train:0.004999, test:0.000277 | lr:0.000100\n",
      "Epoch[94/100] | loss train:0.005056, test:0.000279 | lr:0.000100\n",
      "Epoch[95/100] | loss train:0.004842, test:0.000281 | lr:0.000100\n",
      "Epoch[96/100] | loss train:0.004710, test:0.000294 | lr:0.000100\n",
      "Epoch[97/100] | loss train:0.004747, test:0.000275 | lr:0.000100\n",
      "Epoch[98/100] | loss train:0.004966, test:0.000271 | lr:0.000100\n",
      "Epoch[99/100] | loss train:0.005259, test:0.000298 | lr:0.000100\n",
      "Epoch[100/100] | loss train:0.004514, test:0.000277 | lr:0.000100\n",
      "Mean absolute error:  1.6695005236512672\n",
      "Root mean squared error:  5.773634707779928\n"
     ]
    }
   ],
   "source": [
    "# 100 Epochs\n",
    "\n",
    "n_epochs = 100\n",
    "uni_absolute1 = []\n",
    "uni_root1 = []\n",
    "\n",
    "for i in range(n):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "\n",
    "    model = LSTMModel(input_size=config[\"model\"][\"input_size\"], hidden_layer_size=config[\"model\"][\"lstm_size\"], num_layers=config[\"model\"][\"num_lstm_layers\"], output_size=1, dropout=config[\"model\"][\"dropout\"])\n",
    "    model = model.to(config[\"training\"][\"device\"])\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.98), eps=1e-9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"training\"][\"scheduler_step_size\"], gamma=0.1)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_train, lr_train = run_epoch(train_dataloader, is_training=True)\n",
    "        loss_val, lr_val = run_epoch(val_dataloader)\n",
    "        scheduler.step()\n",
    "\n",
    "        print('Epoch[{}/{}] | loss train:{:.6f}, test:{:.6f} | lr:{:.6f}'\n",
    "                  .format(epoch+1, config[\"training\"][\"num_epoch\"], loss_train, loss_val, lr_train))\n",
    "        \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    predicted_train = np.array([])\n",
    "\n",
    "    for idx, (x, y) in enumerate(train_dataloader):\n",
    "        x = x.to(config[\"training\"][\"device\"])\n",
    "        out = model(x)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        predicted_train = np.concatenate((predicted_train, out))\n",
    "\n",
    "    predicted_val = np.array([])\n",
    "\n",
    "    for idx, (x, y) in enumerate(val_dataloader):\n",
    "        x = x.to(config[\"training\"][\"device\"])\n",
    "        out = model(x)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        predicted_val = np.concatenate((predicted_val, out))\n",
    "\n",
    "    data_y_train_pred = np.zeros(num_data_points)\n",
    "    data_y_val_pred = np.zeros(num_data_points)\n",
    "\n",
    "    data_y_train_pred[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(predicted_train)\n",
    "    data_y_val_pred[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(predicted_val)\n",
    "\n",
    "    mae = mean_absolute_error(close_price_data, data_y_train_pred + data_y_val_pred)\n",
    "    print(\"Mean absolute error: \", mae)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(close_price_data, data_y_train_pred+data_y_val_pred))\n",
    "    print(\"Root mean squared error: \", rmse)\n",
    "    \n",
    "    uni_absolute1.append(mae)\n",
    "    uni_root1.append(rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b03675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 30.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mean absolute error, no early stop\n",
    "\n",
    "mean = sum(uni_absolute1) / len(uni_absolute1)\n",
    "variance = sum([((x - mean) ** 2) for x in uni_absolute1]) / len(uni_absolute1)\n",
    "sd = variance ** 0.5\n",
    "\n",
    "m, bins, patches = plt.hist(x=uni_absolute1, bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('MAE for 100 Epochs')\n",
    "maxfreq = m.max()\n",
    "plt.text(1.75, 4.5, '\\u03BC={},\\n\\n\\u03C3={}$'.format(mean,sd))\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe832129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 30.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAPJUAAAHHCAYAAACU48PcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAADDxUlEQVR4nOzVe5BX9X3/8df3uyuLiLvILYC4QCygctGRizANFoNCNNairMZQa9RGJ+ViqpW0pgxKq6HRpLlZSEynxYnQOiAEaDVq03KxookKKrUxhiYTRaLSFDDgLrf9/dHJTva3oItFj/h9PGZ2ds/n8/5+zvOcZZZSc3NzcwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAN5j5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeO+9+OKLmThxYurq6lIqlfLd73636CR+w+rVq1MqlbJ06dKiU+BdVS46AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADe7xYuXJhSqdTyVV1dnRNPPDFXXXVVtmzZ0mZ+/PjxKZVKGThw4EHPe+SRR1rOWrp0aau95557Lg0NDenXr186duyYE088Meedd16+8Y1vtJrr379/q6bf/PrYxz72ts/0qU99Ks8991xuv/32fOc738nIkSMP440cvgULFuTSSy9NfX19SqVSrrrqqkPObt++Pdddd1169OiR4447Luecc06efvrpg86uXLkyZ555Zjp27Jj6+vrccsst2bdv39v2rF69+pDvr1Qq5R//8R/f6aMCh6G66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFr8xV/8RQYMGJDGxsY8/vjjWbhwYR599NFs2rQpHTt2bDXbsWPH/OQnP8kPfvCDjB49utXeokWL0rFjxzQ2NrZaf+yxx3LOOeekvr4+1157bXr16pWXXnopjz/+eL72ta9l5syZrebPOOOM/Mmf/Embzj59+rzlc7z55ptZv359/vzP/zwzZsw4nFfwjn3xi1/MG2+8kdGjR2fr1q2HnDtw4EA+/vGP55lnnsmsWbPSvXv3zJ8/P+PHj89TTz2VgQMHtsw++OCDmTx5csaPH59vfOMbee6553Lbbbfltddey4IFC9rVdf3112fUqFFt1seOHXv4DwkctuqiAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgaHH++edn5MiRSZJPf/rT6d69e774xS9m5cqVueyyy1rNnnzyydm3b1/+4R/+IaNHj25Zb2xszPLly/Pxj388999/f6vP3H777amrq8sPf/jDdOnSpdXea6+91qbnxBNPzBVXXHHYz/H6668nSZt7/F/s2rUrxx133CH316xZk/r6+pRKpXTu3PmQc0uXLs1jjz2WJUuWpKGhIUly2WWXZdCgQbnllluyePHiltmbbropw4cPz8MPP5zq6uokSW1tbb7whS/ks5/9bE455ZS37R43blzLfYD3XrnoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Wo0bNy5Jsnnz5oPuf/KTn8x9992XAwcOtKytWrUqu3fvzmWXXdZmfvPmzRkyZEi6dOnSZq9nz55HpPnWW29Nv379kiSzZs1KqVRK//79W/Y3bNiQ888/P7W1tencuXMmTJiQxx9/vNUZCxcuTKlUypo1azJt2rT07Nkzffv2fcv79uvXL6VS6W37li5dmg996EO55JJLWtZ69OiRyy67LCtWrEhTU1OS5Pnnn8/zzz+f6667LtXV1S2z06ZNS3Nzc5YuXfq292qvUqmUGTNmZNGiRRk8eHA6duyYESNGZO3atW1m2/P+kmT79u254YYb0r9//9TU1KRv37658sors23btlZzBw4cyO23356+ffumY8eOmTBhQn7yk5+0mnnxxRczZcqU9OrVKx07dkzfvn1z+eWXZ8eOHUfsHcC7pfrtRwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAg/nZz36WJDnhhBMOuj916tTceuutWb16dT760Y8mSRYvXpwJEyakZ8+ebeb79euX9evXZ9OmTRk6dOjb3n/v3r3Ztm1bm/Xjjjsuxx577EE/c8kll6RLly654YYb8slPfjIXXHBBOnfunCT5j//4j4wbNy61tbX53Oc+l2OOOSbf+ta3Mn78+KxZsyZnnXVWq7OmTZuWHj16ZM6cOdm1a9fb9rbHhg0bcuaZZ6ZcLrdaHz16dO6+++78+Mc/zrBhw7Jhw4YkyciRI1vN9enTJ3379m3ZfztvvPHGQd9ht27dUiqVWq7XrFmT++67L9dff31qamoyf/78fOxjH8sPfvCDlt9Ve9/fr371q4wbNy7/+Z//mWuuuSZnnnlmtm3blpUrV+bll19O9+7dW+77V3/1VymXy7npppuyY8eO3HHHHfn93//9PPHEE0mSPXv2ZNKkSWlqasrMmTPTq1evbNmyJf/0T/+U7du3p66url3vAYpSXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwtduzYkW3btqWxsTFPPPFE5s6dm5qamlx44YUHnR84cGBGjhyZxYsX56Mf/Wi2b9+eBx54IN/+9rcPOn/TTTfl/PPPzxlnnJHRo0dn3LhxmTBhQs4555wcc8wxbeYffvjh9OjRo836vHnz8md/9mcHvcfw4cNTW1ubG264IWeeeWauuOKKlr3Zs2dn7969efTRR/PhD384SXLllVdm8ODB+dznPpc1a9a0Oqtr1675/ve/n6qqqoO/sHdg69atOfvss9us9+7dO0nyyiuvZNiwYdm6dWur9f9/9pVXXmnX/a655ppDdvTq1avletOmTXnyySczYsSIJMnll1+ewYMHZ86cOVm2bFmS9r+/O++8M5s2bcqyZcty8cUXt9xj9uzZaW5ubtXR2NiYjRs3pkOHDkmSE044IZ/97GezadOmDB06NM8//3x++tOfZsmSJWloaGj53Jw5c9r1/FC06qIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBoce6557a67t+/f+6999707dv3kJ+ZOnVq/vIv/zLz58/P0qVLU1VVlYsvvjhPPfVUm9nzzjsv69evz7x58/LQQw9l/fr1ueOOO9KjR4/87d/+bS666KJW82eddVZuu+22NucMHDjwsJ9t//79efjhhzN58uR8+MMfblnv3bt3pk6dmm9/+9vZuXNnamtrW/auvfbaVFVVHfa93sqbb76ZmpqaNusdO3Zs2f/N74ea3blzZ7vuN2fOnIwbN67NeteuXVtdjx07NiNGjGi5rq+vz+/93u9l1apV2b9/f5K0+/3df//9Of3003PxxRe3uW+pVGp1ffXVV6dDhw4t179u/a//+q8MHTo0dXV1SZKHHnooF1xwQTp16tSu54b3i+qiAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgaPE3f/M3GTRoUHbs2JG/+7u/y9q1a1NTU/OWn7n88stz00035cEHH8yiRYty4YUX5vjjjz/k/KhRo7Js2bLs2bMnzzzzTJYvX56vfOUraWhoyMaNG3Paaae1zHbv3j3nnnvuEXm2119/Pbt3787gwYPb7J166qk5cOBAXnrppQwZMqRlfcCAAUfk3r/p2GOPTVNTU5v1xsbGlv3f/H6o2V/vv51hw4a16x0OHDiwzdqgQYOye/fuvP7660nS7ve3efPmTJkypV199fX1ra5POOGEJMn//M//JPnf38GNN96Yv/7rv86iRYsybty4XHTRRbniiitSV1fXrntAkcpFBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA0WL06NE599xzM2XKlKxcuTJDhw7N1KlT86tf/eqQn+ndu3fGjx+fL3/5y1m7dm2mTp3arnt16NAho0aNyhe+8IUsWLAge/fuzZIlS47UoxwRxx577BE/s3fv3tm6dWub9V+v9enTp2XuN9f//9lfzx3tqqqqDrre3Nzc8vOXv/zlPPvss/n85z+fN998M9dff32GDBmSl19++b3KhHesXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByNqqqqMm/evLzyyiu566673nJ26tSpWbduXWpra3PBBRcc9r1GjhyZJNm6des7am2PHj16pFOnTnnhhRfa7P3oRz9KuVzOSSed9K7d/9fOOOOMPP300zlw4ECr9SeeeCKdOnXKoEGDWuaS5Mknn2w198orr+Tll19u2T9SXnzxxTZrP/7xj9OpU6f06NHjsN7fySefnE2bNh3RvmHDhmX27NlZu3Zt1q1bly1btuSb3/zmEb0HvBvKRQcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwNFq/PjxGT16dL761a+msbHxkHMNDQ255ZZbMn/+/HTo0OGQc//2b/+W5ubmNusPPPBAkmTw4MH/9+hDqKqqysSJE7NixYr87Gc/a1l/9dVXs3jx4nzkIx9JbW3tu3b/X2toaMirr76aZcuWtaxt27YtS5Ysye/+7u+mpqYmSTJkyJCccsopufvuu7N///6W2QULFqRUKqWhoeGIdq1fvz5PP/10y/VLL72UFStWZOLEiamqqjqs9zdlypQ888wzWb58eZv7HOz3/1Z27tyZffv2tVobNmxYyuVympqaDussKEJ10QEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcDSbNWtWLr300ixcuDCf+cxnDjpTV1eXW2+99W3PmjlzZnbv3p2LL744p5xySvbs2ZPHHnss9913X/r375+rr7661fyWLVty7733tjmnc+fOmTx58mE/y2233ZZHHnkkH/nIRzJt2rRUV1fnW9/6VpqamnLHHXcc9nm/adWqVXnmmWeSJHv37s2zzz6b2267LUly0UUXZfjw4UmShoaGjBkzJldffXWef/75dO/ePfPnz8/+/fszd+7cVmfeeeedueiiizJx4sRcfvnl2bRpU+666658+tOfzqmnntqurnXr1qWxsbHN+vDhw1uakmTo0KGZNGlSrr/++tTU1GT+/PlJ0qqpve9v1qxZWbp0aS699NJcc801GTFiRH75y19m5cqV+eY3v5nTTz+9Xe1J8q//+q+ZMWNGLr300gwaNCj79u3Ld77znVRVVWXKlCntPgeKUl10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAczS655JKcfPLJ+dKXvpRrr702VVVV7/isL33pS1myZEkeeOCB3H333dmzZ0/q6+szbdq0zJ49O126dGk1v3HjxvzBH/xBm3P69euXyZMnH/b9hwwZknXr1uXmm2/OvHnzcuDAgZx11lm59957c9ZZZ73Dp/pf999/f+65556W6w0bNmTDhg1Jkr59+2b48OFJkqqqqjzwwAOZNWtWvv71r+fNN9/MqFGjsnDhwgwePLjVmRdeeGGWLVuWuXPnZubMmenRo0c+//nPZ86cOe3u+vrXv37Q9VtuuaWlKUl+53d+J2PHjs3cuXPz85//PKeddloWLlzYaqa9769z585Zt25dbrnllixfvjz33HNPevbsmQkTJqRv377tbk+S008/PZMmTcqqVauyZcuWdOrUKaeffnoefPDBjBkz5rDOgiKUmpubm4uOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB4vyqVSpk+fXruuuuuolPgA6dcdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFCZykUHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlalcdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFCZykUHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEevBQsWZPjw4amtrU1tbW3Gjh2bBx98sGW/sbEx06dPT7du3dK5c+dMmTIlr776aoHFAIevubk5d911V9EZ8IFUam5ubi46AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADg6rVq1KlVVVRk4cGCam5tzzz335M4778yGDRsyZMiQ/NEf/VH++Z//OQsXLkxdXV1mzJiRcrmcf//3fy86HQB4Hyg1Nzc3Fx0BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAfHB07do1d955ZxoaGtKjR48sXrw4DQ0NSZIf/ehHOfXUU7N+/fqMGTOm4FIAoGjVRQcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHwz79+/PkiVLsmvXrowdOzZPPfVU9u7dm3PPPbdl5pRTTkl9fX3Wr1+fMWPGHPScpqamNDU1tVwfOHAgv/zlL9OtW7eUSqV3/TkAgP+75ubmvPHGG+nTp0/K5fIh56rfwyYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgA+i5557L2LFj09jYmM6dO2f58uU57bTTsnHjxnTo0CFdunRpNf+hD30ov/jFLw553rx58zJ37tx3uRoAeC+89NJL6du37yH3q9/DFgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOADaPDgwdm4cWN27NiRpUuX5lOf+lTWrFnzjs+7+eabc+ONN7Zc79ixI/X19fnpT3+a2traI5EMALzLdu7cmQEDBuT4449/y7nq96gHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+IDq0KFDfuu3fitJMmLEiPzwhz/M1772tXziE5/Inj17sn379nTp0qVl/tVXX02vXr0OeV5NTU1qamrarHft2jW1tbVHvB8AOPKqq6uTJKVS6S3nyu9FDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFA5Dhw4kKampowYMSLHHHNMvv/977fsvfDCC/n5z3+esWPHFlgIALxfVBcdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABy9br755px//vmpr6/PG2+8kcWLF2f16tV56KGHUldXlz/8wz/MjTfemK5du6a2tjYzZ87M2LFjM2bMmKLTAYD3geqiAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAICj12uvvZYrr7wyW7duTV1dXYYPH56HHnoo5513XpLkK1/5SsrlcqZMmZKmpqZMmjQp8+fPL7gaAHi/KDU3NzcXHQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwKDt37kxdXV127NiR2traonMAgHZo7//f5fewCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoEW56AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKAylYsOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKlO56AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKAylYsOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKlN10QEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8F6ZPPnRohNafPe7Hyk6AaBw5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAylQuOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhM5aIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgKPXvHnzMmrUqBx//PHp2bNnJk+enBdeeKHVzPjx41MqlVp9feYznymoGAB4PykXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcvdasWZPp06fn8ccfzyOPPJK9e/dm4sSJ2bVrV6u5a6+9Nlu3bm35uuOOOwoqBgDeT6qLDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOXt/73vdaXS9cuDA9e/bMU089lbPPPrtlvVOnTunVq9d7nQcAvM+Viw4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPjh27NiRJOnatWur9UWLFqV79+4ZOnRobr755uzevbuIPADgfaa66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgg+HAgQP54z/+4/z2b/92hg4d2rI+derU9OvXL3369Mmzzz6bP/3TP80LL7yQZcuWHfScpqamNDU1tVzv3LkzSbJv377s27fv3X0IPvCqqpqLTmjh3zPwQdbev3HV73IHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUCGmT5+eTZs25dFHH221ft1117X8PGzYsPTu3TsTJkzI5s2bc/LJJ7c5Z968eZk7d26b9SeffDLHHXfckQ+nopx33s6iE1o88cQTRScAvGt27drVrrlSc3Nz87vcAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHzAzZgxIytWrMjatWszYMCAt5zdtWtXOnfunO9973uZNGlSm/2mpqY0NTW1XO/cuTMnnXRS/vu//zu1tbVHvJ3K8olPrC86ocV9940tOgHgXbNz585069YtO3bseMv/v6vfwyYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgA6a5uTkzZ87M8uXLs3r16gwYMOBtP7Nx48YkSe/evQ+6X1NTk5qamjbr1dXVqa6u/j/1wv79paITWvj3DHyQtfdvnL+EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwDs2ffr0LF68OCtWrMjxxx+fX/ziF0mSurq6HHvssdm8eXMWL16cCy64IN26dcuzzz6bG264IWeffXaGDx9ecD0AULTqogMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAo9eCBQuSJOPHj2+1/vd///e56qqr0qFDh/zLv/xLvvrVr2bXrl056aSTMmXKlMyePbuAWgDg/aa66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADg6NXc3PyW+yeddFLWrFnzHtUAAEebctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSmctEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAZSoXHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8P/bqNjar+nzg+NXDoR2wIk/rioEpE9gTe8jm8seIi9DJQxezUl64OYO4Llky3JiFmGxvFoKxUwObiYh74QpkER2ZsodkOgWnY0OXOgfZkqHgZsNaHEGktgu1T3vXpEFd99eeH3A+n+R+8bvO1XO+ve/mLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOWWpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHLKUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADllKUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJRTljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAopyx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUE5Z6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCcstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOWWpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHLKUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADllKUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJRTljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAopyx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUE5Z6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCcstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOWWpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHLKUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADllKUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJRTljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAopyx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUE5Z6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCcstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOWWpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHLKUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADllKUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJRTljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAopyx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUE5Z6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCcstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOWWpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHLKUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA56+Wlpb47Gc/G9XV1VFTUxMNDQ1x+PDhETtnzpyJtWvXxvTp0+O9731vrFq1Kl555ZVExQDAuSRLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACcv5566qlYu3ZtPPPMM/H4449HX19fLF26NHp6eoZ3brnllvjlL38Zu3fvjqeeeio6OjqisbExYTUAcK7IUwcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA569HH310xHn79u1RU1MTzz33XHzuc5+L06dPx/333x8PPPBALFmyJCIiWltb4yMf+Ug888wzsXDhwhTZAMA5Ik8dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFw4Tp8+HRER06ZNi4iI5557Lvr6+uLzn//88M6HP/zh+MAHPhAHDhyIhQsXnnWP3t7e6O3tHT53dXVFRER/f3/09/ePZT4lMG7cUOqEYf6egQvZaL/j8jHuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEpicHAwvv3tb8eVV14ZCxYsiIiI48ePR2VlZUyZMmXE7vvf//44fvz4m96npaUlNm7ceNa8ra0tJk2a9K53Uy7XXNOVOmHYs88+mzoBYMz09PSMai8f4w4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgJNauXRt/+ctfYv/+/e/oPt/5zneiubl5+NzV1RWzZ8+Oyy+/PCZPnvxOMym5LVsOpE4Y9rWv/V/qBIAx09XVNaq9fIw7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgBK4+eab41e/+lU8/fTTMWvWrOF5bW1tvPHGG/Haa6/FlClThuevvPJK1NbWvum9qqqqoqqq6qx5nueR5/m73k65DAxUpE4Y5u8ZuJCN9jsuG+MOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4AI2NDQUN998czzyyCOxb9++mDNnzojrn/nMZ2L8+PGxd+/e4dnhw4ejvb09rrjiiqJzAYBzTJ46AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADh/rV27Nh544IH4+c9/HtXV1XH8+PGIiLjoootiwoQJcdFFF0VTU1M0NzfHtGnTYvLkyfHNb34zrrjiili4cGHiegAgtTx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHD+2rZtW0REXH311SPmra2tsWbNmoiI+MEPfhBZlsWqVauit7c3li1bFvfee2/BpQDAuShPHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACcv4aGhv7rznve857YunVrbN26tYAiAOB8kqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJRTljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAopyx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUE5Z6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCcstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOWWpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHLKUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADllKUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJRTljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAopyx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUE5Z6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCcstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOWWpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHLKUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADllKUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJRTnjoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgLfX0LA/dcKwPXsWpU4A4AKSpQ4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADKKUsdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlFOWOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACinLHUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAULyXXnopdQIAQGSpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDizZ07NxYvXhw/+clP4syZM6lzAICSylIHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMX705/+FJ/4xCeiubk5amtr4+tf/3r88Y9/TJ0FAJRMljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKN6nPvWpuPvuu6OjoyN+/OMfR2dnZyxatCgWLFgQW7ZsiRMnTqROBABKIEsdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKST53k0NjbG7t2744477ogjR47Ehg0bYvbs2bF69ero7OxMnQgAXMCy1AEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOm1tbfGNb3wjZs6cGVu2bIkNGzbE0aNH4/HHH4+Ojo744he/mDoRALiA5akDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOJt2bIlWltb4/Dhw1FfXx87d+6M+vr6yLIsIiLmzJkT27dvj0svvTRtKABwQctTBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADF27ZtW3z1q1+NNWvWxMyZM990p6amJu6///6CywCAMslTBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADFe/HFF//rTmVlZdx4440F1AAAZZWlDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACK19raGrt37z5rvnv37tixY0eCIgCgjLLUAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDxWlpaYsaMGWfNa2pq4vbbb09QBACUUZY6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAChee3t7zJkz56z5JZdcEu3t7QmKAIAyylIHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMWrqamJQ4cOnTU/ePBgTJ8+PUERAFBGWeoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoHhf/vKX41vf+lY8+eSTMTAwEAMDA7Fv375Yt25dfOlLX0qdBwCURJ46AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACjepk2b4h//+EfU1dVFnucRETE4OBirV6+O22+/PXEdAFAWeeoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoHiVlZXx0EMPxaZNm+LgwYMxYcKE+PjHPx6XXHJJ6jQAoETy1AEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOvPnz4/58+enzgAASipPHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUb2BgILZv3x579+6Nf/3rXzE4ODji+r59+xKVAQBlkqcOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIq3bt262L59e3zhC1+IBQsWREVFReokAKCE8tQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQPEefPDB+OlPfxr19fWpUwCAEstSBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADFq6ysjLlz56bOAABKLksdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABRv/fr1cffdd8fQ0FDqFACgxPLUAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDx9u/fH08++WT8+te/jo997GMxfvz4EdcffvjhRGUAQJnkqQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA4k2ZMiVWrlyZOgMAKLk8dQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQvNbW1tQJAACRpQ4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0ujv748nnngifvSjH8Xrr78eEREdHR3R3d2duAwAKIs8dQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQvJdffjmWL18e7e3t0dvbG9dcc01UV1fHHXfcEb29vXHfffelTgQASiBLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUb926dXH55ZfHqVOnYsKECcPzlStXxt69exOWAQBlkqcOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIr3u9/9Lv7whz9EZWXliPmll14a//znPxNVAQBlk6UOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIo3ODgYAwMDZ82PHTsW1dXVo77P008/Hddee21cfPHFUVFREXv27Blxfc2aNVFRUTHitXz58neaDwBcILLUAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDxli5dGj/84Q+HzxUVFdHd3R3f+973or6+ftT36enpiU9+8pOxdevWt9xZvnx5dHZ2Dr927dr1TtIBgAtInjoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKN7mzZtj2bJl8dGPfjTOnDkT119/fbz44osxY8aM2LVr16jvs2LFilixYsXb7lRVVUVtbe07TQYALkB56gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgeLNmzYqDBw/Ggw8+GIcOHYru7u5oamqKr3zlKzFhwoR39Vm//e1vo6amJqZOnRpLliyJ2267LaZPn/6W+729vdHb2zt87urqioiI/v7+6O/vf1fbzhfjxg2lThh2vn8G3kuAYoz2Oy4f4w4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgHJXnedxwww1j+ozly5dHY2NjzJkzJ44ePRrf/e53Y8WKFXHgwIEYN27cm/5MS0tLbNy48ax5W1tbTJo0aUx7z1XXXNOVOmHYs88+mzrhHfFeAhSjp6dnVHsVQ0NDQ2PcAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJxjdu7c+bbXV69e/T/fs6KiIh555JFoaGh4y52XXnopLrvssnjiiSeirq7uTXd6e3ujt7d3+NzV1RWzZ8+OkydPxuTJk//nrgvBddcdSJ0w7KGHrkid8I54LwGK0dXVFdOnT4/Tp0+/7f/vvMAmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Byxbt26Eee+vr7497//HZWVlTFx4sRYvXr1mDz3gx/8YMyYMSOOHDkSdXV1b7pTVVUVVVVVZ83zPI88z8ek61w3MFCROmHY+f4ZeC8BijHa77hsjDsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAc9CpU6dGvLq7u+Pw4cOxaNGi2LVr15g999ixY3Hy5MmYOXPmmD0DADh/5KkDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHPDvHnz4vvf/37ccMMN8be//W1UP9Pd3R1HjhwZPv/973+PP//5zzFt2rSYNm1abNy4MVatWhW1tbVx9OjRuPXWW2Pu3LmxbNmysfo1AIDzSJ46AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADh35HkeHR0do95va2uLxYsXD5+bm5sjIuLGG2+Mbdu2xaFDh2LHjh3x2muvxcUXXxxLly6NTZs2RVVV1bveDgCcf/LUAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDxfvGLX4w4Dw0NRWdnZ9xzzz1x5ZVXjvo+V199dQwNDb3l9ccee+z/3QgAXPjy1AEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABA8RoaGkacKyoq4n3ve18sWbIkNm/enCYKACidPHUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAULzBwcHUCQAAkaUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyilPHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUr7m5edS7W7ZsGcMSAKDM8tQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQPGef/75eP7556Ovry8+9KEPRUTECy+8EOPGjYtPf/rTw3sVFRWpEgGAEshTBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADFu/baa6O6ujp27NgRU6dOjYiIU6dOxU033RRXXXVVrF+/PnEh56OGhv2pE4bt2bModQIAo5ClDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACKt3nz5mhpaYmpU6cOz6ZOnRq33XZbbN68OWEZAFAmWeoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoHhdXV1x4sSJs+YnTpyI119/PUERAFBGWeoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoHgrV66Mm266KR5++OE4duxYHDt2LH72s59FU1NTNDY2ps4DAEoiTx0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFO++++6LDRs2xPXXXx99fX0REZHneTQ1NcVdd92VuA4AKIs8dQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQvIkTJ8a9994bd911Vxw9ejQiIi677LKYNGlS4jIAoEyy1AEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAOp2dndHZ2Rnz5s2LSZMmxdDQUOokAKBEstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQPFOnjwZdXV1MX/+/Kivr4/Ozs6IiGhqaor169cnrgMAyiJLHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAU75Zbbonx48dHe3t7TJw4cXh+3XXXxaOPPpqwDAAokzx1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFC83/zmN/HYY4/FrFmzRsznzZsXL7/8cqIqAKBsstQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQPF6enpi4sSJZ81fffXVqKqqSlAEAJRRljoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKN5VV10VO3fuHD5XVFTE4OBg3HnnnbF48eKEZQBAmeSpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDi3XnnnVFXVxdtbW3xxhtvxK233hp//etf49VXX43f//73qfMAgJLIUwcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxVuwYEG88MILcc8990R1dXV0d3dHY2NjrF27NmbOnJk6rzANDftTJ4ywZ8+i1AkAUKg8dQAAAAAAAAAAAAAAAAAAAADAf9it83irq3p//K+zOQxHZBKBA8qkKaiJIirilCWjXpB7KxVNUTG0IDUqla4DOBIiTtfUZFAzhExE7ZsDRgoqKpJoOJUDlglqmRCoyHB+f/we7XvPPRyFJLfc83w+Hvvx2J/3eq+1Xmvtz+MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw2VqzZk369++f66+/Pv/5n/9Z6jgAQB1WKHUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4LNVv379PPvss6WOAQCQQqkDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJ+9b3zjG5k8eXKpYwAAdVx5qQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAn721a9dmypQpefDBB9OjR480bty42vjEiRNLlAwAqEvKSx0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+Oy8+uqr6dSpUxYvXpy99torSfL73/++Wk9ZWVkpogEAdVB5qQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAn52ddtopS5cuzW9+85skyVFHHZWrr746bdq0KXEyAKAuKpQ6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDZqaqqqvZ87733ZtWqVSVKAwDUdYVSBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABKp6qqqtQRAIA6rFDqAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBnp6ysLGVlZTVqAAClUF7qAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBnp6qqKieccEIaNmyYJPnwww9z6qmnpnHjxtX6Zs6cWYp4AEAdU17qAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBnZ+jQodWev/GNb5QoCQBAUl7qAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBnZ+rUqaWOAABQVCh1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoG4qlDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1E2FUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqpkKpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHVTodQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAuqlQ6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDdVCh1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoG4qlDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1E2FUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqpkKpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHVTodQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAuqlQ6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDdVCh1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoG4qlDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGy55s6dm4EDB6Zdu3YpKyvLrFmzqo1XVVXlvPPOS9u2bVNRUZHevXvnD3/4Q2nCAgCfO4VSBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2XKtWrcoee+yRa6+9doPj48ePz9VXX53rr78+TzzxRBo3bpx+/frlww8//IyTAgCfR+WlDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsuQYMGJABAwZscKyqqipXXnllzjnnnBxxxBFJkltuuSVt2rTJrFmzcvTRR3+WUQGAz6FCqQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/ze99tprWbZsWXr37l2sNWvWLD179sz8+fNLmAwA+LwoL3UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4P+mZcuWJUnatGlTrd6mTZvi2IasXr06q1evLj6vWLEiSbJ27dqsXbt2s2asV69qs673adV2vs9Tzo/7DbaEnFtCRoD/Czb2b1z5vzgHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwCa59NJLM3bs2Br1p556Ko0bN96se/Xps2KzrvdpPfHEExusf55y1pYx2TJybgkZk+R3v3vvswvyCXbfvXmpIwBboFWrVm1UX/m/OAcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQR1VWViZJ3nrrrbRt27ZYf+utt7LnnnvWOm/06NEZNWpU8XnFihVp37599t577zRt2nSzZpw4cf5mXe/TOvnknhusf55y1pYx2TJybgkZky0nJ0BtVqxYsVF95f/iHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEAd1blz51RWVubXv/519txzzyTJihUr8sQTT+Rb3/pWrfMaNmyYhg0b1qiXl5envLx8s2Zct65ss673adV2vs9Tzo/7DbaEnFtCxmTLyQlQm4392+EvDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBPW7lyZV5++eXi82uvvZZFixZlm222SYcOHXLGGWfkoosuyk477ZTOnTvn3HPPTbt27TJ48ODShQYAPjfKSx0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2HI99dRT+fKXv1x8HjVqVJJk6NChuemmm3LmmWdm1apVGT58eN57770ceOCBue+++9KoUaNSRQYAPkfKSx0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2HIdcsghqaqqqnW8rKwsF1xwQS644ILPMBUAsKUolDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1E2FUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqpkKpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHVTodQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAuqlQ6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDdVCh1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoG4qlDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1E2FUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqpkKpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHVTodQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAuqlQ6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDdVCh1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoG4qlDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1E2FUm28ZMmSlJWV1fg8/vjjtc656aabNjinrKwsb7/9drHv2muvzS677JKKiop06dIlt9xyS7V1DjnkkA2ucfjhhxd7Vq5cmZEjR2b77bdPRUVFdt1111x//fUbzFVVVZUBAwakrKwss2bNKtafeeaZDBkyJO3bt09FRUV22WWXXHXVVdXmnnDCCRvMsttuu21wr3HjxqWsrCxnnHFGtfopp5ySHXfcMRUVFWnVqlWOOOKIvPjii9V6NrTP9OnTNynLpZdemn322SdNmjRJ69atM3jw4Lz00kvV9vnJT36SQw45JE2bNk1ZWVnee++9Gud49913c+yxx6Zp06Zp3rx5hg0blpUrVxbH/5n3AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACALUt5qQM8+OCD2W233YrPLVu2rLX3qKOOSv/+/avVTjjhhHz44Ydp3bp1kuS6667L6NGjc+ONN2afffbJk08+mW9+85tp0aJFBg4cmCSZOXNmPvroo+Iaf/3rX7PHHnvk61//erE2atSozJkzJ7feems6deqUBx54IN/+9rfTrl27DBo0qFqGK6+8MmVlZTXyLly4MK1bt86tt96a9u3b57HHHsvw4cNTr169jBw5Mkly1VVXZdy4ccU5a9eurZHlHxYsWJAbbrgh3bp1qzHWo0ePHHvssenQoUPefffdjBkzJn379s1rr72WevXqFfumTp1a7Q6bN29e/L4xWR5++OGMGDEi++yzT9auXZsf/vCH6du3b55//vk0btw4SfL++++nf//+6d+/f0aPHl0ja5Ice+yxWbp0aWbPnp01a9bkxBNPzPDhwzNt2rRqfZvyfgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsGUp35TmTp065YwzzsgZZ5xRrO25554ZPHhwxowZ808FaNmyZSorKzeqt6KiIhUVFcXnd955J3PmzMnkyZOLtZ/+9Kc55ZRTctRRRyVJdthhhyxYsCA/+tGPMnDgwCTJNttsU23d6dOnZ6uttsrXv/71Yu2xxx7L0KFDc8ghhyRJhg8fnhtuuCFPPvlkBg0aVOxbtGhRLr/88jz11FNp27ZttXVPOumkas877LBD5s+fn5kzZ2bkyJFJkmbNmqVZs2bFnlmzZuVvf/tbTjzxxGpzV65cmWOPPTY33nhjLrroohp3M3z48OL3Tp065aKLLsoee+yRJUuWZMcddyyONW/evNb73pgs9913X7U5N910U1q3bp2FCxfm4IMPTpLi+/HQQw9tcJ8XXngh9913XxYsWJC99947SXLNNdfksMMOy4QJE9KuXbti76a8HwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbFkKm3OxAQMGZOutt671s9tuu9WYM2jQoLRu3ToHHnhg7r777k3a75ZbbslWW22Vr33ta8Xa6tWr06hRo2p9FRUVefLJJ7NmzZoNrjN58uQcffTRady4cbG2//775+67786f//znVFVV5Te/+U1+//vfp2/fvsWe999/P8ccc0yuvfbaVFZWblTm5cuXZ5tttql1fPLkyendu3c6duxYrT5ixIgcfvjh6d279yfusWrVqkydOjWdO3dO+/bta6yz7bbbZt99982UKVNSVVW1yVn+93mSfOyZ/rf58+enefPm2XvvvYu13r17p1Ao5IknnqjW+2neDwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPt/KN+dikyZNygcffFDreP369Yvft95661x++eU54IADUigUcscdd2Tw4MGZNWtWBg0atFH7TZ48Occcc0wqKiqKtX79+mXSpEkZPHhw9tprryxcuDCTJk3KmjVr8pe//CVt27attsaTTz6ZxYsXZ/LkydXq11xzTYYPH57tt98+5eXlKRQKufHGG3PwwQcXe7773e9m//33zxFHHLFReR977LHMmDEj/+///b8Njr/55pu59957M23atGr16dOn57e//W0WLFjwsev/+Mc/zplnnplVq1alS5cumT17dho0aFAcv+CCC/KVr3wlW221VR544IF8+9vfzsqVK3PaaadtdJb/af369TnjjDNywAEH5Itf/OLHZvufli1bltatW1erlZeXZ5tttsmyZcuSbJ73AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAz7fyzbnYdtttt9G92267bUaNGlV83mefffLmm2/msssuy6BBgz5x/vz58/PCCy/kpz/9abX6ueeem2XLlmW//fZLVVVV2rRpk6FDh2b8+PEpFAo11pk8eXJ233337LvvvtXq11xzTR5//PHcfffd6dixY+bOnZsRI0akXbt26d27d+6+++7MmTMnTz/99Eadd/HixTniiCNy/vnnp2/fvhvsufnmm9O8efMMHjy4WPvTn/6U008/PbNnz06jRo0+do9jjz02ffr0ydKlSzNhwoQceeSRefTRR4vzzj333GJv9+7ds2rVqlx22WU57bTTNirL/zZixIgsXrw4jzzyyMfm+md82vcDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDPv8KnXWDdunXF7wMGDMjWW29d62e33Xb72LV69uyZl19+eaP2nTRpUvbcc8/06NGjWr2ioiJTpkzJ+++/nyVLluSPf/xjOnXqlCZNmqRVq1bVeletWpXp06dn2LBh1eoffPBBfvjDH2bixIkZOHBgunXrlpEjR+aoo47KhAkTkiRz5szJK6+8kubNm6e8vDzl5eVJkq9+9as55JBDqq33/PPP59BDD83w4cNzzjnnbPA8VVVVmTJlSo477rg0aNCgWF+4cGHefvvt7LXXXsV9Hn744Vx99dUpLy+vdv/NmjXLTjvtlIMPPji/+MUv8uKLL+bOO++s9Q579uyZN954I6tXr96oLP/TyJEj88tf/jK/+c1vsv3229e6x4ZUVlbm7bffrlZbu3Zt3n333VRWVn5s3o19PwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+Pwr39QJb731VvH7mjVr8qc//an4PGnSpHzwwQe1zq1fv/7Hrr1o0aK0bdv2EzOsXLkyP//5z3PppZd+7F7bb799kmT69On5t3/7txQKhWo9t99+e1avXp1vfOMb1epr1qzJmjVravTXq1cv69evT5KcffbZOfnkk6uN77777rniiisycODAYu25557LV77ylQwdOjQXX3xxrXkffvjhvPzyyxk2bFi1+qGHHprf/e531WonnnhiunbtmrPOOiv16tXb4HpVVVWpqqrK6tWra91z0aJFadGiRRo2bLhRWf6x7ne+853ceeedeeihh9K5c+da169Nr1698t5772XhwoXp0aNHkmTOnDlZv359evbs+bF5N+b9AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgy1C+qROmTJmSQw89NB07dsxVV12V5cuX55VXXslbb72V7bbbbqPXufnmm9OgQYN07949STJz5sxMmTIlkyZNKvbceeedGT16dF588cVqc2fMmJG1a9fmG9/4Ro11f//73+fJJ59Mz54987e//S0TJ07M4sWLc/PNN9fonTx5cgYPHpyWLVtWqzdt2jRf+tKX8oMf/CAVFRXp2LFjHn744dxyyy2ZOHFikqSysjKVlZU11uzQoUM6d+6cJFm8eHG+8pWvpF+/fhk1alSWLVuWJKlXr15atWpVI0vPnj3zxS9+sVq9SZMmNWqNGzdOy5Yti/VXX301M2bMSN++fdOqVau88cYbGTduXCoqKnLYYYclSe6555689dZb2W+//dKoUaPMnj07l1xySb7//e9v8F42lCVJRowYkWnTpuWuu+5KkyZNimdq1qxZKioqkiTLli3LsmXL8vLLLydJfve736VJkybp0KFDttlmm+yyyy7p379/vvnNb+b666/PmjVrMnLkyBx99NFp165dko17PwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2LIVNnXCwIEDc9ppp2X33XfPu+++m4suuigzZ87Mgw8+uMmbX3jhhenRo0d69uyZu+66KzNmzMiJJ55YHF++fHleeumlGvMmT56c//iP/0jz5s1rjK1bty6XX3559thjj/Tp0ycffvhhHnvssXTq1Kla30svvZRHHnkkw4YN22C26dOnZ5999smxxx6bXXfdNePGjcvFF1+cU089daPP94tf/CLvvPNObr311rRt27b42Weffar1LV++PHfccUetWT5Jo0aNMm/evBx22GH5whe+kKOOOipNmjTJY489ltatWydJ6tevn2uvvTa9evXKnnvumRtuuCETJ07M+eefv0lZrrvuuixfvjyHHHJItTPNmDGj2HP99dene/fu+eY3v5kkOfjgg9O9e/fcfffdxZ6f/exn6dq1aw499NAcdthhOfDAA/OTn/yk2l6f9H489NBDKSsry5IlS/6pewMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoLTKqqqqqja2uVOnTjnjjDNyxhln/AsjwcaZOnVqLrnkkjz//POpX79+qeMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwL7JixYo0a9Ysy5cvT9OmTTfr2oMHP7JZ1/u0Zs06cIP1z1PO2jImW0bOLSFjsuXkBKjNxv77XfgMM8Fm9atf/SqXXHJJ6tevX+ooAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8E8pLHQD+WbfffnupIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8CmUb0rzkiVL/kUxAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAuqZQ6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDdVCh1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoG4qlDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1E2FUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqpkKpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHVTodQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAuqlQ6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDdVCh1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoG4qlDoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQNxVKHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKibCqUOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1E2FUgcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADqpkKpAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHVTodQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAuqlQ6gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEDdVCh1APg8WbJkScaMGVPqGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdUKh1AGeffbZHHTQQWnUqFHat2+f8ePHf+KcP/7xjzn88MOz1VZbpXXr1vnBD36QtWvXFsdnzpyZPn36pFWrVmnatGl69eqV+++/v9oaY8aMSVlZWbVP165di+NLliypMf6Pz+23317s+/Wvf539998/TZo0SWVlZc4666xqWT788MOccMIJ2X333VNeXp7Bgwd/7NkeffTRlJeXZ88996xW79Sp0wazjBgxothzyimnZMcdd0xFRUVatWqVI444Ii+++GK1dRYsWJBDDz00zZs3T4sWLdKvX78888wz1XqqqqoyYcKE7LzzzmnYsGG22267XHzxxcXxRx55JAcccEBatmyZioqKdO3aNVdccUWtZxo3blzKyspyxhlnbHC8qqoqAwYMSFlZWWbNmlVt7LTTTkuPHj3SsGHDGneS1P47Pf7448WeG2+8MQcddFBatGiRFi1apHfv3nnyySdrzQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmNWbMmJSVlVX7dO3atdSxAIDPgUIpN1+xYkX69u2bjh07ZuHChbnssssyZsyY/OQnP6l1zrp163L44Yfno48+ymOPPZabb745N910U84777xiz9y5c9OnT5/86le/ysKFC/PlL385AwcOzNNPP11trd122y1Lly4tfh555JHiWPv27auNLV26NGPHjs3WW2+dAQMGJEmeeeaZHHbYYenfv3+efvrpzJgxI3fffXfOPvvsankrKipy2mmnpXfv3h97H++9916OP/74HHrooTXGFixYUC3L7NmzkyRf//rXiz09evTI1KlT88ILL+T+++9PVVVV+vbtm3Xr1iVJVq5cmf79+6dDhw554okn8sgjj6RJkybp169f1qxZU1zn9NNPz6RJkzJhwoS8+OKLufvuu7PvvvsWxxs3bpyRI0dm7ty5eeGFF3LOOefknHPO2eDvtmDBgtxwww3p1q1bree+8sorU1ZWVuv4SSedlKOOOupjbi558MEHq91Pjx49imMPPfRQhgwZkt/85jeZP39+2rdvn759++bPf/5zsee1117Lv//7v2e//fbL+PHj07Vr15x66qkfuycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbb7fddsvSpUuLn0ceeaTUkQCAz4HyTZ3wl7/8JSNGjMgDDzyQ9957r9rY1KlTc8IJJ2z0Wj/72c/y0UcfZcqUKWnQoEF22223LFq0KBMnTszw4cM3OOeBBx7I888/nwcffDBt2rTJnnvumQsvvDBnnXVWxowZkwYNGuTKK6+sNueSSy7JXXfdlXvuuSfdu3cv1svLy1NZWbnBferVq1dj7M4778yRRx6ZrbfeOkkyY8aMdOvWLeedd16S5Atf+ELGjx+fI488Mueff36aNGmSxo0b57rrrkuSPProozXu7H869dRTc8wxx6RevXqZNWtWtbFWrVpVex43blx23HHHfOlLXyrW/uedderUKRdddFH22GOPLFmyJDvuuGNefPHFvPvuu7ngggvSvn37JMn555+fbt265fXXX88XvvCFvPDCC7nuuuuyePHidOnSJUnSuXPnant379692j126tQpM2fOzLx586plWLlyZY499tjceOONueiiizZ45kWLFuXyyy/PU089lbZt29YYv/rqq5Mk77zzTp599tla765ly5a1/pY/+9nPqj1PmjQpd9xxR37961/n+OOPT5Icf/zxWbduXa677rrMnj07RxxxRObOnVvrfgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGya8vLyVFZWljoGAPA5U76pE04//fTMnz8/M2bMSPv27TNx4sRMmjQp11xzTQ4++OAMGDAg8+bNq3V+x44d89xzzyVJ5s+fn4MPPjgNGjQojvfr1y8/+tGP8re//S0tWrSoMX/+/PnZfffd06ZNm2pzvvWtb+W5555L9+7da8xZv359/v73v2ebbbapVv/DH/6Qdu3apVGjRunVq1cuvfTSdOjQYYO5Fy5cmEWLFuXaa68t1lavXp1GjRpV66uoqMiHH36YhQsX5pBDDqn1Hv63qVOn5tVXX82tt96aiy666GN7P/roo9x6660ZNWpUysrKNtizatWqTJ06NZ07d0779u2TJF26dEnLli0zefLk/PCHP8y6desyefLk7LLLLunUqVOS5J577skOO+yQX/7yl+nfv3+qqqrSu3fvjB8/vsb9/cPTTz+dxx57rEbuESNG5PDDD0/v3r03eKb3338/xxxzTK699tpP/R/VQYMG5cMPP8zOO++cM888M4MGDaq19/3338+aNWuqnefpp5/ODTfckO7du+eZZ55Jv3790q9fv0+VCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP/2hz/8Ie3atUujRo3Sq1evXHrppenQocMGe1evXp3Vq1cXn1esWJEkWbt2bdauXbtZc9WrV7VZ1/u0ajvf5ynnx/0GW0LOLSFjsuXkBKjNxv7tKN+URZcvX57bbrstt912W/r27Zskue6663LvvfdmzZo12WGHHTJp0qR88MEHta5Rv3794vdly5alc+fO1cbbtGlTHGvRokWN+cuWLSv2bGjOhkyYMCErV67MkUceWaz17NkzN910U7p06ZKlS5dm7NixOeigg7J48eI0adKkxhqTJ0/OLrvskv33379Y69evX6688srcdtttOfLII7Ns2bJccMEFSZKlS5fWegf/2x/+8IecffbZmTdvXsrLP/knmTVrVt57772ccMIJNcZ+/OMf58wzz8yqVavSpUuXzJ49Ow0aNEiSNGnSJA899FAGDx6cCy+8MEmy00475f777y/u++qrr+b111/P7bffnltuuSXr1q3Ld7/73Xzta1/LnDlzqu21/fbb55133snatWszZsyYnHzyycWx6dOn57e//W0WLFhQ6zm++93vZv/9988RRxzxiWeuzdZbb53LL788BxxwQAqFQu64444MHjw4s2bNyqBBgzY456yzzkq7du3Su3fvYu2AAw7IlVdemfXr1//TWQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANiwnj175qabbkqXLl2ydOnSjB07NgcddFAWL16cJk2a1Oi/9NJLM3bs2Br1p556Ko0bN96s2fr0WbFZ1/u0nnjiiQ3WP085a8uYbBk5t4SMyZaTE6A2q1at2qi+8k1Z9NVXX01VVVX233///16gvDz77rtvnn322STJdttttylL/stNmzYtY8eOzV133ZXWrVsX6wMGDCh+79atW3r27JmOHTvm5z//eYYNG1ZtjQ8++CDTpk3LueeeW63et2/fXHbZZTn11FNz3HHHpWHDhjn33HMzb968FAqFjcq3bt26HHPMMRk7dmx23nnnjZozefLkDBgwIO3atasxduyxx6ZPnz5ZunRpJkyYkCOPPDKPPvpoGjVqlA8++CDDhg3LAQcckNtuuy3r1q3LhAkTcvjhh2fBggWpqKjI+vXrs3r16txyyy3FPJMnT06PHj3y0ksvpUuXLsW95s2bl5UrV+bxxx/P2WefnS984QsZMmRI/vSnP+X000/P7Nmz06hRow2e4e67786cOXPy9NNPb9SZa7Pttttm1KhRxed99tknb775Zi677LIMGjSoRv+4ceMyffr0PPTQQ9Wy/exnP8vYsWPzwx/+MMuWLcv999+f733ve/na1772qfIBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACQDBgwoPi9W7du6dmzZzp27Jif//znGTZsWI3+0aNHZ9SoUcXnFStWpH379tl7773TtGnTzZpt4sT5m3W9T+vkk3tusP55yllbxmTLyLklZEy2nJwAtVmxYsVG9ZVvyqL169dPkqxbt65afd26dalXr16S//8/HvPmzat1jY4dO+a5555LklRWVuatt96qNv6P58rKyg3Or6yszJNPPrlRc6ZPn56TTz45t99+e3r37v2xZ2vevHl23nnnvPzyyzXGfvGLX+T999/P8ccfX2Ns1KhR+e53v5ulS5emRYsWWbJkSUaPHp0ddtjhY/f7h7///e956qmn8vTTT2fkyJFJkvXr16eqqirl5eV54IEH8pWvfKXY//rrr+fBBx/MzJkzN7hes2bN0qxZs+y0007Zb7/90qJFi9x5550ZMmRIpk2bliVLlmT+/PkpFApJkmnTpqVFixa56667cvTRR6dt27YpLy/PzjvvXFxzl112SZL88Y9/TJcuXYr1zp07J0l23333vPXWWxkzZkyGDBmShQsX5u23385ee+1V7F23bl3mzp2b//qv/8rq1aszZ86cvPLKK2nevHm1/F/96ldz0EEH5aGHHtqo+9uQnj17Zvbs2TXqEyZMyLhx4/Lggw+mW7du1ca23XbbXHPNNfne976XcePGpVOnTjnqqKNy7733pm/fvv90FgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGpq3rx5dt5557z88ssbHG/YsGEaNmxYo15eXp7y8vLNmmXdurLNut6nVdv5Pk85P+432BJybgkZky0nJ0BtNvZvxyb9hdlxxx3TqFGjPProo+nUqVOS5KOPPspTTz2VUaNGJUkmTZqUDz74oNY16tevX/zeq1ev/Od//mfWrFlTrM+ePTtdunRJixYtNji/V69eufjii/P222+ndevWxTlNmzbNrrvuWuy77bbbctJJJ2X69Ok5/PDDP/FsK1euzCuvvJLjjjuuxtjkyZMzaNCgtGrVaoNzy8rK0q5du+K+7du3z1577fWJeyZJ06ZN87vf/a5a7cc//nHmzJmTX/ziF+ncuXO1salTp6Z169YbdaaqqqpUVVVl9erVSZL3338/hUIhZWX//Y/cP57Xr1+fJDnggAOydu3avPLKK9lxxx2TJL///e+TJB07dqx1r/Xr1xf3OfTQQ2uc6cQTT0zXrl1z1llnpV69ejn77LNz8sknV+vZfffdc8UVV2TgwIGfeLaPs2jRorRt27Zabfz48bn44otz//33Z++99/7Y+ZWVlTn77LNz++23Z968eenbt++nygMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB1K1euzCuvvJLjjjuu1FEAgBIr35TmioqKjBw5MmeeeWZatmyZDh06ZPz48fnwww8zbNiwJMl222230esdc8wxGTt2bIYNG5azzjorixcvzlVXXZUrrrii2HPnnXdm9OjRefHFF5Mkffv2za677prjjjsu48ePz7Jly3LOOedkxIgRadiwYZJk2rRpGTp0aK666qr07Nkzy5YtK+Zv1qxZkuT73/9+Bg4cmI4dO+bNN9/M+eefn3r16mXIkCHVMr788suZO3dufvWrX23wDJdddln69++fQqGQmTNnZty4cfn5z3+eevXqFXuef/75fPTRR3n33Xfz97//PYsWLUqS7LnnnikUCvniF79Ybc3WrVunUaNGNerr16/P1KlTM3To0JSXV//pXn311cyYMSN9+/ZNq1at8sYbb2TcuHGpqKjIYYcdliTp06dPfvCDH2TEiBH5zne+k/Xr12fcuHEpLy/Pl7/85SRJ7969s9dee+Wkk07KlVdemfXr12fEiBHp06dPdt555yTJtddemw4dOqRr165Jkrlz52bChAk57bTTkiRNmjSpkb1x48Zp2bJlsV5ZWZnKysoa99mhQ4d07ty52v2vXLkyy5YtywcffFC8u1133TUNGjTIzTffnAYNGqR79+5JkpkzZ2bKlCmZNGlScY0f/ehHOe+88zJt2rR06tSp+D5svfXW2XrrrZMkw4YNyymnnJLGjRtn9erVmTlzZp577rmce+65NTICAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwab7//e9n4MCB6dixY958882cf/75qVevXoYMGVLqaABAiZVv6oSLL744a9euzfHHH58VK1Zk7733zv3335/mzZtv8ubNmjXLAw88kBEjRqRHjx7Zdtttc95552X48OHFnuXLl+ell14qPterVy+//OUv861vfSu9evVK48aNM3To0FxwwQXFnp/85CdZu3ZtRowYkREjRhTrQ4cOzU033ZQkeeONNzJkyJD89a9/TatWrXLggQfm8ccfT6tWraplnDJlSrbffvv07dt3g2e49957c/HFF2f16tXZY489ctddd2XAgAHVeg477LC8/vrrxefu3bsnSaqqqjbpvh588MH88Y9/zEknnVRjrFGjRpk3b16uvPLK/O1vf0ubNm1y8MEH57HHHkvr1q2TJF27ds0999yTsWPHplevXikUCunevXvuu+++tG3bNklSKBRyzz335Dvf+U4OPvjgNG7cOAMGDMjll19e3Gv9+vUZPXp0XnvttZSXl2fHHXfMj370o5xyyimbdJ6NcfLJJ+fhhx8uPv/j7l577bV06tQpSXLhhRfm9ddfT3l5ebp27ZoZM2bka1/7WnHOddddl48++qhaLUnOP//8jBkzJknSunXrnHTSSXnttdeyevXqdOjQIRdeeGEGDx682c8EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQ17zxxhsZMmRI/vrXv6ZVq1Y58MAD8/jjj6dVq1aljgYAlFhZVVVVValDwOfFkiVLctNNN2XMmDGljgIAAAAAAAAAAADw/7VX/9Ffz/f/x2/vZ+/p94+VQqHizI8sQumIka0j00rbDklImt/51Ykj5HdrzDpt4wgjczYyx5jNNBYimWh+zGaS/cjPmN8xRe/395/v531O8yu8Xu+nt9flck6H1+P1/HG9371OAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4/95444107tw5r7/+ejp16lTRZ48evbCiz/usbrpp1w88/zx1flhj0jI6W0Jj0nI6AT7Muv7/u2jGJgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgCZF2QHwedKnT5+cddZZZWcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANSEouwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgNhVlBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALWpKDsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACoTfVlBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALc/o0QvLTljLTTft+oHnn6fOD2tsKeySaijKDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGpTUXYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQm4qyAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNpUlB0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADUpqLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoDYVZQcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC1qSg7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAqE1F2QEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEBtKsoOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAalNRdgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFCbirIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA2lSUHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANSmouwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgNhVlBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALWpKDsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACoTUXZAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQG0qyg4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABqU1F2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUJuKsgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDaVJQdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1Kai7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKA2FWUHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtakoOwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhNRdkBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAbaovOwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACpl9OiFZSc0uemmXT/wvCU0Npei1LcDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1qyg7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAqE1F2QEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEBtKsoOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAalNRdgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFCbirIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA2lSUHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANSmouwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgNhVlBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALWpKDsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACoTUXZAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQG0qyg4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABqU1F2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUJuKsgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDaVJQdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1Kai7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKA2FWUHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtakoOwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhNRdkBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAbSrKDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC++C6++OL06dMnbdq0yeDBg7N48eKykwCAz4Gi7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgi+26667L5MmTc+aZZ+bPf/5ztttuuwwfPjwvvvhi2WkAQMmKsgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAL7aZM2fmsMMOy4QJE9KvX7/Mnj077dq1y5VXXll2GgBQsqLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOCLa/Xq1VmyZEmGDRvWdFYURYYNG5b77ruvxDIA4POgvuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4IvrP//5T9asWZMNNthgrfMNNtggf//73z/wnlWrVmXVqlVNn19//fUkySuvvJL33nuvon0NDSsr+rzP6pVXXvnA889T54c1Ji2jsyU0Ji2j8/PUmLSMzo/6b94StJRdtoTOltD4Wb3xxhtJksbGxo+8rr4qbwcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4lGbMmJGzzz77fed9+/YtoaZ5detWdsHHawmNScvobAmNic5KagmNLUVL2WVL6Kx245tvvpnOnTt/6Pf11X09AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUMvWX3/9tGrVKitWrFjrfMWKFdlwww0/8J6pU6dm8uTJTZ8bGhryyiuvpFu3bqmrq/vULW+88UY22WSTPP300+nUqdOnfk4tsKt1Y0/rzq7WnV2tO7tad2XsqrGxMW+++WZ69uz5kdfVN0sNAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUJPWW2+97Ljjjpk/f35Gjx6dJGloaMj8+fMzadKkD7yndevWad269VpnXbp0qVhTp06d0qlTp4o974vMrtaNPa07u1p3drXu7GrdNfeuOnfu/LHX1DdDBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFDDJk+enPHjx2fgwIHZaaedMmvWrLz11luZMGFC2WkAQMnqyw4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvtjGjBmTl156KWeccUZeeOGFDBgwIPPmzcsGG2xQdhoAULL6sgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAL75JkyZl0qRJpTa0bt06Z555Zlq3bl1qR0tgV+vGntadXa07u1p3drXuPs+7qmtsbGwsOwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKg9RdkBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAbSrKDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGpTUXYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQm4qyAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNpUlB0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8EmcddZZqaurW+vPVltt9aHXDx069H3X19XVZcSIEWtd9/jjj2fUqFHp3Llz2rdvn0GDBmX58uXVHqeqqrGrlStXZtKkSdl4443Ttm3b9OvXL7Nnz26Ocarqk+4qSWbNmpUtt9wybdu2zSabbJITTzwx77zzzlrXXHzxxenTp0/atGmTwYMHZ/HixdUco1lUY1czZszIoEGD0rFjx/To0SOjR4/OE088Ue1Rqq5av6v/84Mf/CB1dXU54YQTqlDfvKq1q2effTYHHnhgunXrlrZt26Z///558MEHqzlK1VVjV2vWrMm0adPSt2/ftG3bNptvvnnOPffcNDY2Vnuc1Ff9DQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVts022+SPf/xj0+f6+voPvfbXv/51Vq9e3fT55ZdfznbbbZd999236eypp57KrrvumokTJ+bss89Op06d8te//jVt2rSpzgDNqNK7mjx5cu6444784he/SJ8+fXLbbbfl6KOPTs+ePTNq1KjqDNFMPsmurrnmmpxyyim58sorM2TIkCxdujSHHHJI6urqMnPmzCTJddddl8mTJ2f27NkZPHhwZs2aleHDh+eJJ55Ijx49qj5PNVV6VwsWLMgxxxyTQYMG5b333supp56aPffcM3/729/Svn37qs9TTZXe1f954IEHcumll2bbbbetWntzq/SuXn311eyyyy7ZY489cuutt6Z79+558skn8+Uvf7nqs1RbpXd1/vnn55JLLsnPf/7zbLPNNnnwwQczYcKEdO7cOccdd1xVZ/nwcgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDPqfr6+my44YbrdG3Xrl3X+jx37ty0a9cu++67b9PZaaedlr333jsXXHBB09nmm29emdiSVXpXixYtyvjx4zN06NAkyeGHH55LL700ixcvzqhRoyrWXYZPsqtFixZll112yQEHHJAk6dOnT8aOHZv777+/6ZqZM2fmsMMOy4QJE5Iks2fPzi233JIrr7wyp5xySuUHaEaV3tW8efPWuueqq65Kjx49smTJkuy2226VCy9BpXeVJCtXrsy4ceNy+eWX57zzzqt4c1kqvavzzz8/m2yySebMmdN01rdv38pGl6TSu1q0aFH22WefjBgxoumaa6+9NosXL658/P8oqv4GAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAp78skn07Nnz2y22WYZN25cli9fvs73XnHFFdl///3Tvn37JElDQ0NuueWWbLHFFhk+fHh69OiRwYMH56abbqpSffOq5K6SZMiQIbn55pvz7LPPprGxMXfeeWeWLl2aPffcsxr5zeqT7GrIkCFZsmRJFi9enCT5xz/+kd///vfZe++9kySrV6/OkiVLMmzYsKZ7iqLIsGHDct9991V3kGZQyV19kNdffz1J0rVr18qGl6AauzrmmGMyYsSItX5fXwSV3tXNN9+cgQMHZt99902PHj2y/fbb5/LLL6/6HM2h0rsaMmRI5s+fn6VLlyZJHnnkkSxcuDDf/OY3qztIkrrGxsbGqr8FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoEJuvfXWrFy5MltuuWWef/75nH322Xn22Wfz2GOPpWPHjh957+LFizN48ODcf//92WmnnZIkL7zwQjbaaKO0a9cu5513XvbYY4/Mmzcvp556au68887svvvuzTFWVVR6V0myatWqHH744bn66qtTX1+foihy+eWX5+CDD672OFX1aXb1k5/8JFOmTEljY2Pee++9HHnkkbnkkkuSJM8991x69eqVRYsWZeedd2665+STT86CBQty//33N8tc1VDpXf2vhoaGjBo1Kq+99loWLlxYzVGqrhq7mjt3bqZPn54HHnggbdq0ydChQzNgwIDMmjWrmaaqjmrsqk2bNkmSyZMnZ999980DDzyQ448/PrNnz8748eObZa5qqMauGhoacuqpp+aCCy5Iq1atsmbNmkyfPj1Tp06t+jx1jY2NjVV/CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAECVvPbaa+ndu3dmzpyZiRMnfuS1RxxxRO677748+uijTWfPPfdcevXqlbFjx+aaa65pOh81alTat2+fa6+9tmrtze2z7ipJLrzwwlx++eW58MIL07t379x9992ZOnVqbrzxxgwbNqya+c3q43Z11113Zf/99895552XwYMHZ9myZTn++ONz2GGHZdq0aU2/q0WLFmXnnXduuu/kk0/OggULcv/99zfnOFX1WXf1v4466qjceuutWbhwYTbeeOPmGKHZfNZdPf300xk4cGBuv/32bLvttkmSoUOHZsCAAZk1a1YzT1Ndlfhdrbfeehk4cGAWLVrUdN9xxx2XBx54IPfdd1+zzVJtldjV3Llzc9JJJ+WHP/xhttlmmzz88MM54YQTMnPmzIwfP76q/fVVfToAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAlXXp0iVbbLFFli1b9pHXvfXWW5k7d27OOeectc7XX3/91NfXp1+/fmudb7311lm4cGHFe8v0WXf13//+N6eeempuvPHGjBgxIkmy7bbb5uGHH86FF16YYcOGVa29uX3crqZNm5aDDjoo3/ve95Ik/fv3z1tvvZXDDz88p512WtZff/20atUqK1asWOu+FStWZMMNN6x6f3P6rLsqiqLp2kmTJuV3v/td7r777my88cbN0t+cPuuulixZkhdffDE77LBD0z1r1qzJ3XffnYsuuiirVq1Kq1atmmWWaqvE72qjjTb6wL/bb7jhhqr3N6dK7Oqkk07KKaeckv3337/pmn//+9+ZMWNGxo8fX9X+4uMvAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPj8WrlyZZ566qlstNFGH3nd9ddfn1WrVuXAAw9c63y99dbLoEGD8sQTT6x1vnTp0vTu3bvivWX6rLt699138+6776YoirXOW7VqlYaGhor3lunjdvX2229/4B6SpLGxMeutt1523HHHzJ8/v+n7hoaGzJ8/PzvvvHP1wkvwWXf1f/+cNGlSbrzxxtxxxx3p27dvdaNL8ll39Y1vfCN/+ctf8vDDDzf9GThwYMaNG5eHH3646dovgkr8rnbZZRd/t2fddvVh1zTH3+31VX8DAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAVNmTIlI0eOTO/evfPcc8/lzDPPTKtWrTJ27NgkycEHH5xevXplxowZa913xRVXZPTo0enWrdv7nnnSSSdlzJgx2W233bLHHntk3rx5+e1vf5u77rqrOUaqmkrvqlOnTtl9991z0kknpW3btundu3cWLFiQq6++OjNnzmy2uarhk+5q5MiRmTlzZrbffvsMHjw4y5Yty7Rp0zJy5Mi0atUqSTJ58uSMHz8+AwcOzE477ZRZs2blrbfeyoQJE0qbsxKqsatjjjkm11xzTX7zm9+kY8eOeeGFF5IknTt3Ttu2bcsZtAIqvauOHTvmq1/96lrvaN++fbp16/a+85amGr+rE088MUOGDMn3v//97Lffflm8eHEuu+yyXHbZZaXNWQnV2NXIkSMzffr0bLrpptlmm23y0EMPZebMmTn00EOrPk991d8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUEHPPPNMxo4dm5dffjndu3fPrrvumj/96U/p3r17kmT58uUpimKte5544oksXLgwt9122wc+89vf/nZmz56dGTNm5LjjjsuWW26ZG264IbvuumvV56mmauxq7ty5mTp1asaNG5dXXnklvXv3zvTp03PkkUdWfZ5q+qS7Ov3001NXV5fTTz89zz77bLp3756RI0dm+vTpTdeMGTMmL730Us4444y88MILGTBgQObNm5cNNtig2eerpGrs6pJLLkmSDB06dK13zZkzJ4ccckjVZ6qWauzqi6oauxo0aFBuvPHGTJ06Neecc0769u2bWbNmZdy4cc0+XyVVY1c//elPM23atBx99NF58cUX07NnzxxxxBE544wzqj5PXWNjY2PV3wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPA/irIDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA2lSUHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANSmouwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgNhVlBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALWpKDsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACoTUXZAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQG0qyg4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABqU1F2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQe4YOHZoTTjih7AygZEXZAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAyzJy5MjstddeH/jdPffck7q6ujz66KPNXAW0REXZAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAyzJx4sTcfvvteeaZZ9733Zw5czJw4MBsu+22JZQBLU1RdgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0LJ861vfSvfu3XPVVVetdb5y5cpcf/31GT16dMaOHZtevXqlXbt26d+/f6699tqPfGZdXV1uuummtc66dOmy1juefvrp7LfffunSpUu6du2affbZJ//6178qMxRQiqLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgZamvr8/BBx+cq666Ko2NjU3n119/fdasWZMDDzwwO+64Y2655ZY89thjOfzww3PQQQdl8eLFn/qd7777boYPH56OHTvmnnvuyb333psOHTpkr732yurVqysxFlCCouwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKDlOfTQQ/PUU09lwYIFTWdz5szJd7/73fTu3TtTpkzJgAEDstlmm+XYY4/NXnvtlV/96lef+n3XXXddGhoa8rOf/Sz9+/fP1ltvnTlz5mT58uW56667KjARUIai7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoOXZaqutMmTIkFx55ZVJkmXLluWee+7JxIkTs2bNmpx77rnp379/unbtmg4dOuQPf/hDli9f/qnf98gjj2TZsmXp2LFjOnTokA4dOqRr165555138tRTT1VqLKCZ1ZcdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC0TBMnTsyxxx6biy++OHPmzMnmm2+e3XffPeeff35+/OMfZ9asWenfv3/at2+fE044IatXr/7QZ9XV1aWxsXGts3fffbfp31euXJkdd9wxv/zlL993b/fu3Ss3FNCs6ssOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABapv322y/HH398rrnmmlx99dU56qijUldXl3vvvTf77LNPDjzwwCRJQ0NDli5dmn79+n3os7p3757nn3++6fOTTz6Zt99+u+nzDjvskOuuuy49evRIp06dqjcU0KyKsgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgJapQ4cOGTNmTKZOnZrnn38+hxxySJLkK1/5Sm6//fYsWrQojz/+eI444oisWLHiI5/19a9/PRdddFEeeuihPPjggznyyCPzpS99qen7cePGZf31188+++yTe+65J//85z9z11135bjjjsszzzxTzTGBKirKDgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWq6JEyfm1VdfzfDhw9OzZ88kyemnn54ddtghw4cPz9ChQ7Phhhtm9OjRH/mcH/3oR9lkk03yta99LQcccECmTJmSdu3aNX3frl273H333dl0003zne98J1tvvXUmTpyYd955J506darmiEAV1TU2NjaWHQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANSeouwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgNhVlBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALWpKDsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACoTUXZAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQG0qyg4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABqU1F2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUJuKsgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDaVJQdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1Kai7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKA2FWUHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtakoOwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKhNRdkBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAbfp/8iXRteGOxLQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Root mean squared error, no early stop\n",
    "\n",
    "mean = sum(uni_root1) / len(uni_root1)\n",
    "variance = sum([((x - mean) ** 2) for x in uni_root1]) / len(uni_root1)\n",
    "sd = variance ** 0.5\n",
    "\n",
    "m, bins, patches = plt.hist(x=uni_root1, bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('RMSE for 100 Epochs')\n",
    "plt.text(1.75, 4.5, '\\u03BC={},\\n\\n\\u03C3={}$'.format(mean,sd))\n",
    "maxfreq = m.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a627e16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] | loss train:0.041617, test:0.000789 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012797, test:0.005335 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011997, test:0.005244 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011014, test:0.009217 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011866, test:0.000559 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010343, test:0.002962 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008132, test:0.000624 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010007, test:0.004586 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011973, test:0.005928 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010737, test:0.007365 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011237, test:0.004760 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008832, test:0.004924 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008923, test:0.000558 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007558, test:0.000316 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007727, test:0.000429 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008813, test:0.001419 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008086, test:0.000567 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007383, test:0.007094 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008305, test:0.002280 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007250, test:0.000589 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007560, test:0.002589 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009096, test:0.002104 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007421, test:0.000354 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006518, test:0.000718 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008117, test:0.000812 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.010608, test:0.001273 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009635, test:0.000455 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009739, test:0.001621 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008161, test:0.000476 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007023, test:0.000376 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007395, test:0.002831 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007298, test:0.000536 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006867, test:0.000740 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007084, test:0.000447 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007752, test:0.000417 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007173, test:0.000487 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007494, test:0.003155 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006531, test:0.002178 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007582, test:0.001023 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007213, test:0.001777 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005915, test:0.000369 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007542, test:0.000455 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005661, test:0.000363 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005435, test:0.000715 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005381, test:0.000395 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005078, test:0.000330 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005045, test:0.000442 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004981, test:0.000347 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005301, test:0.000329 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.007120, test:0.000322 | lr:0.001000\n",
      "Mean absolute error:  1.6827604957560285\n",
      "Root mean squared error:  5.79684166392478\n",
      "Epoch[1/100] | loss train:0.060996, test:0.009836 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013126, test:0.010437 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012690, test:0.000456 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012879, test:0.000761 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009663, test:0.000532 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011038, test:0.008772 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008664, test:0.001224 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009042, test:0.000647 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007296, test:0.001514 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007618, test:0.000710 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008521, test:0.002533 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009836, test:0.008225 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008671, test:0.001470 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008317, test:0.001685 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008856, test:0.002444 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008989, test:0.002273 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008435, test:0.003832 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007662, test:0.000928 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009071, test:0.000761 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008497, test:0.000603 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008640, test:0.000866 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008460, test:0.000371 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008756, test:0.001000 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007422, test:0.000408 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006675, test:0.001070 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007969, test:0.000827 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007692, test:0.004877 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008220, test:0.000459 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007940, test:0.000583 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006732, test:0.000627 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006633, test:0.000677 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007650, test:0.000633 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007173, test:0.000486 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008030, test:0.000441 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007075, test:0.001137 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006261, test:0.000535 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006975, test:0.000588 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008378, test:0.004448 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008359, test:0.002478 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007333, test:0.000474 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005808, test:0.000411 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005582, test:0.000476 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006154, test:0.000383 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005665, test:0.000414 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005348, test:0.000405 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006871, test:0.000603 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005121, test:0.000439 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005686, test:0.000453 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005793, test:0.000356 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005488, test:0.000374 | lr:0.001000\n",
      "Mean absolute error:  1.8761657783984869\n",
      "Root mean squared error:  5.868648284725035\n",
      "Epoch[1/100] | loss train:0.060420, test:0.000461 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010477, test:0.000889 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009459, test:0.000364 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010545, test:0.006608 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011271, test:0.001671 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007921, test:0.000349 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.012653, test:0.000553 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010829, test:0.003058 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008536, test:0.000640 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007844, test:0.000901 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007345, test:0.003288 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008502, test:0.000389 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007394, test:0.001045 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007017, test:0.007107 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008253, test:0.000913 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007058, test:0.000483 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007996, test:0.001315 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007328, test:0.007025 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007401, test:0.000981 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007815, test:0.002544 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009756, test:0.000491 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007657, test:0.003205 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006168, test:0.000457 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007331, test:0.000580 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/100] | loss train:0.007063, test:0.000434 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007124, test:0.000429 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007774, test:0.003818 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009424, test:0.000528 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006092, test:0.000523 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008060, test:0.000768 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007625, test:0.000627 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.010738, test:0.000798 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008610, test:0.000608 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006603, test:0.000424 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007153, test:0.002688 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007619, test:0.001695 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006496, test:0.000482 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006671, test:0.001038 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008367, test:0.001028 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007488, test:0.000558 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006944, test:0.000512 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005597, test:0.000482 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005069, test:0.000471 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006017, test:0.000564 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.008305, test:0.000397 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005892, test:0.000333 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005266, test:0.000360 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005326, test:0.000495 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004936, test:0.000377 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006288, test:0.000466 | lr:0.001000\n",
      "Mean absolute error:  2.1246648510784145\n",
      "Root mean squared error:  6.050062519008328\n",
      "Epoch[1/100] | loss train:0.057468, test:0.004261 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013287, test:0.000429 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010328, test:0.000465 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009888, test:0.002901 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009398, test:0.000304 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009507, test:0.000360 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009410, test:0.003335 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008892, test:0.001236 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008242, test:0.000563 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009404, test:0.000320 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008390, test:0.000709 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009427, test:0.002005 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007569, test:0.001847 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007296, test:0.002795 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008035, test:0.000399 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006982, test:0.001921 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007917, test:0.000421 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007153, test:0.002147 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007798, test:0.001319 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008445, test:0.009307 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.010346, test:0.001013 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010003, test:0.000384 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007187, test:0.001146 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007353, test:0.001441 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006791, test:0.002097 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009349, test:0.001366 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009066, test:0.000564 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008264, test:0.000776 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008371, test:0.000841 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007128, test:0.000669 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.010901, test:0.000687 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007065, test:0.005480 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007214, test:0.000320 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007539, test:0.000627 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006595, test:0.001626 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006703, test:0.000421 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006323, test:0.001128 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006912, test:0.000631 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006564, test:0.000463 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006677, test:0.000574 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005551, test:0.000476 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005815, test:0.000447 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005152, test:0.000382 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005242, test:0.000338 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005948, test:0.000353 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004953, test:0.000360 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005564, test:0.000338 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006865, test:0.000360 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005125, test:0.000562 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005639, test:0.000323 | lr:0.001000\n",
      "Mean absolute error:  1.8988541592827597\n",
      "Root mean squared error:  5.856689940344836\n",
      "Epoch[1/100] | loss train:0.053689, test:0.000433 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011660, test:0.000514 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010710, test:0.002166 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012753, test:0.007169 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010460, test:0.000340 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008864, test:0.000980 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008473, test:0.002766 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008447, test:0.000350 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007104, test:0.001013 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008490, test:0.000841 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008228, test:0.008942 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008703, test:0.000305 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009246, test:0.000420 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007031, test:0.000292 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007435, test:0.000358 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.013503, test:0.002085 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008871, test:0.000333 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007359, test:0.002420 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007548, test:0.000630 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007043, test:0.000444 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006331, test:0.000590 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007953, test:0.003115 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008809, test:0.000402 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007128, test:0.000579 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007026, test:0.000837 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008727, test:0.001138 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006516, test:0.000985 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008444, test:0.000353 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007829, test:0.001852 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.005986, test:0.000429 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006788, test:0.003620 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007712, test:0.000342 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007788, test:0.000473 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007628, test:0.002248 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006723, test:0.001650 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006732, test:0.000494 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008706, test:0.002323 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008064, test:0.000841 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007734, test:0.000403 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006172, test:0.000877 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005539, test:0.000505 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007335, test:0.000443 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005776, test:0.000319 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005888, test:0.000651 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005488, test:0.000347 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005271, test:0.000305 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006171, test:0.000455 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004981, test:0.000309 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49/100] | loss train:0.005207, test:0.000620 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.010718, test:0.000301 | lr:0.001000\n",
      "Mean absolute error:  1.7230166371455304\n",
      "Root mean squared error:  5.812556350633915\n",
      "Epoch[1/100] | loss train:0.073173, test:0.001055 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012877, test:0.000519 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011245, test:0.001937 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009328, test:0.000294 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009263, test:0.001359 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011773, test:0.002036 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011134, test:0.004316 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009239, test:0.000404 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007684, test:0.000749 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009497, test:0.002214 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008973, test:0.000419 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007465, test:0.000352 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007902, test:0.001344 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006775, test:0.002923 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.010934, test:0.001689 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008451, test:0.003401 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007400, test:0.000401 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007465, test:0.000753 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007343, test:0.000546 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007387, test:0.000495 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007798, test:0.002706 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008003, test:0.000683 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.019836, test:0.002874 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008774, test:0.001371 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007091, test:0.000886 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007987, test:0.000606 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008176, test:0.000365 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.026226, test:0.003593 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010099, test:0.000431 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007535, test:0.001163 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007263, test:0.000531 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007466, test:0.001949 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008216, test:0.000531 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008423, test:0.000773 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006883, test:0.000627 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008809, test:0.002257 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008434, test:0.000494 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007285, test:0.001028 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008774, test:0.000507 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007459, test:0.000607 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006073, test:0.000410 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006592, test:0.000382 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005708, test:0.000675 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005565, test:0.000518 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005384, test:0.000471 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005924, test:0.000416 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005401, test:0.000343 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005846, test:0.000460 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006519, test:0.000376 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006687, test:0.000420 | lr:0.001000\n",
      "Mean absolute error:  2.0276916307014696\n",
      "Root mean squared error:  6.007897133203237\n",
      "Epoch[1/100] | loss train:0.061327, test:0.000654 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009556, test:0.000748 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009634, test:0.001347 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009428, test:0.000491 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010778, test:0.010819 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011327, test:0.000357 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008525, test:0.007478 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008758, test:0.004313 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011487, test:0.000713 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007694, test:0.001049 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008193, test:0.000403 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007959, test:0.000398 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007599, test:0.001946 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007955, test:0.000337 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006691, test:0.002060 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006928, test:0.002970 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007359, test:0.000382 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006798, test:0.000431 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008870, test:0.001067 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008408, test:0.000555 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007500, test:0.000413 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007734, test:0.000527 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006495, test:0.000393 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007799, test:0.000456 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009653, test:0.006099 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009889, test:0.001778 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006546, test:0.000730 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006821, test:0.000536 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006028, test:0.000672 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007751, test:0.001071 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006983, test:0.001582 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007016, test:0.000674 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006842, test:0.001263 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007307, test:0.001735 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007263, test:0.002831 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009816, test:0.003398 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007600, test:0.000869 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006339, test:0.000600 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006969, test:0.000480 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006730, test:0.000966 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005305, test:0.000431 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006082, test:0.000455 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006701, test:0.000422 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005772, test:0.000588 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005056, test:0.001031 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004815, test:0.000419 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.009524, test:0.000656 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005898, test:0.000550 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005929, test:0.000432 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005115, test:0.000445 | lr:0.001000\n",
      "Mean absolute error:  2.2068101017958104\n",
      "Root mean squared error:  6.038447623138276\n",
      "Epoch[1/100] | loss train:0.078408, test:0.000830 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010869, test:0.002456 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011866, test:0.000325 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011524, test:0.002774 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009125, test:0.000489 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.013363, test:0.000330 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011412, test:0.006625 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.012699, test:0.001747 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008723, test:0.001628 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010188, test:0.000466 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008818, test:0.000763 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011075, test:0.000415 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008262, test:0.002026 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008140, test:0.001261 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007913, test:0.000524 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007122, test:0.001680 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007631, test:0.000422 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007535, test:0.000652 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008329, test:0.000531 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008108, test:0.000566 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007408, test:0.000438 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/100] | loss train:0.007204, test:0.000709 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007965, test:0.003561 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008020, test:0.005077 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008488, test:0.000595 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007942, test:0.000681 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008099, test:0.002204 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007754, test:0.000505 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008314, test:0.000433 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008237, test:0.000444 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006811, test:0.000512 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008489, test:0.000653 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007100, test:0.000462 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008712, test:0.000846 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008533, test:0.000702 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007013, test:0.002914 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009838, test:0.000376 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008123, test:0.000506 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006325, test:0.000573 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007508, test:0.000335 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005502, test:0.000358 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005456, test:0.000336 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005856, test:0.000536 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005017, test:0.000412 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005128, test:0.000324 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.007484, test:0.000514 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005125, test:0.000359 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005293, test:0.000451 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004961, test:0.000313 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005721, test:0.000321 | lr:0.001000\n",
      "Mean absolute error:  2.069262667676407\n",
      "Root mean squared error:  5.902193496757303\n",
      "Epoch[1/100] | loss train:0.053572, test:0.000839 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012090, test:0.000420 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010225, test:0.005165 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008981, test:0.000829 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008998, test:0.000302 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010562, test:0.001278 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008163, test:0.001250 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007871, test:0.000352 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009882, test:0.000961 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011620, test:0.001834 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007390, test:0.000322 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008917, test:0.000310 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007745, test:0.002041 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008631, test:0.001613 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008459, test:0.002536 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.011879, test:0.012354 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.012120, test:0.001147 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007194, test:0.003142 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007592, test:0.000372 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007782, test:0.002890 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007777, test:0.000827 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006829, test:0.000729 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008317, test:0.000552 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009094, test:0.000570 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008458, test:0.000402 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006246, test:0.000800 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007995, test:0.000628 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007347, test:0.000436 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007727, test:0.002453 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008519, test:0.000611 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007910, test:0.000568 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007107, test:0.000473 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007078, test:0.004277 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006805, test:0.001561 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007835, test:0.002613 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007784, test:0.006910 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007485, test:0.002530 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006127, test:0.002041 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008552, test:0.002045 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008463, test:0.001038 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006431, test:0.000463 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006229, test:0.000563 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005940, test:0.000741 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005679, test:0.000404 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005477, test:0.000408 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005841, test:0.000409 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005839, test:0.000455 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005481, test:0.000392 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005384, test:0.000741 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005449, test:0.000380 | lr:0.001000\n",
      "Mean absolute error:  1.8602713354991447\n",
      "Root mean squared error:  5.866506271159139\n",
      "Epoch[1/100] | loss train:0.047023, test:0.004357 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010984, test:0.000951 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009883, test:0.002974 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009389, test:0.002379 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009826, test:0.000458 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007857, test:0.004157 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009138, test:0.000360 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008124, test:0.000423 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008928, test:0.000645 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008047, test:0.001081 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008370, test:0.000360 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008253, test:0.000326 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009096, test:0.001014 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008137, test:0.001550 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007894, test:0.001113 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006750, test:0.002777 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007186, test:0.002200 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009267, test:0.000469 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007922, test:0.000557 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007686, test:0.000363 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007681, test:0.000730 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006360, test:0.000491 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009092, test:0.004141 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008215, test:0.000589 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009399, test:0.000442 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008829, test:0.000524 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006107, test:0.000530 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007744, test:0.000877 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006050, test:0.000506 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009815, test:0.001047 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006977, test:0.000413 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007816, test:0.000619 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007216, test:0.000468 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006749, test:0.000827 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.012788, test:0.002403 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008124, test:0.001119 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006690, test:0.000518 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007507, test:0.000554 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006361, test:0.000620 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006876, test:0.003412 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006603, test:0.000496 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005740, test:0.000452 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005101, test:0.000501 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006044, test:0.000561 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005242, test:0.000392 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[46/100] | loss train:0.005816, test:0.000570 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005823, test:0.000540 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004756, test:0.000470 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005563, test:0.000415 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004654, test:0.000529 | lr:0.001000\n",
      "Mean absolute error:  2.060969374340822\n",
      "Root mean squared error:  6.09641860520588\n",
      "Epoch[1/100] | loss train:0.060347, test:0.000400 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012143, test:0.001602 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010080, test:0.000839 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010203, test:0.000491 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008616, test:0.002521 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012651, test:0.002782 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011581, test:0.000485 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007833, test:0.009756 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009026, test:0.000653 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007688, test:0.002080 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008253, test:0.002305 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008569, test:0.000491 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008549, test:0.000632 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007693, test:0.001627 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008174, test:0.002044 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009691, test:0.002402 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008395, test:0.000461 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008140, test:0.000603 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007254, test:0.003438 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008053, test:0.001329 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007106, test:0.001457 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007910, test:0.000591 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007655, test:0.002777 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008116, test:0.001331 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010793, test:0.001244 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008179, test:0.000489 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008384, test:0.001453 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007409, test:0.000592 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.011221, test:0.000610 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008165, test:0.001099 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007520, test:0.000664 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008267, test:0.001664 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008377, test:0.001694 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008232, test:0.007177 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007201, test:0.002135 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007501, test:0.000639 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007754, test:0.000951 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006871, test:0.000570 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007763, test:0.002237 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009347, test:0.000926 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006465, test:0.000430 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007617, test:0.000507 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005654, test:0.000407 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006541, test:0.000365 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005773, test:0.000601 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005698, test:0.000363 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005640, test:0.000402 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.008977, test:0.000379 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005667, test:0.000368 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006147, test:0.000433 | lr:0.001000\n",
      "Mean absolute error:  1.7480269712103873\n",
      "Root mean squared error:  5.856468800417317\n",
      "Epoch[1/100] | loss train:0.046184, test:0.005444 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011949, test:0.002581 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012280, test:0.001644 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011500, test:0.002430 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009519, test:0.002075 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009567, test:0.000499 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008830, test:0.000478 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010127, test:0.003457 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010209, test:0.000320 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007932, test:0.000351 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.006446, test:0.003017 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008793, test:0.002558 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007536, test:0.003694 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007342, test:0.000388 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007317, test:0.000394 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007539, test:0.001863 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007001, test:0.000374 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006683, test:0.000820 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006955, test:0.000578 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007200, test:0.002495 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009702, test:0.000526 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007124, test:0.000493 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010818, test:0.000365 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009827, test:0.000612 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006617, test:0.000730 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.005897, test:0.001114 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007650, test:0.001427 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006528, test:0.001277 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008574, test:0.004126 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006533, test:0.005626 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008301, test:0.000644 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007199, test:0.000362 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006038, test:0.002598 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006771, test:0.000783 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006094, test:0.000383 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006980, test:0.000367 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006647, test:0.000977 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006874, test:0.001003 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006085, test:0.000471 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007340, test:0.000935 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005650, test:0.000539 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006433, test:0.000429 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.004976, test:0.000372 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006195, test:0.000470 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005671, test:0.000878 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005335, test:0.000390 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005400, test:0.000549 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006745, test:0.000461 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.011798, test:0.000431 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005140, test:0.000345 | lr:0.001000\n",
      "Mean absolute error:  1.7727311147269016\n",
      "Root mean squared error:  5.83387670495999\n",
      "Epoch[1/100] | loss train:0.068172, test:0.002271 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012844, test:0.000730 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013256, test:0.010614 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009833, test:0.003292 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011182, test:0.000301 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007930, test:0.000343 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008792, test:0.003859 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009852, test:0.002219 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009110, test:0.000297 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007083, test:0.000743 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009335, test:0.000900 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008593, test:0.000995 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007184, test:0.000722 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.011033, test:0.000396 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007276, test:0.002812 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010026, test:0.001909 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007581, test:0.005280 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007980, test:0.003848 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/100] | loss train:0.008088, test:0.000413 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008415, test:0.004067 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009811, test:0.000499 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007816, test:0.000379 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007604, test:0.005336 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.011345, test:0.004213 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010078, test:0.000856 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007954, test:0.000679 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006993, test:0.000651 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007730, test:0.000698 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006778, test:0.000581 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007822, test:0.000916 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007197, test:0.000798 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.012233, test:0.001840 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.010306, test:0.001465 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006749, test:0.002822 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006960, test:0.000473 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009235, test:0.000637 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007151, test:0.000909 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008033, test:0.001164 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008064, test:0.000902 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008307, test:0.000999 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005516, test:0.000429 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006336, test:0.000387 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005716, test:0.000371 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.007582, test:0.000351 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005211, test:0.000506 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005558, test:0.000418 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005165, test:0.000459 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005747, test:0.000411 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007491, test:0.000314 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004982, test:0.000321 | lr:0.001000\n",
      "Mean absolute error:  1.7207514939130113\n",
      "Root mean squared error:  5.8063618452613746\n",
      "Epoch[1/100] | loss train:0.059557, test:0.000508 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014517, test:0.000913 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010606, test:0.001772 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009483, test:0.000277 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008941, test:0.000324 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008362, test:0.001362 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010492, test:0.000889 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.013697, test:0.002339 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.018399, test:0.002345 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009580, test:0.002218 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009875, test:0.000481 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008882, test:0.001146 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009897, test:0.001022 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009747, test:0.000513 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008205, test:0.000369 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007353, test:0.001498 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.011373, test:0.001232 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009115, test:0.000446 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008171, test:0.002377 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008298, test:0.000647 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007502, test:0.001281 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010207, test:0.003072 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006873, test:0.000653 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007817, test:0.000416 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007992, test:0.004509 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008377, test:0.000443 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006961, test:0.002069 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007189, test:0.001185 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006549, test:0.000624 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007052, test:0.001739 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006770, test:0.000505 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.015615, test:0.000418 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008455, test:0.000432 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006740, test:0.000451 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009715, test:0.000593 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007003, test:0.000374 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006448, test:0.000892 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.010951, test:0.002386 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007279, test:0.001003 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007935, test:0.000828 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.008273, test:0.000391 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005175, test:0.000419 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005049, test:0.000412 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005316, test:0.000364 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005290, test:0.000487 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.008498, test:0.000758 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005361, test:0.000355 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005039, test:0.000717 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004809, test:0.000390 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005631, test:0.000352 | lr:0.001000\n",
      "Mean absolute error:  1.9028579132826569\n",
      "Root mean squared error:  5.862709442529831\n",
      "Epoch[1/100] | loss train:0.058803, test:0.005286 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011870, test:0.004385 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009492, test:0.000405 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009304, test:0.000460 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008860, test:0.000736 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009773, test:0.011759 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010794, test:0.001483 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.014464, test:0.003684 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009616, test:0.001805 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008007, test:0.000431 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008384, test:0.005055 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008037, test:0.000627 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007269, test:0.002000 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008655, test:0.003581 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007343, test:0.000360 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006817, test:0.001283 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006934, test:0.000496 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007069, test:0.000422 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007930, test:0.003307 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008396, test:0.000985 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007399, test:0.000878 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007523, test:0.001737 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009896, test:0.000456 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007957, test:0.000688 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006963, test:0.000501 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006864, test:0.001141 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008213, test:0.000474 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007233, test:0.000431 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006347, test:0.001323 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010444, test:0.000689 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007384, test:0.000595 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007387, test:0.000679 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.010233, test:0.001046 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007960, test:0.001324 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007703, test:0.000617 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006713, test:0.000786 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007022, test:0.000424 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006081, test:0.001678 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007486, test:0.000806 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007390, test:0.000482 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005745, test:0.000367 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006988, test:0.000479 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[43/100] | loss train:0.005573, test:0.000382 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005202, test:0.000406 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005518, test:0.000424 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005773, test:0.000370 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005018, test:0.000419 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005356, test:0.000610 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005643, test:0.000375 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.008304, test:0.000393 | lr:0.001000\n",
      "Mean absolute error:  1.800683111894242\n",
      "Root mean squared error:  5.883818938867948\n",
      "Epoch[1/100] | loss train:0.060226, test:0.006278 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012012, test:0.000508 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013226, test:0.002088 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009451, test:0.000858 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008802, test:0.000497 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012299, test:0.000327 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009832, test:0.000364 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011333, test:0.000764 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007670, test:0.001564 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008611, test:0.002171 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.006887, test:0.000727 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011707, test:0.000342 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007107, test:0.000416 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007229, test:0.003639 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008678, test:0.001539 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007467, test:0.000362 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010096, test:0.003433 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008675, test:0.002751 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008226, test:0.000404 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007215, test:0.001542 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007403, test:0.000604 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010351, test:0.004419 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006909, test:0.000570 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009374, test:0.000684 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007603, test:0.000358 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007724, test:0.001373 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006855, test:0.001437 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009409, test:0.003348 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010798, test:0.004815 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007904, test:0.001449 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008706, test:0.000529 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006543, test:0.000379 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008013, test:0.000442 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006461, test:0.000394 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008576, test:0.001201 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008129, test:0.000492 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006851, test:0.000346 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008361, test:0.004613 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008869, test:0.000381 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007019, test:0.001314 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005859, test:0.000604 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007448, test:0.000338 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005805, test:0.000376 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005181, test:0.000315 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005882, test:0.000494 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005045, test:0.000309 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005032, test:0.000444 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005175, test:0.000539 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005158, test:0.000327 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005086, test:0.000333 | lr:0.001000\n",
      "Mean absolute error:  1.703383825261328\n",
      "Root mean squared error:  5.792983645977946\n",
      "Epoch[1/100] | loss train:0.060183, test:0.002186 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011060, test:0.003964 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010330, test:0.002973 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011336, test:0.007099 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010161, test:0.002322 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010049, test:0.000298 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009113, test:0.001067 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009919, test:0.000590 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009478, test:0.006955 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009369, test:0.000587 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.006687, test:0.002692 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009227, test:0.000487 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009563, test:0.000389 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007290, test:0.000526 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008089, test:0.002412 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008127, test:0.000531 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007760, test:0.000927 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007617, test:0.000817 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007994, test:0.000815 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007617, test:0.000633 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007043, test:0.000702 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008469, test:0.001821 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006965, test:0.000598 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.013961, test:0.000782 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007450, test:0.001455 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007100, test:0.001046 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007193, test:0.000647 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007141, test:0.005591 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007513, test:0.000836 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006385, test:0.000453 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006474, test:0.001212 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.012526, test:0.000943 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009136, test:0.000762 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006964, test:0.000368 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006640, test:0.002482 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006830, test:0.000403 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007739, test:0.000398 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006583, test:0.000857 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.013232, test:0.000446 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007915, test:0.000613 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005301, test:0.000380 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005143, test:0.000344 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005327, test:0.000370 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006657, test:0.000360 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005237, test:0.000443 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006105, test:0.000354 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004887, test:0.000427 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005600, test:0.000391 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005011, test:0.000365 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006688, test:0.000400 | lr:0.001000\n",
      "Mean absolute error:  2.103116108227989\n",
      "Root mean squared error:  6.002696669907856\n",
      "Epoch[1/100] | loss train:0.046422, test:0.006324 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013327, test:0.000337 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010733, test:0.002383 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011665, test:0.000718 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008590, test:0.000400 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008731, test:0.001218 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.016634, test:0.004718 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010029, test:0.000367 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007582, test:0.002213 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007949, test:0.000311 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008090, test:0.000729 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008814, test:0.001106 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008566, test:0.003052 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007839, test:0.000331 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006932, test:0.002057 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/100] | loss train:0.007383, test:0.000889 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008002, test:0.000509 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008633, test:0.001384 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007385, test:0.001694 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007477, test:0.001725 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008390, test:0.000441 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010342, test:0.000867 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007250, test:0.000614 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009584, test:0.000622 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008420, test:0.000624 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007852, test:0.000704 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008012, test:0.000814 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006647, test:0.000325 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007425, test:0.000491 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008109, test:0.004217 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009039, test:0.001055 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009748, test:0.000500 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008304, test:0.001245 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006988, test:0.005031 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006776, test:0.000842 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006749, test:0.000751 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006456, test:0.000375 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008635, test:0.000391 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006849, test:0.000967 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009218, test:0.000672 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007625, test:0.000325 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006123, test:0.000310 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006220, test:0.000299 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004958, test:0.000324 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006074, test:0.000325 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004686, test:0.000345 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005329, test:0.000300 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005463, test:0.000273 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005670, test:0.000317 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005533, test:0.000323 | lr:0.001000\n",
      "Mean absolute error:  2.637296276673326\n",
      "Root mean squared error:  6.079407159611198\n",
      "Epoch[1/100] | loss train:0.061629, test:0.001276 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013851, test:0.000423 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010026, test:0.003271 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012714, test:0.002968 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010720, test:0.001770 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010673, test:0.000764 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008483, test:0.000318 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009828, test:0.000367 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008150, test:0.000745 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010049, test:0.000561 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007774, test:0.001384 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009525, test:0.000796 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008907, test:0.000396 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010142, test:0.000366 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007802, test:0.001292 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008135, test:0.001126 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007887, test:0.000452 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008947, test:0.005982 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009011, test:0.000647 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009793, test:0.001660 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009209, test:0.000401 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009042, test:0.000511 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008330, test:0.000413 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007558, test:0.001185 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008379, test:0.004068 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007265, test:0.000484 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007597, test:0.000519 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009331, test:0.000723 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010431, test:0.006610 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009070, test:0.002681 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009633, test:0.000865 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.010897, test:0.000428 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007819, test:0.000552 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007257, test:0.001121 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009374, test:0.002457 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009692, test:0.001316 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009036, test:0.001445 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007956, test:0.002733 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008364, test:0.000480 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008733, test:0.000980 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006295, test:0.000437 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005993, test:0.000384 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005881, test:0.000494 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006312, test:0.000391 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.008286, test:0.000427 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005087, test:0.000418 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005254, test:0.000393 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.008030, test:0.000360 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007373, test:0.000356 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005479, test:0.000410 | lr:0.001000\n",
      "Mean absolute error:  2.248024125012333\n",
      "Root mean squared error:  6.0488325239318295\n",
      "Epoch[1/100] | loss train:0.045453, test:0.001107 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012650, test:0.000763 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009141, test:0.001088 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009647, test:0.000351 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007204, test:0.005577 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008360, test:0.000420 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008938, test:0.000344 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007521, test:0.003316 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007356, test:0.000339 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008428, test:0.001017 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008502, test:0.004443 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008967, test:0.001971 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007377, test:0.000409 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007975, test:0.000579 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007825, test:0.000443 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008005, test:0.000919 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009923, test:0.000456 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007211, test:0.000803 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.011292, test:0.003060 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008684, test:0.001092 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007925, test:0.000704 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007186, test:0.000442 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006467, test:0.000588 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.012312, test:0.009005 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008821, test:0.001053 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007240, test:0.001044 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008222, test:0.000617 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009108, test:0.000771 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006262, test:0.003520 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006889, test:0.000469 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008684, test:0.001526 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007901, test:0.001047 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006827, test:0.001402 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007281, test:0.000431 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007087, test:0.000644 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006906, test:0.000487 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007446, test:0.000476 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006986, test:0.001179 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007279, test:0.000466 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/100] | loss train:0.007160, test:0.000415 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005327, test:0.000548 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005277, test:0.000329 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005877, test:0.000307 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.011240, test:0.000288 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004965, test:0.000333 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005469, test:0.000425 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005732, test:0.000616 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005458, test:0.000318 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005089, test:0.000292 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005440, test:0.000325 | lr:0.001000\n",
      "Mean absolute error:  1.932041259042894\n",
      "Root mean squared error:  5.863616112864714\n",
      "Epoch[1/100] | loss train:0.049572, test:0.000615 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010293, test:0.000706 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008929, test:0.000550 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010206, test:0.000505 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011881, test:0.005823 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009953, test:0.001267 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.015811, test:0.002115 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010821, test:0.001044 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008830, test:0.002618 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007689, test:0.000551 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008182, test:0.000542 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008025, test:0.000392 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007143, test:0.000455 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007727, test:0.000589 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007401, test:0.000697 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010073, test:0.000476 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007878, test:0.000853 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009321, test:0.002270 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007798, test:0.001356 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007791, test:0.001804 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007693, test:0.000354 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.013287, test:0.001185 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008411, test:0.000526 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007133, test:0.000490 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007001, test:0.001992 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.010417, test:0.004626 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008639, test:0.005015 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007587, test:0.001126 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007774, test:0.003892 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008238, test:0.000473 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006695, test:0.000927 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007839, test:0.000454 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006274, test:0.002174 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006575, test:0.000883 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007264, test:0.001412 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006543, test:0.000861 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006286, test:0.000334 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006907, test:0.000664 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007037, test:0.000934 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007765, test:0.000669 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006250, test:0.000514 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005807, test:0.000406 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005145, test:0.000414 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005183, test:0.000647 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005351, test:0.000331 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005188, test:0.000580 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004841, test:0.000506 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005217, test:0.000306 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005418, test:0.000371 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005084, test:0.000326 | lr:0.001000\n",
      "Mean absolute error:  1.7685986793825095\n",
      "Root mean squared error:  5.818830503722833\n",
      "Epoch[1/100] | loss train:0.053961, test:0.002422 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010799, test:0.001411 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012073, test:0.000403 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010077, test:0.000946 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009845, test:0.001275 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008654, test:0.000438 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008034, test:0.000579 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008314, test:0.000379 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011668, test:0.002014 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009898, test:0.000842 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008743, test:0.002059 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008346, test:0.004121 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007636, test:0.000385 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008786, test:0.000709 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.014781, test:0.000394 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009682, test:0.000538 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007876, test:0.000874 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007226, test:0.000406 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007728, test:0.000994 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008427, test:0.006678 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007295, test:0.000879 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007872, test:0.003804 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008917, test:0.000497 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008861, test:0.001452 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009581, test:0.006034 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.010368, test:0.000471 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007906, test:0.002488 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007351, test:0.001313 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007729, test:0.001039 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007017, test:0.001742 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007375, test:0.000843 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006462, test:0.000482 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007387, test:0.002695 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006586, test:0.001088 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007453, test:0.000439 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007875, test:0.001217 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007980, test:0.000886 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007421, test:0.000313 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007241, test:0.002882 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009618, test:0.000475 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005747, test:0.000542 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005825, test:0.000460 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007567, test:0.000409 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005594, test:0.000557 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005432, test:0.000564 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005818, test:0.000505 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005580, test:0.000503 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005534, test:0.000471 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005240, test:0.000352 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005318, test:0.000462 | lr:0.001000\n",
      "Mean absolute error:  2.0530296974375037\n",
      "Root mean squared error:  5.920729603135923\n",
      "Epoch[1/100] | loss train:0.049683, test:0.002340 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011895, test:0.000791 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010545, test:0.001079 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010164, test:0.002913 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010418, test:0.001429 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009494, test:0.002379 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009266, test:0.002299 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007891, test:0.000301 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007837, test:0.000512 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007803, test:0.000955 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010488, test:0.004164 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010712, test:0.005517 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/100] | loss train:0.009919, test:0.000454 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.011039, test:0.007076 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008586, test:0.000949 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008991, test:0.001664 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007940, test:0.001079 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006814, test:0.000291 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007018, test:0.000597 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007849, test:0.002584 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008042, test:0.002341 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008238, test:0.000549 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007426, test:0.002927 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008012, test:0.000756 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007925, test:0.001569 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006684, test:0.000434 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006791, test:0.001817 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007216, test:0.000942 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006772, test:0.001002 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008145, test:0.000380 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008236, test:0.001303 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006973, test:0.000456 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008095, test:0.000681 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.010209, test:0.003257 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008208, test:0.000759 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.010529, test:0.003047 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007631, test:0.000442 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006324, test:0.000674 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006827, test:0.000631 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008653, test:0.000575 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006100, test:0.000506 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005626, test:0.000613 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005146, test:0.000414 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006112, test:0.000521 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005586, test:0.000428 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005834, test:0.000377 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005278, test:0.000455 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005931, test:0.000317 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004857, test:0.000705 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005459, test:0.000330 | lr:0.001000\n",
      "Mean absolute error:  1.8994077761458394\n",
      "Root mean squared error:  5.8833511094570845\n",
      "Epoch[1/100] | loss train:0.039316, test:0.010878 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012609, test:0.001136 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009851, test:0.000461 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009605, test:0.003471 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010995, test:0.000768 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010775, test:0.004245 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010654, test:0.006197 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010029, test:0.001795 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007705, test:0.000337 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008000, test:0.001650 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008807, test:0.000660 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007871, test:0.001339 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.011090, test:0.001181 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007540, test:0.000740 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006948, test:0.001751 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008249, test:0.000591 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008008, test:0.002446 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006795, test:0.000963 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007681, test:0.000599 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007935, test:0.000763 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007618, test:0.000628 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007261, test:0.000620 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008435, test:0.000579 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007409, test:0.000536 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007410, test:0.003236 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007231, test:0.000658 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007533, test:0.003452 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007213, test:0.001226 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.009077, test:0.001130 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007752, test:0.000634 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007534, test:0.000408 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006734, test:0.002486 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007079, test:0.000751 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006707, test:0.000486 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007431, test:0.001849 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008242, test:0.001191 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006752, test:0.000584 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006847, test:0.000979 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008368, test:0.000435 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009906, test:0.000410 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006333, test:0.000377 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005569, test:0.000363 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005305, test:0.000404 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004744, test:0.000349 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.008745, test:0.000358 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005173, test:0.000482 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006016, test:0.000491 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006427, test:0.000350 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005674, test:0.000489 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.007323, test:0.000500 | lr:0.001000\n",
      "Mean absolute error:  2.258329356578713\n",
      "Root mean squared error:  6.135921534173255\n",
      "Epoch[1/100] | loss train:0.049310, test:0.008104 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011711, test:0.000743 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010692, test:0.000297 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010069, test:0.006007 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010648, test:0.008413 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008538, test:0.003268 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007539, test:0.000702 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010252, test:0.000531 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007467, test:0.002757 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007947, test:0.001280 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008647, test:0.002488 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008414, test:0.000647 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009460, test:0.007382 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008423, test:0.001579 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007179, test:0.002670 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006973, test:0.000451 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.015205, test:0.002792 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008592, test:0.000369 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009556, test:0.000375 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006954, test:0.003516 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.010936, test:0.000412 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.010982, test:0.000499 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007847, test:0.000686 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007076, test:0.002895 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007345, test:0.002250 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007435, test:0.000480 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006694, test:0.000868 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007573, test:0.000385 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010965, test:0.000588 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007457, test:0.000674 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007343, test:0.001045 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006894, test:0.001065 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006312, test:0.001149 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007547, test:0.000559 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006980, test:0.000626 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.005826, test:0.002701 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/100] | loss train:0.007057, test:0.000715 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006626, test:0.001145 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.011238, test:0.000975 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008280, test:0.000372 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005424, test:0.000452 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.010523, test:0.000371 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005619, test:0.000402 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005203, test:0.000374 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005695, test:0.000411 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005445, test:0.000454 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005911, test:0.000467 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005094, test:0.000343 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006114, test:0.000344 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005659, test:0.000325 | lr:0.001000\n",
      "Mean absolute error:  2.0173447029582903\n",
      "Root mean squared error:  5.873798544409702\n",
      "Epoch[1/100] | loss train:0.052175, test:0.004094 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012987, test:0.006229 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013142, test:0.003493 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009070, test:0.006766 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009364, test:0.000672 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008355, test:0.000432 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.016124, test:0.002975 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.014856, test:0.010413 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009053, test:0.002598 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008091, test:0.000726 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007759, test:0.000367 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008663, test:0.005290 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008645, test:0.000437 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007585, test:0.000776 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006784, test:0.000468 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006202, test:0.001671 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007309, test:0.000406 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008277, test:0.001272 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007425, test:0.000369 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007743, test:0.000453 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009983, test:0.001299 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007664, test:0.001305 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007089, test:0.000758 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007297, test:0.000556 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007532, test:0.003361 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007330, test:0.000614 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006908, test:0.000678 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006934, test:0.003070 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007819, test:0.002406 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008003, test:0.000906 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007678, test:0.005035 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008777, test:0.002211 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008511, test:0.001796 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007469, test:0.000676 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006713, test:0.000341 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007044, test:0.001366 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007021, test:0.000527 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.013624, test:0.000520 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008333, test:0.004487 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007714, test:0.000508 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005189, test:0.000370 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005556, test:0.000769 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007034, test:0.000432 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005763, test:0.000400 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005463, test:0.000377 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005933, test:0.000439 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005689, test:0.000558 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005765, test:0.000477 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005572, test:0.000327 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006045, test:0.000956 | lr:0.001000\n",
      "Mean absolute error:  2.6608938485172176\n",
      "Root mean squared error:  6.662822530372924\n",
      "Epoch[1/100] | loss train:0.069894, test:0.013095 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.018601, test:0.001050 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011096, test:0.005850 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011100, test:0.006362 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010963, test:0.000541 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008006, test:0.002133 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009031, test:0.002517 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008967, test:0.002082 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008026, test:0.000363 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008416, test:0.002172 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008410, test:0.000331 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010152, test:0.003610 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008150, test:0.000533 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008386, test:0.000695 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008020, test:0.000567 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006705, test:0.000468 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009976, test:0.000544 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007921, test:0.000394 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006779, test:0.001087 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007763, test:0.000340 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007822, test:0.000447 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007845, test:0.000757 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006584, test:0.003896 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007919, test:0.000471 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006869, test:0.000355 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007916, test:0.000398 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.010353, test:0.000723 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007193, test:0.000499 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006439, test:0.001448 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.011857, test:0.002991 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009905, test:0.000414 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006987, test:0.000521 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006103, test:0.000372 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007276, test:0.001002 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007692, test:0.000344 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006995, test:0.007204 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008243, test:0.000443 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007330, test:0.003131 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007304, test:0.001206 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006800, test:0.000325 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.008366, test:0.000364 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005732, test:0.000346 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005381, test:0.000344 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.011133, test:0.000358 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005553, test:0.000335 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005770, test:0.000333 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004768, test:0.000308 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005316, test:0.000520 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005463, test:0.000381 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006164, test:0.000290 | lr:0.001000\n",
      "Mean absolute error:  1.7574668534732976\n",
      "Root mean squared error:  5.804786554915982\n",
      "Epoch[1/100] | loss train:0.055822, test:0.000547 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013391, test:0.007069 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.015664, test:0.001151 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010762, test:0.002472 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010747, test:0.000412 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009667, test:0.006052 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010172, test:0.001426 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010424, test:0.001384 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010276, test:0.008668 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/100] | loss train:0.008939, test:0.001718 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011137, test:0.000475 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008785, test:0.000888 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009905, test:0.000703 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007467, test:0.000485 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009302, test:0.002158 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008533, test:0.000355 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008769, test:0.000673 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007676, test:0.000620 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008583, test:0.000417 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007914, test:0.001908 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008478, test:0.000755 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007831, test:0.000373 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008866, test:0.001084 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007730, test:0.001203 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008889, test:0.000444 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007966, test:0.001054 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007490, test:0.000720 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008347, test:0.000801 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007860, test:0.002875 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007919, test:0.000844 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008408, test:0.001036 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007558, test:0.000595 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007298, test:0.000356 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.017656, test:0.002401 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009779, test:0.000454 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008875, test:0.000546 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008227, test:0.001364 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007160, test:0.000488 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008402, test:0.003032 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007169, test:0.000680 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006834, test:0.000454 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006098, test:0.000493 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006917, test:0.000513 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005781, test:0.000423 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005327, test:0.000377 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005999, test:0.000644 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005896, test:0.000416 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006179, test:0.000493 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006260, test:0.000407 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005506, test:0.000496 | lr:0.001000\n",
      "Mean absolute error:  2.164487178767467\n",
      "Root mean squared error:  6.100577721246805\n",
      "Epoch[1/100] | loss train:0.075668, test:0.000358 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013953, test:0.001270 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011012, test:0.001217 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010662, test:0.005824 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.013174, test:0.002568 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008843, test:0.002032 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008920, test:0.000522 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008719, test:0.005650 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009939, test:0.000354 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011020, test:0.000421 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.014800, test:0.007788 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011499, test:0.001425 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009227, test:0.000386 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.015919, test:0.000451 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009873, test:0.000667 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008232, test:0.001791 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007678, test:0.001612 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008645, test:0.000491 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007918, test:0.001087 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006774, test:0.000656 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006876, test:0.000689 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007749, test:0.002484 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007872, test:0.000607 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008354, test:0.000593 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008883, test:0.000437 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008103, test:0.000851 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007240, test:0.002597 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008262, test:0.000448 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007470, test:0.000726 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007952, test:0.000561 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008385, test:0.000462 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009000, test:0.000466 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008100, test:0.001822 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007776, test:0.000412 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008446, test:0.000931 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009011, test:0.000765 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007764, test:0.001541 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007621, test:0.000943 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006787, test:0.001468 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009053, test:0.000485 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006541, test:0.000440 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006063, test:0.000469 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005461, test:0.000425 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005838, test:0.000463 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005484, test:0.000379 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006482, test:0.000385 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005234, test:0.000607 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005762, test:0.000443 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005304, test:0.000397 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005176, test:0.000371 | lr:0.001000\n",
      "Mean absolute error:  2.0453991729949546\n",
      "Root mean squared error:  5.910777675058635\n",
      "Epoch[1/100] | loss train:0.042804, test:0.000903 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010080, test:0.003957 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009955, test:0.004246 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008792, test:0.000338 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009534, test:0.000634 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010703, test:0.000384 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008324, test:0.000882 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008479, test:0.000328 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008239, test:0.000651 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008054, test:0.002246 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009634, test:0.004098 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010111, test:0.001315 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008564, test:0.000487 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008149, test:0.003641 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009525, test:0.007727 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008598, test:0.000331 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008293, test:0.003510 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007817, test:0.000391 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007579, test:0.000856 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.011135, test:0.001598 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.011594, test:0.004608 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009247, test:0.000618 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010487, test:0.006239 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007849, test:0.000701 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008834, test:0.003065 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007074, test:0.000870 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.010991, test:0.000685 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007856, test:0.001669 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006955, test:0.000892 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007587, test:0.001521 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008344, test:0.000832 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007572, test:0.000637 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007803, test:0.002222 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/100] | loss train:0.008719, test:0.002483 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008096, test:0.000692 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007682, test:0.003057 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008561, test:0.002791 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007433, test:0.005032 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007976, test:0.002642 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007023, test:0.000394 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006057, test:0.000341 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006293, test:0.000396 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005121, test:0.000339 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.008586, test:0.000358 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006131, test:0.000327 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006009, test:0.000331 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005669, test:0.000331 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005804, test:0.000343 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005879, test:0.000475 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005574, test:0.000309 | lr:0.001000\n",
      "Mean absolute error:  1.701499427105494\n",
      "Root mean squared error:  5.794342125124638\n",
      "Epoch[1/100] | loss train:0.051790, test:0.002090 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012011, test:0.000621 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.014686, test:0.002271 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013045, test:0.001507 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010384, test:0.000603 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011781, test:0.002761 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.012160, test:0.000587 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.012977, test:0.002527 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008276, test:0.000383 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009701, test:0.000527 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009488, test:0.000425 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010502, test:0.000718 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008560, test:0.000610 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009012, test:0.000591 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008814, test:0.000878 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008857, test:0.000590 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007326, test:0.000891 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007593, test:0.000524 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007315, test:0.000365 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009270, test:0.000482 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009224, test:0.000403 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007986, test:0.000642 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006617, test:0.000568 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.013525, test:0.001287 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008545, test:0.000911 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.013584, test:0.000794 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008890, test:0.000553 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008166, test:0.001103 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007274, test:0.001927 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007754, test:0.001063 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008358, test:0.000432 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007915, test:0.000429 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008241, test:0.001152 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008234, test:0.000725 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007226, test:0.000613 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009619, test:0.001571 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007271, test:0.002587 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008028, test:0.000529 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008501, test:0.002228 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.010008, test:0.000838 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007886, test:0.000473 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006432, test:0.000462 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005958, test:0.000528 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005417, test:0.000707 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005227, test:0.000956 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005838, test:0.000458 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005643, test:0.000650 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006660, test:0.000469 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.008002, test:0.000441 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005495, test:0.000386 | lr:0.001000\n",
      "Mean absolute error:  1.784842166112611\n",
      "Root mean squared error:  5.872390806047307\n",
      "Epoch[1/100] | loss train:0.063207, test:0.000616 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012000, test:0.003451 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009295, test:0.009282 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011101, test:0.001227 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010057, test:0.000506 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008804, test:0.000314 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008967, test:0.002908 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009190, test:0.000629 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009478, test:0.001243 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008259, test:0.000512 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008137, test:0.004625 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008129, test:0.000575 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007508, test:0.000736 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008439, test:0.002237 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008638, test:0.000403 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009739, test:0.001468 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009073, test:0.005047 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010762, test:0.000614 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007922, test:0.000452 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007405, test:0.002048 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008050, test:0.000640 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006850, test:0.002599 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007710, test:0.003417 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009150, test:0.001092 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007104, test:0.001302 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007102, test:0.000422 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006730, test:0.000806 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007239, test:0.001646 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006706, test:0.000793 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006996, test:0.000415 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009629, test:0.000575 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006942, test:0.002445 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008312, test:0.000554 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006924, test:0.004309 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009069, test:0.000331 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009894, test:0.007487 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009981, test:0.001917 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006599, test:0.000487 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.009360, test:0.000499 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006965, test:0.001248 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005524, test:0.000469 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006033, test:0.000404 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006026, test:0.000414 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.014409, test:0.000386 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006223, test:0.000363 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005841, test:0.000378 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005408, test:0.000403 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005436, test:0.000340 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005378, test:0.000344 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005416, test:0.000338 | lr:0.001000\n",
      "Mean absolute error:  1.7126097098865865\n",
      "Root mean squared error:  5.811640354548313\n",
      "Epoch[1/100] | loss train:0.078443, test:0.001205 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013145, test:0.001263 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.014590, test:0.001367 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011117, test:0.004043 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011904, test:0.000406 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010155, test:0.014027 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/100] | loss train:0.009108, test:0.001143 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009305, test:0.002266 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.018075, test:0.002064 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010946, test:0.000684 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009046, test:0.005351 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009479, test:0.003910 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008318, test:0.000600 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007912, test:0.001170 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.012612, test:0.000732 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010904, test:0.003260 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010335, test:0.000800 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007257, test:0.000953 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007834, test:0.000412 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008341, test:0.001532 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008568, test:0.000518 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007229, test:0.000755 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006526, test:0.000370 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008606, test:0.003782 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007111, test:0.004020 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008196, test:0.001304 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007919, test:0.000343 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007937, test:0.000365 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010017, test:0.006582 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008593, test:0.001060 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008057, test:0.002209 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008479, test:0.006170 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008758, test:0.001159 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007000, test:0.000510 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008938, test:0.002189 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007633, test:0.000515 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006705, test:0.000835 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008029, test:0.002405 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008020, test:0.003523 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008871, test:0.000569 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005901, test:0.000584 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006416, test:0.000539 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005607, test:0.000396 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006104, test:0.000390 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005803, test:0.000359 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006247, test:0.000383 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007241, test:0.000549 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005556, test:0.000454 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006830, test:0.000353 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005887, test:0.000616 | lr:0.001000\n",
      "Mean absolute error:  2.3665450594341615\n",
      "Root mean squared error:  6.292245192309691\n",
      "Epoch[1/100] | loss train:0.058117, test:0.000404 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012028, test:0.003633 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009176, test:0.000391 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.014645, test:0.000480 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.015238, test:0.005250 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011475, test:0.000398 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007578, test:0.001795 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010957, test:0.007670 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008147, test:0.001457 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007488, test:0.000395 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007532, test:0.009780 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011459, test:0.006070 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008558, test:0.000722 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006306, test:0.000786 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006975, test:0.001263 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.012155, test:0.000441 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008498, test:0.001880 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008050, test:0.000950 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007433, test:0.001152 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007595, test:0.000922 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007279, test:0.000800 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007404, test:0.002589 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006853, test:0.001536 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007327, test:0.000321 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009168, test:0.001085 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006492, test:0.000602 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009504, test:0.001570 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007508, test:0.000402 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007002, test:0.001208 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008580, test:0.002240 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009232, test:0.000659 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007837, test:0.000471 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007991, test:0.004214 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007490, test:0.000493 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007495, test:0.002608 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006281, test:0.001629 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006649, test:0.000972 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007091, test:0.000880 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006113, test:0.002700 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007573, test:0.000427 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005515, test:0.000421 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006166, test:0.000511 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005879, test:0.000350 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005153, test:0.000421 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005324, test:0.000619 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005705, test:0.000430 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005954, test:0.000388 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005143, test:0.000451 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004979, test:0.000382 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004993, test:0.000357 | lr:0.001000\n",
      "Mean absolute error:  1.9711925633311365\n",
      "Root mean squared error:  5.880875702352179\n",
      "Epoch[1/100] | loss train:0.056740, test:0.001017 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011752, test:0.001099 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008946, test:0.000367 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010567, test:0.001365 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009732, test:0.011206 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.013853, test:0.002066 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009529, test:0.001219 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.015432, test:0.007140 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011864, test:0.001284 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008114, test:0.000405 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007222, test:0.002175 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008002, test:0.000468 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007528, test:0.002387 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007859, test:0.000484 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007720, test:0.000384 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008179, test:0.000994 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008764, test:0.000811 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007166, test:0.001463 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.010242, test:0.003760 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008712, test:0.003862 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007542, test:0.001519 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009955, test:0.000640 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007673, test:0.002825 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007136, test:0.000454 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007592, test:0.000457 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007707, test:0.001064 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008579, test:0.002612 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008897, test:0.000753 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007748, test:0.000549 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008021, test:0.000397 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31/100] | loss train:0.009250, test:0.000404 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008707, test:0.001333 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007132, test:0.000599 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006378, test:0.000740 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007783, test:0.000387 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007016, test:0.000988 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007823, test:0.000384 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007025, test:0.000478 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007373, test:0.001145 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008092, test:0.000742 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005688, test:0.000407 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005918, test:0.000448 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005699, test:0.000494 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005237, test:0.000347 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005254, test:0.000398 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004813, test:0.000413 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005849, test:0.000368 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006887, test:0.000396 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005489, test:0.000515 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006060, test:0.000381 | lr:0.001000\n",
      "Mean absolute error:  1.9588737702145542\n",
      "Root mean squared error:  5.908303731745482\n",
      "Epoch[1/100] | loss train:0.055492, test:0.000644 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011634, test:0.002466 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011996, test:0.000444 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013854, test:0.000277 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008844, test:0.000408 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008790, test:0.002330 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.013112, test:0.000302 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.014952, test:0.001289 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010246, test:0.000779 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009773, test:0.004557 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008145, test:0.001332 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008048, test:0.000474 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008378, test:0.000432 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009228, test:0.008701 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009959, test:0.000550 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007278, test:0.000458 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007905, test:0.000769 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010906, test:0.003635 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008061, test:0.000383 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007304, test:0.000761 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007513, test:0.000562 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.012243, test:0.001985 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007917, test:0.000862 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008067, test:0.000414 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006709, test:0.001420 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008079, test:0.001523 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007503, test:0.000941 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006801, test:0.001044 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006820, test:0.000360 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007943, test:0.006257 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007501, test:0.000551 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008016, test:0.002019 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006274, test:0.000410 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009468, test:0.000936 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008402, test:0.000547 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007834, test:0.000641 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007875, test:0.000431 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006902, test:0.000627 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007166, test:0.000677 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007936, test:0.001928 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006123, test:0.000420 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005973, test:0.000420 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005290, test:0.000449 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005672, test:0.000383 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005765, test:0.000419 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006658, test:0.000386 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005334, test:0.000446 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005639, test:0.000475 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006283, test:0.000433 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005286, test:0.000397 | lr:0.001000\n",
      "Mean absolute error:  2.3222690857561377\n",
      "Root mean squared error:  6.00003155243243\n",
      "Epoch[1/100] | loss train:0.044008, test:0.001912 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011376, test:0.000574 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008790, test:0.003953 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010836, test:0.002197 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009868, test:0.004074 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009140, test:0.002019 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.013726, test:0.003340 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011366, test:0.000672 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008361, test:0.002948 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008339, test:0.000749 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008141, test:0.003068 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008167, test:0.000449 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008896, test:0.000677 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008826, test:0.000472 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008252, test:0.001285 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.018083, test:0.001299 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007643, test:0.000992 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008165, test:0.002074 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007241, test:0.000605 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008807, test:0.002955 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007335, test:0.001413 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007746, test:0.000470 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009527, test:0.002421 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007186, test:0.001290 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008045, test:0.000830 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009316, test:0.000554 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006592, test:0.003738 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007448, test:0.000519 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006343, test:0.000793 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006950, test:0.001131 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006968, test:0.000366 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007343, test:0.000513 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006791, test:0.000321 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006721, test:0.000508 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007795, test:0.000412 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007029, test:0.002271 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008562, test:0.000408 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006764, test:0.000298 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006275, test:0.000904 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.005865, test:0.000986 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005381, test:0.000362 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005210, test:0.000367 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005501, test:0.000500 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005300, test:0.000356 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005439, test:0.000466 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004896, test:0.000333 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005353, test:0.000318 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004921, test:0.000329 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004750, test:0.000331 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005150, test:0.000319 | lr:0.001000\n",
      "Mean absolute error:  1.7054124800076471\n",
      "Root mean squared error:  5.802290800620936\n",
      "Epoch[1/100] | loss train:0.044599, test:0.000431 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011373, test:0.000798 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008424, test:0.000678 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/100] | loss train:0.017778, test:0.000314 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008898, test:0.000487 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007236, test:0.000887 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009031, test:0.004127 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008276, test:0.000542 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008839, test:0.000710 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009051, test:0.002742 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008043, test:0.002584 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008091, test:0.003350 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007943, test:0.000758 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007445, test:0.000669 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008891, test:0.001363 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008545, test:0.000838 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007189, test:0.000388 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007592, test:0.000500 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.011315, test:0.003192 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008876, test:0.001486 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007415, test:0.000504 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006679, test:0.001341 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007092, test:0.000703 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.011062, test:0.001596 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008441, test:0.001221 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007307, test:0.001158 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008289, test:0.000404 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007380, test:0.002023 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007113, test:0.000394 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006534, test:0.000341 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007324, test:0.000578 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006718, test:0.000830 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007024, test:0.000576 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006723, test:0.001969 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007365, test:0.000502 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006757, test:0.000660 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007614, test:0.000982 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006614, test:0.000320 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007113, test:0.000383 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007631, test:0.000310 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006008, test:0.000566 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005616, test:0.000321 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005023, test:0.000318 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005246, test:0.000362 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005136, test:0.000376 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005104, test:0.000346 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.017042, test:0.000307 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004897, test:0.000364 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005096, test:0.000345 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005568, test:0.000567 | lr:0.001000\n",
      "Mean absolute error:  2.214096371563598\n",
      "Root mean squared error:  6.098480767278849\n",
      "Epoch[1/100] | loss train:0.064942, test:0.000637 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012488, test:0.002575 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.014527, test:0.000534 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009605, test:0.000792 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009703, test:0.009409 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009140, test:0.001459 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007014, test:0.001549 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008707, test:0.000321 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008999, test:0.001623 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008327, test:0.004242 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007782, test:0.000408 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.006902, test:0.000559 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008390, test:0.006738 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008999, test:0.000547 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006827, test:0.000880 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007477, test:0.000544 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007968, test:0.003086 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007140, test:0.001250 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007602, test:0.000557 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006181, test:0.001804 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009736, test:0.001295 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007231, test:0.000394 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006907, test:0.000512 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008704, test:0.001115 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007513, test:0.000622 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006493, test:0.001289 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007164, test:0.001016 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008268, test:0.000620 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007607, test:0.000670 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007445, test:0.001258 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008235, test:0.000557 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007075, test:0.000709 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006713, test:0.000419 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006724, test:0.000466 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007067, test:0.000674 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008002, test:0.002644 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006881, test:0.001883 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007813, test:0.003594 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007612, test:0.002179 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007015, test:0.001296 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006132, test:0.000554 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005395, test:0.000528 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006566, test:0.000385 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006327, test:0.000385 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005005, test:0.000334 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005671, test:0.000546 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005196, test:0.000345 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005117, test:0.000322 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004679, test:0.000397 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005106, test:0.000518 | lr:0.001000\n",
      "Mean absolute error:  2.2039965046602923\n",
      "Root mean squared error:  6.178510035321743\n",
      "Epoch[1/100] | loss train:0.036120, test:0.000495 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012315, test:0.001437 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009804, test:0.000413 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009638, test:0.000715 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009203, test:0.000697 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008151, test:0.003324 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.006787, test:0.002014 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008127, test:0.002531 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008414, test:0.004628 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008016, test:0.000837 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007658, test:0.001056 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009672, test:0.000401 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007860, test:0.001535 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008606, test:0.000464 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008733, test:0.000389 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008544, test:0.000482 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006944, test:0.000642 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007993, test:0.005912 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007551, test:0.000466 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008515, test:0.000510 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007388, test:0.002419 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007655, test:0.000729 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008162, test:0.001018 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006998, test:0.000853 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008783, test:0.000680 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006573, test:0.000432 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007413, test:0.008567 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28/100] | loss train:0.008077, test:0.001033 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006796, test:0.003696 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007416, test:0.001182 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008012, test:0.002133 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007770, test:0.001017 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008219, test:0.000391 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006556, test:0.000442 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.005949, test:0.000397 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006612, test:0.000715 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008573, test:0.000703 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007424, test:0.000581 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.010831, test:0.000529 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006990, test:0.000476 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.008270, test:0.000495 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.009946, test:0.000376 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005235, test:0.000317 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005109, test:0.000314 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006283, test:0.000410 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004826, test:0.000378 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005458, test:0.000358 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005538, test:0.000352 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005033, test:0.000341 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005319, test:0.000329 | lr:0.001000\n",
      "Mean absolute error:  1.796962637979631\n",
      "Root mean squared error:  5.828631374908742\n",
      "Epoch[1/100] | loss train:0.050486, test:0.012754 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013615, test:0.004505 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013410, test:0.001090 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011216, test:0.006370 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011420, test:0.001460 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010009, test:0.002061 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008304, test:0.000723 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008338, test:0.003804 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008844, test:0.000857 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008408, test:0.002209 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007400, test:0.001127 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008945, test:0.007299 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009418, test:0.001213 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007642, test:0.000783 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007481, test:0.001099 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009719, test:0.002141 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008885, test:0.000375 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007547, test:0.000393 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006869, test:0.003617 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007252, test:0.000346 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007886, test:0.000858 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007174, test:0.000336 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008739, test:0.000482 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006655, test:0.000920 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007511, test:0.000682 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007274, test:0.001019 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006842, test:0.000445 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.010498, test:0.002394 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007346, test:0.002483 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006340, test:0.000540 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.017371, test:0.000540 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007276, test:0.000425 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007624, test:0.000475 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007123, test:0.000369 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007225, test:0.000568 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007616, test:0.000714 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007364, test:0.003781 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007948, test:0.000795 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006966, test:0.001430 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007213, test:0.000680 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.009347, test:0.000406 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.004922, test:0.000341 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005223, test:0.000552 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004999, test:0.000389 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005870, test:0.000358 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005264, test:0.000342 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006301, test:0.000327 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005775, test:0.000318 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005464, test:0.000346 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006916, test:0.000318 | lr:0.001000\n",
      "Mean absolute error:  1.7921948776191539\n",
      "Root mean squared error:  5.826469355255662\n",
      "Epoch[1/100] | loss train:0.047947, test:0.002031 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011289, test:0.000386 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011083, test:0.000589 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009470, test:0.001749 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011030, test:0.000760 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009023, test:0.000772 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008935, test:0.006690 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010210, test:0.004415 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011608, test:0.001476 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010082, test:0.006375 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008823, test:0.000474 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009453, test:0.002674 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.015854, test:0.002698 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009456, test:0.001162 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006635, test:0.000423 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.011599, test:0.002870 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010982, test:0.000548 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008178, test:0.004775 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.013406, test:0.000468 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006977, test:0.000576 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007226, test:0.000663 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008092, test:0.000475 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007875, test:0.001498 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007509, test:0.001740 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008461, test:0.003388 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008198, test:0.000465 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008579, test:0.001234 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009679, test:0.000977 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006932, test:0.001635 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007499, test:0.000538 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006997, test:0.001478 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007971, test:0.000372 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007255, test:0.000823 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006705, test:0.000812 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007739, test:0.001837 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006877, test:0.000928 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006108, test:0.005127 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007836, test:0.000801 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006605, test:0.000589 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007517, test:0.000456 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006174, test:0.000821 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007352, test:0.000617 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005432, test:0.000595 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005493, test:0.000446 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005464, test:0.000410 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005185, test:0.000479 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006022, test:0.000353 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005920, test:0.000369 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005468, test:0.000367 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005699, test:0.000540 | lr:0.001000\n",
      "Mean absolute error:  2.1114236838580824\n",
      "Root mean squared error:  6.088247623930705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] | loss train:0.055230, test:0.000663 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011376, test:0.003030 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011314, test:0.004330 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009641, test:0.003830 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009812, test:0.002773 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009851, test:0.004119 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009596, test:0.000957 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008343, test:0.000594 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007932, test:0.000348 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007213, test:0.001003 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010138, test:0.005749 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009548, test:0.000565 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009203, test:0.002121 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007292, test:0.000430 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009202, test:0.000547 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008309, test:0.002894 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008540, test:0.007524 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008880, test:0.000619 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007324, test:0.001298 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007439, test:0.000587 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008614, test:0.004505 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007530, test:0.001574 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007238, test:0.002703 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.011078, test:0.000496 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009152, test:0.003007 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008236, test:0.000366 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006837, test:0.000561 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007434, test:0.000664 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007160, test:0.000592 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007077, test:0.001056 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006986, test:0.000831 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008775, test:0.001007 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007299, test:0.000994 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.011286, test:0.004200 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.010705, test:0.001339 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.012550, test:0.000359 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009539, test:0.000733 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006104, test:0.000890 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006251, test:0.000885 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007050, test:0.001062 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007867, test:0.000531 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006079, test:0.000386 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005374, test:0.000433 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004947, test:0.000660 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006107, test:0.000415 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004845, test:0.000352 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.008880, test:0.000509 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005332, test:0.000383 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005459, test:0.000364 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005075, test:0.000410 | lr:0.001000\n",
      "Mean absolute error:  1.7950528223522544\n",
      "Root mean squared error:  5.873907673472002\n",
      "Epoch[1/100] | loss train:0.051446, test:0.003132 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014707, test:0.001133 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010660, test:0.000383 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008893, test:0.000324 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007689, test:0.000392 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007317, test:0.004880 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.013944, test:0.007179 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011033, test:0.000375 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008525, test:0.004630 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.013267, test:0.002654 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007717, test:0.000682 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009095, test:0.001675 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007242, test:0.000336 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.012973, test:0.000648 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008797, test:0.000407 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007763, test:0.002127 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008970, test:0.000587 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007448, test:0.000362 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007907, test:0.001606 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007374, test:0.001005 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008252, test:0.001282 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008375, test:0.001581 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007889, test:0.000526 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008037, test:0.000815 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007453, test:0.000453 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009033, test:0.000913 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008581, test:0.002373 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008362, test:0.001710 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007203, test:0.006418 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007898, test:0.000656 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006758, test:0.001002 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006170, test:0.000711 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007535, test:0.002149 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006985, test:0.000722 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009299, test:0.001622 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008781, test:0.000562 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007145, test:0.000634 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008569, test:0.001234 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007439, test:0.000518 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006953, test:0.000860 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006708, test:0.000388 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005508, test:0.000383 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006271, test:0.000412 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005413, test:0.000354 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005641, test:0.000376 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005713, test:0.000411 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006160, test:0.000376 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006343, test:0.000365 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005213, test:0.000414 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005146, test:0.000463 | lr:0.001000\n",
      "Mean absolute error:  2.22907916787826\n",
      "Root mean squared error:  6.064482208843915\n",
      "Epoch[1/100] | loss train:0.058878, test:0.001384 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011662, test:0.004331 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011277, test:0.000761 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010109, test:0.000566 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010192, test:0.000347 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009027, test:0.000363 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009079, test:0.000263 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010441, test:0.007034 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007739, test:0.000409 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008489, test:0.001980 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009206, test:0.009666 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010589, test:0.000504 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007976, test:0.001227 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.014802, test:0.001488 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009292, test:0.003971 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007979, test:0.000609 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007957, test:0.000632 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.013837, test:0.000508 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.010566, test:0.000375 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008219, test:0.000546 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007561, test:0.000587 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008804, test:0.000669 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007565, test:0.000796 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006548, test:0.000345 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/100] | loss train:0.007537, test:0.003144 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.011792, test:0.000748 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008286, test:0.000469 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006750, test:0.000990 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006931, test:0.001729 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006841, test:0.001494 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008265, test:0.000641 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007778, test:0.002114 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007411, test:0.001086 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.011659, test:0.001728 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.011722, test:0.001061 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007789, test:0.000506 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007337, test:0.000469 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009478, test:0.000426 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006930, test:0.002333 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009451, test:0.001328 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005716, test:0.000382 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005146, test:0.000473 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005518, test:0.000359 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005334, test:0.000386 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006051, test:0.000401 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005334, test:0.000355 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006817, test:0.000339 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005030, test:0.000335 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004952, test:0.000696 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004959, test:0.000322 | lr:0.001000\n",
      "Mean absolute error:  2.083456246333502\n",
      "Root mean squared error:  5.902765793829139\n",
      "Epoch[1/100] | loss train:0.050866, test:0.001867 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011266, test:0.004358 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011635, test:0.004177 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.007963, test:0.000802 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010677, test:0.000337 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008021, test:0.000895 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008562, test:0.002003 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008244, test:0.002290 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007229, test:0.000466 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008908, test:0.007074 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008681, test:0.001046 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011370, test:0.002871 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009298, test:0.001049 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006679, test:0.000448 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007878, test:0.000477 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009476, test:0.000448 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007298, test:0.004382 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009222, test:0.001420 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007189, test:0.004148 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007806, test:0.001719 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006586, test:0.000463 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006898, test:0.001566 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008191, test:0.000574 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008116, test:0.004056 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007662, test:0.000369 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009122, test:0.003176 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008336, test:0.000654 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008004, test:0.000503 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007350, test:0.001339 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008575, test:0.002717 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006928, test:0.001262 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006009, test:0.000567 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006527, test:0.000407 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008087, test:0.000661 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008744, test:0.001073 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007662, test:0.000979 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006468, test:0.001342 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007371, test:0.000537 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008182, test:0.001893 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006607, test:0.000484 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007494, test:0.000344 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005384, test:0.000334 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005319, test:0.000489 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005006, test:0.000338 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005462, test:0.000274 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005007, test:0.000291 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.009312, test:0.000363 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006172, test:0.000292 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004829, test:0.000339 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005036, test:0.000588 | lr:0.001000\n",
      "Mean absolute error:  2.152102153960773\n",
      "Root mean squared error:  6.105631511189572\n",
      "Epoch[1/100] | loss train:0.055722, test:0.005863 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010784, test:0.003553 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008960, test:0.000910 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009507, test:0.000785 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011744, test:0.002773 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007790, test:0.001725 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009790, test:0.000470 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007730, test:0.000445 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009287, test:0.001285 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008173, test:0.015714 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008227, test:0.002842 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009298, test:0.001719 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008000, test:0.000532 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009372, test:0.000493 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008553, test:0.000352 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007829, test:0.002489 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008588, test:0.000328 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009123, test:0.001590 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006884, test:0.001025 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007539, test:0.000390 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007924, test:0.002616 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008581, test:0.000624 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008016, test:0.000399 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009807, test:0.000709 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007931, test:0.001517 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007102, test:0.000992 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007495, test:0.001183 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007151, test:0.000475 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008009, test:0.001087 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009297, test:0.000424 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007580, test:0.000557 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.015806, test:0.001557 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009961, test:0.001313 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007586, test:0.000723 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006350, test:0.000960 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007318, test:0.000420 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008143, test:0.000494 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008237, test:0.000810 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008564, test:0.000458 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007866, test:0.000872 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.008945, test:0.000396 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005790, test:0.000438 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005618, test:0.000365 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005085, test:0.000639 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005550, test:0.000407 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005777, test:0.000459 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006188, test:0.000390 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005612, test:0.000407 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49/100] | loss train:0.006070, test:0.000393 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005551, test:0.000380 | lr:0.001000\n",
      "Mean absolute error:  1.7552094969545255\n",
      "Root mean squared error:  5.848438424098581\n",
      "Epoch[1/100] | loss train:0.069496, test:0.001162 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011205, test:0.000825 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009842, test:0.001418 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009626, test:0.002583 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010119, test:0.001446 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009757, test:0.000518 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007844, test:0.003535 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009999, test:0.000806 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008649, test:0.000434 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007009, test:0.000330 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008501, test:0.000348 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009677, test:0.001376 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007221, test:0.000340 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006496, test:0.000347 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008011, test:0.001211 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007602, test:0.000371 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008522, test:0.006357 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009029, test:0.000314 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007468, test:0.001351 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.010695, test:0.000855 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006767, test:0.000629 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007162, test:0.002544 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.009967, test:0.004908 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008523, test:0.000658 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007530, test:0.001621 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007880, test:0.001018 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006930, test:0.000334 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006915, test:0.000715 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006855, test:0.000393 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008410, test:0.003636 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007554, test:0.000306 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009133, test:0.001749 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007231, test:0.000427 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006409, test:0.001281 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007410, test:0.002041 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006205, test:0.000907 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007681, test:0.000581 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006808, test:0.000286 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.009315, test:0.000818 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007117, test:0.000674 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005517, test:0.000343 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005895, test:0.000315 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006490, test:0.000323 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005166, test:0.000366 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005690, test:0.000370 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006116, test:0.000344 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006310, test:0.000401 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005765, test:0.000405 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007046, test:0.000350 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005227, test:0.000466 | lr:0.001000\n",
      "Mean absolute error:  2.292430210790984\n",
      "Root mean squared error:  6.181113207887478\n",
      "Epoch[1/100] | loss train:0.057169, test:0.000704 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013177, test:0.006155 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011899, test:0.000591 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010010, test:0.000366 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011566, test:0.001290 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008925, test:0.000365 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008961, test:0.000458 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008200, test:0.000688 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009027, test:0.003684 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010098, test:0.002677 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007601, test:0.002069 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010723, test:0.000469 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008326, test:0.000471 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007381, test:0.002219 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007739, test:0.001939 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008790, test:0.000855 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007719, test:0.001370 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007351, test:0.001030 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007241, test:0.000415 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009716, test:0.000839 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006721, test:0.002006 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007800, test:0.000403 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007732, test:0.001221 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.011519, test:0.001161 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007353, test:0.001033 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007511, test:0.003240 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007578, test:0.000822 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007803, test:0.000844 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007100, test:0.000529 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007296, test:0.001319 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.011712, test:0.004587 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008635, test:0.001120 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006481, test:0.002468 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007887, test:0.001999 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007371, test:0.000715 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007336, test:0.001307 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008356, test:0.001745 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007992, test:0.000934 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007393, test:0.005903 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007908, test:0.000439 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006007, test:0.000487 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005381, test:0.000489 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006663, test:0.000494 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005324, test:0.000459 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004989, test:0.000464 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006216, test:0.000538 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005241, test:0.000442 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.009619, test:0.000470 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006527, test:0.000426 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005645, test:0.000399 | lr:0.001000\n",
      "Mean absolute error:  1.8912694053761228\n",
      "Root mean squared error:  5.934624530258928\n",
      "Epoch[1/100] | loss train:0.054954, test:0.003001 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012085, test:0.001231 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010922, test:0.000849 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.021060, test:0.015948 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.015747, test:0.003675 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009612, test:0.001953 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009509, test:0.001068 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007962, test:0.002699 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007879, test:0.003327 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010265, test:0.000829 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.024604, test:0.003037 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.013868, test:0.001619 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007458, test:0.002102 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008506, test:0.001641 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008195, test:0.002285 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008285, test:0.000617 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007673, test:0.000430 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007620, test:0.000552 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007688, test:0.000378 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008495, test:0.000441 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006878, test:0.000486 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/100] | loss train:0.006581, test:0.000784 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006450, test:0.000691 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008517, test:0.000520 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009056, test:0.001828 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007980, test:0.000977 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006565, test:0.000382 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007306, test:0.004612 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.010166, test:0.001166 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008194, test:0.001870 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007322, test:0.002926 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007069, test:0.000648 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007674, test:0.000744 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006624, test:0.000497 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006643, test:0.000339 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007394, test:0.002241 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007007, test:0.000319 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007438, test:0.000598 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006606, test:0.000662 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006607, test:0.000501 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.013022, test:0.000369 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005701, test:0.000318 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005431, test:0.000360 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005181, test:0.000321 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005501, test:0.000466 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005739, test:0.000677 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005659, test:0.000478 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005704, test:0.000478 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006910, test:0.000293 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005826, test:0.000317 | lr:0.001000\n",
      "Mean absolute error:  1.816307197520234\n",
      "Root mean squared error:  5.820005441771995\n",
      "Epoch[1/100] | loss train:0.050945, test:0.003654 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011655, test:0.000383 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010061, test:0.009036 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009849, test:0.002504 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009281, test:0.000449 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008069, test:0.000521 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008108, test:0.001678 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008066, test:0.001008 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008019, test:0.001143 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008516, test:0.001752 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007496, test:0.001159 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.006720, test:0.000330 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007823, test:0.000345 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010551, test:0.000606 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007384, test:0.000373 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008034, test:0.000429 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007430, test:0.000408 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007652, test:0.000470 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007070, test:0.004656 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007267, test:0.001355 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007330, test:0.000422 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007514, test:0.004476 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008724, test:0.000316 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007895, test:0.001155 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007318, test:0.000508 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006923, test:0.000954 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007417, test:0.002955 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007080, test:0.000670 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006804, test:0.000422 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006419, test:0.000337 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006134, test:0.000492 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.005911, test:0.000372 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008395, test:0.001054 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007848, test:0.000912 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007827, test:0.000575 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008165, test:0.002841 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007511, test:0.001370 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006563, test:0.000425 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006383, test:0.001094 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.005676, test:0.000978 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.008246, test:0.000313 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005572, test:0.000309 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005088, test:0.000291 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005382, test:0.000352 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.007619, test:0.000504 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005245, test:0.000371 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004720, test:0.000329 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004862, test:0.000335 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004918, test:0.000528 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004685, test:0.000504 | lr:0.001000\n",
      "Mean absolute error:  2.3596340621632943\n",
      "Root mean squared error:  6.191775790137985\n",
      "Epoch[1/100] | loss train:0.044407, test:0.005924 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014790, test:0.000405 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.015948, test:0.007726 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012899, test:0.002349 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009415, test:0.000760 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010108, test:0.001412 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008964, test:0.005359 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009345, test:0.000346 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010185, test:0.000730 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009245, test:0.000735 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007224, test:0.003334 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008071, test:0.001525 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008793, test:0.000421 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007589, test:0.001417 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008306, test:0.003312 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008772, test:0.000544 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007858, test:0.002697 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008472, test:0.001189 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.013694, test:0.000334 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.010250, test:0.001389 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008506, test:0.005317 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007451, test:0.001621 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.013012, test:0.004989 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.013316, test:0.002598 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008478, test:0.001408 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008619, test:0.000498 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006816, test:0.001340 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.011245, test:0.001629 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008077, test:0.000444 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.005752, test:0.001322 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007786, test:0.000777 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006709, test:0.000546 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006721, test:0.002974 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007825, test:0.001955 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.010253, test:0.003820 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008758, test:0.001147 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007861, test:0.000731 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007766, test:0.003980 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007120, test:0.000329 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007626, test:0.000513 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005454, test:0.000531 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005408, test:0.000604 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005137, test:0.000482 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005005, test:0.000436 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004955, test:0.000535 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[46/100] | loss train:0.005320, test:0.000382 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005332, test:0.000370 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004955, test:0.000356 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005569, test:0.000355 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005749, test:0.000309 | lr:0.001000\n",
      "Mean absolute error:  1.9326370558580306\n",
      "Root mean squared error:  5.858623016580412\n",
      "Epoch[1/100] | loss train:0.052700, test:0.003204 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011890, test:0.001269 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012388, test:0.000318 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011509, test:0.000299 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008953, test:0.001556 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009342, test:0.004761 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009231, test:0.000952 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007512, test:0.000670 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009324, test:0.000893 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009252, test:0.001004 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.006818, test:0.000327 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008656, test:0.000583 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.006602, test:0.000822 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008515, test:0.001678 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008800, test:0.000364 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007710, test:0.000895 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007037, test:0.000811 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007268, test:0.000744 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006881, test:0.000977 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008253, test:0.000347 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008123, test:0.001029 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007175, test:0.005098 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007428, test:0.001184 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.016249, test:0.000451 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008647, test:0.001161 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007126, test:0.000378 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008056, test:0.000550 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009456, test:0.000812 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007054, test:0.000691 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007515, test:0.000808 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007340, test:0.000541 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007549, test:0.000488 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007349, test:0.000788 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006412, test:0.001764 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007548, test:0.000433 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009748, test:0.002478 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008186, test:0.000482 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006929, test:0.000655 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007031, test:0.001366 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006819, test:0.000617 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005495, test:0.000434 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006394, test:0.000353 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006443, test:0.000512 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.010555, test:0.000365 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005725, test:0.000431 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005239, test:0.000369 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005130, test:0.000524 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005291, test:0.000392 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006834, test:0.000379 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005102, test:0.000349 | lr:0.001000\n",
      "Mean absolute error:  2.152883681219892\n",
      "Root mean squared error:  5.941742565069059\n",
      "Epoch[1/100] | loss train:0.058323, test:0.001853 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013786, test:0.005221 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010629, test:0.000947 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009762, test:0.000338 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010342, test:0.002722 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010403, test:0.001077 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010678, test:0.000900 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008415, test:0.001760 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008316, test:0.000557 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007594, test:0.001299 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008446, test:0.000547 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009415, test:0.000689 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008045, test:0.003648 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008398, test:0.000395 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.011015, test:0.000452 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.013457, test:0.000975 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008362, test:0.002470 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006688, test:0.000837 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007910, test:0.003657 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008182, test:0.000600 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008265, test:0.000356 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009194, test:0.000660 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006970, test:0.002700 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007130, test:0.002694 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009723, test:0.000802 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008090, test:0.000367 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006735, test:0.000454 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008095, test:0.001153 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007006, test:0.000345 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007996, test:0.001000 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007128, test:0.001371 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007055, test:0.001394 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007551, test:0.000371 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007805, test:0.000487 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007157, test:0.000974 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008474, test:0.002178 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006692, test:0.000442 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007067, test:0.000469 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006881, test:0.001380 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007595, test:0.000638 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005590, test:0.000402 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006804, test:0.000356 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006457, test:0.000352 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005867, test:0.000371 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005580, test:0.000439 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005269, test:0.000499 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007455, test:0.000364 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005201, test:0.000420 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005092, test:0.000867 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005317, test:0.000347 | lr:0.001000\n",
      "Mean absolute error:  2.016143514846776\n",
      "Root mean squared error:  5.891292391734544\n",
      "Epoch[1/100] | loss train:0.056729, test:0.000936 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.016651, test:0.008918 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.014708, test:0.001214 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009758, test:0.007918 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.013762, test:0.001916 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009514, test:0.002128 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009833, test:0.000801 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008907, test:0.000696 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010622, test:0.000916 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008763, test:0.001239 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010344, test:0.008887 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010075, test:0.000689 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007954, test:0.001489 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009161, test:0.001911 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008759, test:0.000540 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009396, test:0.001198 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007809, test:0.000525 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009847, test:0.000353 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/100] | loss train:0.008090, test:0.000923 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.013099, test:0.002516 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008589, test:0.000392 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007489, test:0.000378 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006639, test:0.001141 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008026, test:0.000918 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008736, test:0.001034 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009787, test:0.000432 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007471, test:0.000446 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007411, test:0.000437 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007130, test:0.001569 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008818, test:0.002112 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009930, test:0.000397 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009444, test:0.000986 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007191, test:0.001263 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009148, test:0.000829 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007003, test:0.002897 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007389, test:0.000601 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008141, test:0.000544 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007038, test:0.000774 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007573, test:0.001310 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006848, test:0.000812 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007318, test:0.000361 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005750, test:0.000415 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005169, test:0.000398 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005664, test:0.000346 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006614, test:0.000357 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005700, test:0.000361 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004934, test:0.000374 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004967, test:0.000382 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.008749, test:0.000446 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005541, test:0.000345 | lr:0.001000\n",
      "Mean absolute error:  1.8312447378697387\n",
      "Root mean squared error:  5.856230426061768\n",
      "Epoch[1/100] | loss train:0.080205, test:0.001303 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014467, test:0.000900 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011260, test:0.000801 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012661, test:0.000506 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009908, test:0.000319 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009353, test:0.002469 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008991, test:0.004432 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011834, test:0.001182 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008115, test:0.002224 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009025, test:0.008242 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010179, test:0.000702 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008085, test:0.000353 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007938, test:0.000702 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008172, test:0.000359 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007426, test:0.000333 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008284, test:0.000761 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008666, test:0.000512 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007708, test:0.001020 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006497, test:0.000328 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009521, test:0.002214 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008860, test:0.000779 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006608, test:0.001264 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007304, test:0.000727 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007436, test:0.000797 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008269, test:0.000983 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007581, test:0.000481 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009630, test:0.001032 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007888, test:0.000372 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006541, test:0.000930 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006560, test:0.000389 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007663, test:0.000595 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007535, test:0.000336 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007134, test:0.001395 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008379, test:0.000625 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007729, test:0.000429 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009540, test:0.001073 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007990, test:0.000750 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007342, test:0.003045 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008292, test:0.001227 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007262, test:0.000782 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006808, test:0.000450 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006075, test:0.000347 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005562, test:0.000353 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005211, test:0.000362 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005241, test:0.000468 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005043, test:0.000449 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005554, test:0.000349 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005043, test:0.000361 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005233, test:0.000338 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005987, test:0.000303 | lr:0.001000\n",
      "Mean absolute error:  2.0641864675886676\n",
      "Root mean squared error:  5.903739880903077\n",
      "Epoch[1/100] | loss train:0.049156, test:0.012500 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.015513, test:0.000379 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011305, test:0.000301 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012744, test:0.000298 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009964, test:0.002252 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008695, test:0.001831 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008755, test:0.000394 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009405, test:0.000378 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008495, test:0.010003 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009435, test:0.001547 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007259, test:0.000348 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008041, test:0.001860 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008036, test:0.000458 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009101, test:0.001706 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008152, test:0.001400 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008813, test:0.000704 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010081, test:0.004037 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008732, test:0.000513 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008175, test:0.002200 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009558, test:0.002377 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008544, test:0.000435 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006058, test:0.000430 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007596, test:0.001184 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006935, test:0.002046 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006317, test:0.000494 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008857, test:0.000974 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.005879, test:0.000630 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007924, test:0.001049 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.009850, test:0.001055 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006638, test:0.000403 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006837, test:0.000353 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007435, test:0.000378 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006182, test:0.001437 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006183, test:0.000510 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009184, test:0.003291 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008014, test:0.001306 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008424, test:0.000879 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007783, test:0.001273 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006431, test:0.000903 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006698, test:0.000412 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005563, test:0.000341 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005685, test:0.000350 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[43/100] | loss train:0.005310, test:0.000322 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.007213, test:0.000377 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004871, test:0.000332 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.007229, test:0.000326 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004965, test:0.000300 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.007954, test:0.000311 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005127, test:0.000310 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004577, test:0.000298 | lr:0.001000\n",
      "Mean absolute error:  1.8229924479079236\n",
      "Root mean squared error:  5.813977216309009\n",
      "Epoch[1/100] | loss train:0.050999, test:0.000680 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009815, test:0.000609 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009516, test:0.003249 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008805, test:0.001129 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008358, test:0.000390 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009815, test:0.000373 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009306, test:0.000976 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008632, test:0.003113 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007766, test:0.001087 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009389, test:0.004419 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007668, test:0.000795 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007044, test:0.003392 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.006580, test:0.000299 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007869, test:0.000691 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007370, test:0.004873 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.015130, test:0.004951 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009872, test:0.000385 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008071, test:0.000538 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009453, test:0.000637 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006855, test:0.000568 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007832, test:0.000515 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008234, test:0.001353 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.012427, test:0.000392 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007514, test:0.000453 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007256, test:0.002182 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006435, test:0.000472 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006535, test:0.000377 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006984, test:0.004258 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007337, test:0.000363 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006334, test:0.000377 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007300, test:0.001939 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007437, test:0.000536 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007818, test:0.000462 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006770, test:0.000508 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007778, test:0.000358 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006849, test:0.000759 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006253, test:0.001375 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007206, test:0.000699 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007957, test:0.003364 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008645, test:0.000398 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005998, test:0.000369 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005739, test:0.000464 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005655, test:0.000386 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.008978, test:0.000373 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006765, test:0.000395 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005252, test:0.000470 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005960, test:0.000450 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005717, test:0.001130 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005896, test:0.000380 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004874, test:0.000412 | lr:0.001000\n",
      "Mean absolute error:  1.8462678284003278\n",
      "Root mean squared error:  5.906627775907528\n",
      "Epoch[1/100] | loss train:0.067458, test:0.002387 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.015075, test:0.007986 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013090, test:0.003329 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012436, test:0.000443 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009160, test:0.000458 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.032089, test:0.002842 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.012201, test:0.000383 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008532, test:0.001307 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007946, test:0.002356 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009150, test:0.001604 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.014515, test:0.001884 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008211, test:0.002970 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007981, test:0.004319 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007420, test:0.000477 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008658, test:0.000855 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007230, test:0.005479 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007903, test:0.001116 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008279, test:0.001131 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007658, test:0.000966 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008291, test:0.002023 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007266, test:0.000344 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007809, test:0.002223 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007758, test:0.002575 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007127, test:0.003407 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007847, test:0.000588 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007730, test:0.000688 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006466, test:0.002936 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007264, test:0.002576 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006871, test:0.000468 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007303, test:0.005625 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007695, test:0.000464 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007682, test:0.001545 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007467, test:0.003970 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008707, test:0.000938 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008117, test:0.001712 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007135, test:0.001370 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006160, test:0.003993 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007435, test:0.003003 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007406, test:0.002864 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007762, test:0.001123 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006079, test:0.000605 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005475, test:0.000393 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005213, test:0.000531 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005168, test:0.000435 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005479, test:0.000418 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005286, test:0.000531 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005801, test:0.000470 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005700, test:0.000431 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005275, test:0.000375 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005419, test:0.000473 | lr:0.001000\n",
      "Mean absolute error:  2.0346372356487343\n",
      "Root mean squared error:  6.051566612239694\n",
      "Epoch[1/100] | loss train:0.053659, test:0.000561 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.015419, test:0.001542 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.015444, test:0.000679 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011050, test:0.000300 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009283, test:0.001306 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011763, test:0.003374 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.011976, test:0.002224 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011540, test:0.001689 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009296, test:0.000480 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008075, test:0.002376 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008211, test:0.002810 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008298, test:0.000547 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008632, test:0.000629 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008351, test:0.003207 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008128, test:0.000845 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/100] | loss train:0.006738, test:0.001000 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008026, test:0.003680 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009772, test:0.000812 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007683, test:0.000622 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007751, test:0.000960 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007107, test:0.000558 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008457, test:0.001312 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010123, test:0.000706 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007391, test:0.008448 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008593, test:0.003521 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008746, test:0.002358 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009969, test:0.000891 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008010, test:0.001015 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008003, test:0.000521 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008264, test:0.000402 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007619, test:0.000504 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007997, test:0.001157 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006817, test:0.000438 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007637, test:0.004881 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007283, test:0.001134 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007102, test:0.002650 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008961, test:0.000667 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007799, test:0.000300 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008107, test:0.000371 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006499, test:0.001752 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005382, test:0.000416 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005497, test:0.000385 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005466, test:0.000464 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005816, test:0.001001 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005180, test:0.000461 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005415, test:0.000429 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006303, test:0.000456 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005365, test:0.000431 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005405, test:0.000378 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005606, test:0.000596 | lr:0.001000\n",
      "Mean absolute error:  2.4271100357599993\n",
      "Root mean squared error:  6.212985993442065\n",
      "Epoch[1/100] | loss train:0.050950, test:0.004538 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013949, test:0.001689 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012873, test:0.005480 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011309, test:0.000386 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008408, test:0.001991 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012553, test:0.005205 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.014989, test:0.001525 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011025, test:0.000428 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008947, test:0.000321 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008209, test:0.000336 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008960, test:0.000384 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007531, test:0.000672 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007907, test:0.004228 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.012084, test:0.001852 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.010091, test:0.006142 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009487, test:0.000692 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008936, test:0.002637 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.011286, test:0.002217 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008406, test:0.001017 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008480, test:0.000425 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007453, test:0.000763 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008439, test:0.000370 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007066, test:0.001646 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007140, test:0.001404 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007658, test:0.000455 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007773, test:0.001683 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008171, test:0.000410 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006989, test:0.000697 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007406, test:0.001100 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007689, test:0.001668 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.011277, test:0.002389 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008967, test:0.001577 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006934, test:0.001345 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007408, test:0.000600 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006893, test:0.000419 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006903, test:0.000457 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008116, test:0.000577 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007896, test:0.000441 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007345, test:0.001343 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006712, test:0.000428 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005638, test:0.000413 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005494, test:0.000397 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007433, test:0.000449 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005533, test:0.000439 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005640, test:0.000436 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005298, test:0.000617 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005441, test:0.000322 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005103, test:0.000410 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004895, test:0.000370 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005334, test:0.000596 | lr:0.001000\n",
      "Mean absolute error:  2.348452638256427\n",
      "Root mean squared error:  6.250519902552687\n",
      "Epoch[1/100] | loss train:0.043787, test:0.001498 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012303, test:0.005602 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012069, test:0.001772 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009468, test:0.001320 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.016163, test:0.000975 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011050, test:0.001275 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008235, test:0.001400 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008835, test:0.000403 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007694, test:0.006969 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009714, test:0.000471 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008741, test:0.006196 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007179, test:0.001357 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.011890, test:0.001664 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008630, test:0.003869 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.015168, test:0.000387 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009379, test:0.000365 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007981, test:0.003951 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009509, test:0.000728 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007788, test:0.000441 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008030, test:0.000870 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007417, test:0.000543 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007484, test:0.000441 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010691, test:0.001177 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007787, test:0.000981 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008443, test:0.001186 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.011769, test:0.002163 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007040, test:0.000983 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007677, test:0.000575 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008438, test:0.001429 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008327, test:0.001133 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006913, test:0.000950 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006286, test:0.000610 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008553, test:0.001922 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009929, test:0.000963 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006638, test:0.001250 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007594, test:0.001156 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007181, test:0.000351 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008239, test:0.000398 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007130, test:0.001486 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/100] | loss train:0.007476, test:0.000466 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006114, test:0.000565 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006248, test:0.000487 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005564, test:0.000851 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.008999, test:0.000395 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005492, test:0.000444 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005446, test:0.000407 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007688, test:0.000370 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006213, test:0.000459 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006036, test:0.000486 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005413, test:0.000423 | lr:0.001000\n",
      "Mean absolute error:  2.1185721586644912\n",
      "Root mean squared error:  6.052418442545389\n",
      "Epoch[1/100] | loss train:0.054915, test:0.001379 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012637, test:0.000728 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009945, test:0.002634 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011127, test:0.000317 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010575, test:0.000462 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011058, test:0.000358 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009858, test:0.000408 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008380, test:0.002026 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009360, test:0.000361 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007526, test:0.001001 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010120, test:0.000354 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011062, test:0.001122 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007930, test:0.000502 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.013435, test:0.002882 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007903, test:0.000428 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008474, test:0.001282 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009265, test:0.000405 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008276, test:0.004446 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007984, test:0.000438 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007647, test:0.001289 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007248, test:0.000918 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006792, test:0.000891 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007221, test:0.001819 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007521, test:0.001839 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008885, test:0.002035 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008310, test:0.000506 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007388, test:0.002088 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007406, test:0.001467 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007388, test:0.000536 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007944, test:0.001189 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007447, test:0.002439 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007529, test:0.000375 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007610, test:0.000343 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008170, test:0.003534 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007183, test:0.001212 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007304, test:0.000379 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008021, test:0.000505 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006707, test:0.001322 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007612, test:0.000616 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006864, test:0.000448 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005677, test:0.000572 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005662, test:0.000355 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005678, test:0.000361 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006738, test:0.000357 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005009, test:0.000322 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005200, test:0.000359 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005148, test:0.000340 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005340, test:0.000335 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.007991, test:0.000292 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006354, test:0.000427 | lr:0.001000\n",
      "Mean absolute error:  2.1569430945017656\n",
      "Root mean squared error:  6.0360562579121995\n",
      "Epoch[1/100] | loss train:0.070022, test:0.001846 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012999, test:0.000538 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010141, test:0.000554 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010309, test:0.000296 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008695, test:0.003313 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008482, test:0.000282 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008594, test:0.000456 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009362, test:0.002774 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009634, test:0.000442 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008295, test:0.000393 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010417, test:0.001341 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008750, test:0.003653 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008674, test:0.004457 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009265, test:0.003201 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007487, test:0.000824 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008282, test:0.000421 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.006910, test:0.000749 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007871, test:0.000428 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006716, test:0.000405 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008170, test:0.001583 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008024, test:0.000471 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008791, test:0.001688 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007931, test:0.000526 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.014643, test:0.006423 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.010163, test:0.000834 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006528, test:0.000672 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008187, test:0.002941 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007673, test:0.001363 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007264, test:0.002081 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010162, test:0.002525 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007195, test:0.001487 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007614, test:0.001743 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007478, test:0.000575 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007093, test:0.000592 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006581, test:0.000937 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007060, test:0.002604 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006543, test:0.002863 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007833, test:0.002386 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007627, test:0.000374 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006969, test:0.001715 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006074, test:0.000352 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005601, test:0.000489 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005746, test:0.000384 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005234, test:0.000386 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005135, test:0.000415 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006158, test:0.000424 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005216, test:0.000664 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005626, test:0.000478 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005429, test:0.000378 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005045, test:0.000398 | lr:0.001000\n",
      "Mean absolute error:  1.7751480236210755\n",
      "Root mean squared error:  5.850224472306876\n",
      "Epoch[1/100] | loss train:0.061323, test:0.004032 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013407, test:0.001361 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009649, test:0.000590 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009760, test:0.002746 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009794, test:0.000830 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008516, test:0.000915 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008927, test:0.000791 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009520, test:0.001221 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008734, test:0.001250 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009342, test:0.001710 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008161, test:0.000445 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.006917, test:0.000427 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/100] | loss train:0.007885, test:0.000739 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007225, test:0.006894 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008158, test:0.000861 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007801, test:0.000388 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007465, test:0.002811 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.026272, test:0.000858 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008514, test:0.001278 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008379, test:0.003781 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007359, test:0.001199 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006966, test:0.000583 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008541, test:0.000422 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006116, test:0.000842 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007016, test:0.002636 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007407, test:0.000767 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007370, test:0.000919 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006454, test:0.000540 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007910, test:0.000406 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007012, test:0.000726 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.009267, test:0.000424 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006721, test:0.001762 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007449, test:0.003812 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007743, test:0.000706 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006732, test:0.000630 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006092, test:0.000642 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006516, test:0.002028 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.012305, test:0.000962 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008604, test:0.000337 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007632, test:0.000702 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005685, test:0.000452 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005887, test:0.000361 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006211, test:0.000325 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005172, test:0.000408 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005902, test:0.000303 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005158, test:0.000330 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005487, test:0.000356 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005277, test:0.000636 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005092, test:0.000476 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006827, test:0.000455 | lr:0.001000\n",
      "Mean absolute error:  2.587586025211232\n",
      "Root mean squared error:  6.338281798382657\n",
      "Epoch[1/100] | loss train:0.051284, test:0.000730 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012635, test:0.000517 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010816, test:0.001835 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009421, test:0.000458 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010463, test:0.000717 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009159, test:0.004812 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007822, test:0.000360 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009528, test:0.001588 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009491, test:0.005166 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008399, test:0.000326 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009574, test:0.000594 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010251, test:0.000615 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007659, test:0.001713 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007580, test:0.000668 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007994, test:0.000377 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008635, test:0.002171 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010409, test:0.004755 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008348, test:0.000941 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008730, test:0.004535 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007385, test:0.000707 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008798, test:0.000871 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008059, test:0.000639 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007983, test:0.000480 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008827, test:0.001256 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009013, test:0.000497 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009713, test:0.000995 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008992, test:0.001968 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009302, test:0.000796 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007370, test:0.000460 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008052, test:0.001301 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006882, test:0.007196 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007595, test:0.002091 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007064, test:0.000616 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.014264, test:0.002933 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008554, test:0.000729 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007274, test:0.001042 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007582, test:0.003578 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008378, test:0.000455 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007332, test:0.001836 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007037, test:0.001186 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006094, test:0.000389 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006183, test:0.000409 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005367, test:0.000390 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006779, test:0.000531 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005463, test:0.000400 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006338, test:0.000560 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005572, test:0.000449 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006633, test:0.000493 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005088, test:0.000458 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006739, test:0.000416 | lr:0.001000\n",
      "Mean absolute error:  1.7906787255795944\n",
      "Root mean squared error:  5.885359578437379\n",
      "Epoch[1/100] | loss train:0.051131, test:0.000578 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013730, test:0.002093 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010201, test:0.006788 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.028071, test:0.003119 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.026791, test:0.003605 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.014916, test:0.000339 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010014, test:0.000739 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009182, test:0.000510 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.012295, test:0.003077 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.013725, test:0.001032 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009931, test:0.000353 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009519, test:0.001414 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009378, test:0.000340 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007942, test:0.004132 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.012328, test:0.002129 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.013718, test:0.001111 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008797, test:0.001751 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007525, test:0.004293 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009168, test:0.000386 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009246, test:0.000916 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007880, test:0.004414 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009493, test:0.001160 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007931, test:0.000410 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007986, test:0.000461 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008819, test:0.000459 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007659, test:0.000439 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008645, test:0.001638 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007730, test:0.003117 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007768, test:0.001075 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007143, test:0.003489 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008236, test:0.002564 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.014463, test:0.002690 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008677, test:0.001757 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007350, test:0.000487 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007458, test:0.000696 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008145, test:0.000436 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/100] | loss train:0.008255, test:0.001669 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007320, test:0.000603 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006372, test:0.000447 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007329, test:0.000701 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005981, test:0.000462 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007532, test:0.000519 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006149, test:0.000461 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005375, test:0.000413 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.011013, test:0.000725 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005869, test:0.000448 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005885, test:0.000432 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005418, test:0.000555 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005594, test:0.000427 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005246, test:0.000580 | lr:0.001000\n",
      "Mean absolute error:  1.9799367227481148\n",
      "Root mean squared error:  6.0616933941832425\n",
      "Epoch[1/100] | loss train:0.052832, test:0.000505 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013005, test:0.002396 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012167, test:0.000745 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.014918, test:0.002703 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.015151, test:0.000317 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.012666, test:0.006613 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009136, test:0.000665 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010514, test:0.000427 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.011530, test:0.002546 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007697, test:0.002364 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010968, test:0.000874 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009495, test:0.001077 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008928, test:0.000336 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008026, test:0.001171 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007183, test:0.000351 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007794, test:0.002699 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009330, test:0.000477 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009814, test:0.000950 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007894, test:0.000354 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007130, test:0.000554 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007651, test:0.000428 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007783, test:0.000436 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007670, test:0.004932 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009190, test:0.000551 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007046, test:0.000680 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007644, test:0.000464 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007749, test:0.001957 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007003, test:0.002203 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008485, test:0.005123 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008993, test:0.000440 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007661, test:0.000688 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006655, test:0.000535 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.010309, test:0.000460 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009057, test:0.002482 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008303, test:0.000475 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006848, test:0.001002 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008390, test:0.001349 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006895, test:0.000666 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007043, test:0.001303 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007895, test:0.000447 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005943, test:0.000428 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006975, test:0.000393 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005319, test:0.000422 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005583, test:0.000372 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006575, test:0.000420 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004815, test:0.000410 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005325, test:0.000381 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005499, test:0.000515 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005919, test:0.000384 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006085, test:0.000353 | lr:0.001000\n",
      "Mean absolute error:  2.0992425662359886\n",
      "Root mean squared error:  5.910308191300598\n",
      "Epoch[1/100] | loss train:0.049453, test:0.000793 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010753, test:0.000426 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010847, test:0.006413 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012059, test:0.000277 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008767, test:0.001075 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009475, test:0.000301 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008563, test:0.000845 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008062, test:0.003916 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008278, test:0.002286 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008529, test:0.002084 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009753, test:0.000355 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008027, test:0.000624 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.006810, test:0.001011 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007451, test:0.001394 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008730, test:0.000716 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008930, test:0.000645 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.013892, test:0.000404 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008858, test:0.004951 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008641, test:0.000369 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008664, test:0.001046 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007278, test:0.000345 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.016174, test:0.000518 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008630, test:0.000382 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009120, test:0.009216 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.011051, test:0.001013 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007191, test:0.000441 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007282, test:0.000366 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008613, test:0.000489 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007745, test:0.000755 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007223, test:0.000392 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.011054, test:0.002095 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008338, test:0.003446 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006961, test:0.001044 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006582, test:0.000440 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.016235, test:0.001354 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.010502, test:0.000605 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007740, test:0.001321 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007126, test:0.000518 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007444, test:0.000547 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007189, test:0.001153 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006560, test:0.000389 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005418, test:0.000523 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005656, test:0.000541 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005181, test:0.000437 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005102, test:0.000408 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005678, test:0.000409 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005233, test:0.000457 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005373, test:0.000448 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005577, test:0.000391 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005390, test:0.000621 | lr:0.001000\n",
      "Mean absolute error:  2.1920363554781357\n",
      "Root mean squared error:  6.1736786793330785\n",
      "Epoch[1/100] | loss train:0.048787, test:0.001229 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011929, test:0.001491 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010289, test:0.002338 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009558, test:0.003867 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008800, test:0.000509 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007620, test:0.000856 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009250, test:0.003001 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009212, test:0.002743 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008096, test:0.004733 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/100] | loss train:0.009289, test:0.007155 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008871, test:0.000493 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007896, test:0.003127 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010290, test:0.000502 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008342, test:0.000614 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008392, test:0.000498 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008149, test:0.001411 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007172, test:0.000623 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008090, test:0.000564 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.006720, test:0.000917 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.011777, test:0.004407 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008130, test:0.000874 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007332, test:0.003184 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006313, test:0.000717 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008113, test:0.001372 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007775, test:0.002408 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007974, test:0.000397 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006725, test:0.002933 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007594, test:0.001359 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007816, test:0.000484 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007036, test:0.000367 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006729, test:0.000333 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.012304, test:0.000347 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009126, test:0.000952 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006835, test:0.000800 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006936, test:0.000472 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007363, test:0.002716 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.010439, test:0.000681 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008059, test:0.000430 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007545, test:0.000718 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007341, test:0.000435 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005217, test:0.000640 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.007536, test:0.000612 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.008427, test:0.000533 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005198, test:0.000455 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005232, test:0.000694 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005655, test:0.000380 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005262, test:0.000364 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005136, test:0.000352 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005301, test:0.000431 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.008697, test:0.000382 | lr:0.001000\n",
      "Mean absolute error:  1.8326755348244226\n",
      "Root mean squared error:  5.873744216591696\n",
      "Epoch[1/100] | loss train:0.059129, test:0.001073 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010611, test:0.000432 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.008562, test:0.000532 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008949, test:0.004380 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011060, test:0.000825 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008867, test:0.000711 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008494, test:0.002336 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009072, test:0.007536 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007653, test:0.000357 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007910, test:0.000544 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008957, test:0.001729 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007546, test:0.001298 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008495, test:0.000622 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007363, test:0.000659 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008365, test:0.000513 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006876, test:0.000286 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007792, test:0.000473 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007480, test:0.000728 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008594, test:0.002282 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007286, test:0.000336 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007828, test:0.001752 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007923, test:0.000467 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006822, test:0.001520 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007617, test:0.002606 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.017317, test:0.003199 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008753, test:0.001353 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007088, test:0.000709 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006481, test:0.001160 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.014614, test:0.001373 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008048, test:0.000357 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006930, test:0.000712 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007036, test:0.000437 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006662, test:0.001137 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006510, test:0.000540 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008402, test:0.000719 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007137, test:0.001400 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007476, test:0.000792 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007627, test:0.000832 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006840, test:0.000309 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009089, test:0.003753 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005536, test:0.000314 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005448, test:0.000399 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005348, test:0.000281 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005020, test:0.000342 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006052, test:0.000455 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005372, test:0.000335 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005538, test:0.000323 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.007609, test:0.000420 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005216, test:0.000280 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006329, test:0.000332 | lr:0.001000\n",
      "Mean absolute error:  2.0614448754568273\n",
      "Root mean squared error:  5.932897851235341\n",
      "Epoch[1/100] | loss train:0.057499, test:0.000880 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011902, test:0.000419 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011701, test:0.000672 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009849, test:0.004720 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.014483, test:0.006536 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.014757, test:0.000693 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008655, test:0.001073 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008179, test:0.002106 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008689, test:0.001372 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009790, test:0.000373 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009929, test:0.007774 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011089, test:0.000568 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009222, test:0.000700 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008879, test:0.000744 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007947, test:0.000495 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007247, test:0.000940 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008443, test:0.000451 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007575, test:0.000530 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009868, test:0.000487 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007114, test:0.000963 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007723, test:0.000688 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008141, test:0.000363 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008270, test:0.001734 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007680, test:0.001731 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006885, test:0.000343 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008049, test:0.000462 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008127, test:0.000527 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007493, test:0.001277 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007490, test:0.000536 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007143, test:0.000713 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.010438, test:0.000498 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008278, test:0.000363 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006869, test:0.000841 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/100] | loss train:0.006428, test:0.002463 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007402, test:0.000873 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008642, test:0.000358 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006768, test:0.001051 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006901, test:0.000791 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007856, test:0.000465 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006694, test:0.000365 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.010252, test:0.000350 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005642, test:0.000345 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005061, test:0.000346 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005476, test:0.000448 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005890, test:0.000343 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005872, test:0.000378 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005089, test:0.000314 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005528, test:0.000365 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005009, test:0.000307 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005270, test:0.000369 | lr:0.001000\n",
      "Mean absolute error:  1.8571914769849318\n",
      "Root mean squared error:  5.904582655080352\n",
      "Epoch[1/100] | loss train:0.044048, test:0.000581 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.019235, test:0.000437 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012202, test:0.001315 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010513, test:0.006081 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009699, test:0.003360 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009933, test:0.000297 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008715, test:0.000869 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011325, test:0.000323 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007920, test:0.002641 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007609, test:0.001103 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008086, test:0.001014 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009703, test:0.004856 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008466, test:0.000386 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007947, test:0.003382 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007104, test:0.002901 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007566, test:0.000554 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008269, test:0.001192 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007043, test:0.000334 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007290, test:0.000598 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007939, test:0.001541 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006418, test:0.001380 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007841, test:0.002707 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008224, test:0.000605 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008131, test:0.001120 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006954, test:0.000585 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.010850, test:0.004056 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007253, test:0.000366 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006452, test:0.000478 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007972, test:0.003443 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007021, test:0.000452 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007716, test:0.000404 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006370, test:0.000474 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006845, test:0.000559 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009198, test:0.000378 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006380, test:0.000387 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006913, test:0.002603 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006581, test:0.000351 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006818, test:0.000448 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006722, test:0.000941 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006660, test:0.000795 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.011550, test:0.000432 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005586, test:0.000407 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.004763, test:0.000421 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.008288, test:0.000325 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005656, test:0.000400 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005069, test:0.000303 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007012, test:0.000459 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005513, test:0.000365 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005486, test:0.000456 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004965, test:0.000300 | lr:0.001000\n",
      "Mean absolute error:  1.7974117194812518\n",
      "Root mean squared error:  5.836969488271617\n",
      "Epoch[1/100] | loss train:0.061359, test:0.003458 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013208, test:0.001059 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009483, test:0.000412 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011419, test:0.000629 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012051, test:0.003087 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.013579, test:0.000448 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008422, test:0.000342 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009273, test:0.003136 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010222, test:0.006482 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010340, test:0.000425 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008009, test:0.001940 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009175, test:0.001196 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008017, test:0.002071 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007235, test:0.000504 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007222, test:0.000824 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007138, test:0.000471 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008294, test:0.000871 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008661, test:0.000864 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009457, test:0.004238 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009016, test:0.000543 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007581, test:0.000642 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007917, test:0.000434 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007107, test:0.002082 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007776, test:0.000868 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007508, test:0.002070 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008419, test:0.000820 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006627, test:0.001027 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007363, test:0.000654 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007063, test:0.001543 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009229, test:0.001668 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007513, test:0.000870 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007772, test:0.000916 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007440, test:0.000980 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006848, test:0.001857 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.005915, test:0.000993 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008079, test:0.001324 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007232, test:0.001264 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007551, test:0.001687 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006695, test:0.001033 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006704, test:0.000606 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005864, test:0.000421 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005158, test:0.000418 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005036, test:0.000402 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005491, test:0.000448 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005462, test:0.000395 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005764, test:0.000378 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006376, test:0.000648 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.009313, test:0.000675 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006232, test:0.000604 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004848, test:0.000397 | lr:0.001000\n",
      "Mean absolute error:  1.7812060756212287\n",
      "Root mean squared error:  5.871590426155783\n",
      "Epoch[1/100] | loss train:0.048285, test:0.014652 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011805, test:0.000495 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009991, test:0.001730 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010114, test:0.003026 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009032, test:0.001538 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009370, test:0.000921 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/100] | loss train:0.008901, test:0.001488 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008537, test:0.003832 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008613, test:0.000393 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007069, test:0.002561 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009793, test:0.000348 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008370, test:0.000323 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008235, test:0.000849 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008256, test:0.000474 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009773, test:0.000628 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008643, test:0.000475 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007605, test:0.000700 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009076, test:0.000730 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009645, test:0.000406 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007798, test:0.001611 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007665, test:0.000342 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007109, test:0.001780 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007592, test:0.000826 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007055, test:0.000466 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006826, test:0.000459 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007253, test:0.000741 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007049, test:0.000387 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006930, test:0.000414 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007641, test:0.000819 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006510, test:0.000338 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006872, test:0.000435 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008607, test:0.000666 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008095, test:0.000702 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007930, test:0.000445 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008109, test:0.000721 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007281, test:0.001985 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006850, test:0.000677 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007540, test:0.001303 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007143, test:0.000518 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006511, test:0.001345 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006009, test:0.000403 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005079, test:0.000541 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006277, test:0.000355 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004887, test:0.000318 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005140, test:0.000512 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005598, test:0.000323 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004977, test:0.000368 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005266, test:0.000310 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005069, test:0.000352 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.021117, test:0.000357 | lr:0.001000\n",
      "Mean absolute error:  1.7878816472296677\n",
      "Root mean squared error:  5.851726027439042\n",
      "Epoch[1/100] | loss train:0.067187, test:0.002150 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012866, test:0.003938 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009722, test:0.001400 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010289, test:0.006797 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008154, test:0.000308 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008272, test:0.000428 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009315, test:0.001024 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007550, test:0.000609 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010665, test:0.001234 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008580, test:0.000941 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007691, test:0.000350 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008016, test:0.000466 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007485, test:0.005744 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010864, test:0.000524 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007863, test:0.000981 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009230, test:0.000649 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008565, test:0.001114 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007722, test:0.000768 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.018096, test:0.000853 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009165, test:0.000783 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006263, test:0.002948 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008240, test:0.000355 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007175, test:0.000846 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008476, test:0.000433 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007965, test:0.004674 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007909, test:0.000587 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007795, test:0.000845 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006984, test:0.002744 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006123, test:0.000754 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006812, test:0.001720 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007228, test:0.004502 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006961, test:0.000712 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006692, test:0.004225 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008588, test:0.001211 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007047, test:0.000539 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006754, test:0.001593 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006425, test:0.001628 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006697, test:0.000554 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006993, test:0.001551 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006859, test:0.000440 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005826, test:0.000420 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005488, test:0.000412 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005450, test:0.000422 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004815, test:0.000342 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006059, test:0.000349 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005208, test:0.000336 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004673, test:0.000298 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005215, test:0.000441 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005233, test:0.000317 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005371, test:0.000383 | lr:0.001000\n",
      "Mean absolute error:  1.843531122958014\n",
      "Root mean squared error:  5.916256920375974\n",
      "Epoch[1/100] | loss train:0.072605, test:0.003819 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010608, test:0.000572 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009381, test:0.001617 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009872, test:0.008332 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.013015, test:0.001167 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008423, test:0.000367 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007938, test:0.003114 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008930, test:0.003988 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009993, test:0.000420 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007635, test:0.010103 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009294, test:0.000419 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009794, test:0.000715 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010951, test:0.000881 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007460, test:0.000464 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.015780, test:0.001986 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.009851, test:0.000632 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010051, test:0.001529 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007749, test:0.000492 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008152, test:0.000465 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.010054, test:0.000386 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009649, test:0.002968 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009709, test:0.000712 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008748, test:0.000431 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007284, test:0.000915 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.009845, test:0.000925 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008096, test:0.000479 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007552, test:0.000701 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008174, test:0.000407 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006795, test:0.001622 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006745, test:0.000402 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31/100] | loss train:0.012803, test:0.002302 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008172, test:0.003362 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006952, test:0.000632 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007986, test:0.000887 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007732, test:0.000434 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006579, test:0.000318 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006105, test:0.000440 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007270, test:0.000331 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006817, test:0.000695 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006736, test:0.000391 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005653, test:0.000354 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006110, test:0.000336 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005246, test:0.000280 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005835, test:0.000281 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004780, test:0.000299 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005798, test:0.000372 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005264, test:0.000476 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004865, test:0.000291 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005477, test:0.000315 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005244, test:0.000292 | lr:0.001000\n",
      "Mean absolute error:  1.7011866419132213\n",
      "Root mean squared error:  5.794486307571166\n",
      "Epoch[1/100] | loss train:0.058482, test:0.010646 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011731, test:0.000678 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009997, test:0.000403 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009582, test:0.006770 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010007, test:0.000509 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010392, test:0.000316 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008334, test:0.000539 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009578, test:0.001905 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008126, test:0.000465 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008043, test:0.000919 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008094, test:0.004536 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008793, test:0.000454 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007094, test:0.004375 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007860, test:0.000339 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007117, test:0.006692 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007973, test:0.001391 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008246, test:0.002555 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008078, test:0.000435 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007921, test:0.000424 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007858, test:0.000427 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008402, test:0.002062 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007217, test:0.001336 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007986, test:0.001273 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007795, test:0.001239 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008064, test:0.000731 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006432, test:0.000340 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007679, test:0.000358 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007387, test:0.000364 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008541, test:0.002144 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007110, test:0.000844 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007332, test:0.000497 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008715, test:0.003509 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.011674, test:0.000327 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007106, test:0.000342 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.016102, test:0.000514 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008341, test:0.000437 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.013534, test:0.001595 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009205, test:0.000923 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007626, test:0.001625 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007327, test:0.000674 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006162, test:0.000693 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006586, test:0.000435 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005262, test:0.000332 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005559, test:0.000332 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004783, test:0.000342 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005266, test:0.000647 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005195, test:0.000314 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005462, test:0.000466 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006313, test:0.000311 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005184, test:0.000394 | lr:0.001000\n",
      "Mean absolute error:  2.1389008022629112\n",
      "Root mean squared error:  5.961116252716749\n",
      "Epoch[1/100] | loss train:0.054533, test:0.000637 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011536, test:0.002040 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010513, test:0.005896 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011437, test:0.005025 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.008952, test:0.000887 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008959, test:0.001275 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008134, test:0.000820 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009911, test:0.000461 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008250, test:0.000950 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010689, test:0.003271 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010906, test:0.001058 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008002, test:0.000787 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009755, test:0.001650 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009009, test:0.000551 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008156, test:0.000986 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008783, test:0.002485 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007463, test:0.001201 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010162, test:0.000464 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007290, test:0.001886 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007260, test:0.000465 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007660, test:0.000992 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006847, test:0.000831 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.010478, test:0.003582 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008421, test:0.002170 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007088, test:0.003189 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008332, test:0.000803 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006887, test:0.000938 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007217, test:0.000510 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007806, test:0.000708 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006403, test:0.000694 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008283, test:0.000997 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008503, test:0.000825 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007493, test:0.000604 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007588, test:0.000341 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006560, test:0.000795 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006028, test:0.000639 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008769, test:0.000501 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008528, test:0.000435 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007115, test:0.001361 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007274, test:0.002030 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005895, test:0.000298 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005901, test:0.000321 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005280, test:0.000450 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005309, test:0.000305 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.004947, test:0.000317 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005717, test:0.000300 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005087, test:0.000312 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005351, test:0.000317 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005218, test:0.000383 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004947, test:0.000515 | lr:0.001000\n",
      "Mean absolute error:  1.9597850886832249\n",
      "Root mean squared error:  6.048827644669193\n",
      "Epoch[1/100] | loss train:0.068083, test:0.000439 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011296, test:0.000692 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010435, test:0.000317 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/100] | loss train:0.009356, test:0.000892 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009409, test:0.000375 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009328, test:0.000701 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007381, test:0.002528 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010537, test:0.000341 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008974, test:0.004547 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009351, test:0.000992 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007492, test:0.001288 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011118, test:0.012364 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010952, test:0.000745 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.006874, test:0.007934 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007994, test:0.001975 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008864, test:0.000929 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007415, test:0.000357 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009371, test:0.001250 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007939, test:0.000554 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008810, test:0.003668 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007908, test:0.000406 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007600, test:0.001929 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007568, test:0.001618 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006458, test:0.000310 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007636, test:0.001120 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006749, test:0.000496 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008399, test:0.001522 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006945, test:0.003647 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007005, test:0.000531 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007585, test:0.000906 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007555, test:0.002048 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009488, test:0.000731 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007945, test:0.000459 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006919, test:0.000325 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007403, test:0.000291 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006967, test:0.001528 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.009375, test:0.000456 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006956, test:0.000355 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006444, test:0.000305 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008281, test:0.000639 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007006, test:0.000347 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005149, test:0.000377 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005291, test:0.000407 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005594, test:0.000307 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005420, test:0.000306 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005798, test:0.000294 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005189, test:0.000271 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005378, test:0.000353 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004870, test:0.000296 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004924, test:0.000298 | lr:0.001000\n",
      "Mean absolute error:  2.025851795906127\n",
      "Root mean squared error:  5.871170724319504\n",
      "Epoch[1/100] | loss train:0.062648, test:0.000549 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012397, test:0.001269 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.017091, test:0.006720 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.012734, test:0.002648 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009519, test:0.002876 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011199, test:0.000327 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008266, test:0.001250 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010715, test:0.003531 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.013932, test:0.004043 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.011111, test:0.001565 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008296, test:0.006690 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010053, test:0.000785 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008652, test:0.004224 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.012532, test:0.000455 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009421, test:0.005753 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008131, test:0.000420 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007301, test:0.004022 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010779, test:0.001476 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009291, test:0.000953 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008514, test:0.000389 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007417, test:0.000583 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007090, test:0.005136 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008535, test:0.002758 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008127, test:0.000500 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007038, test:0.001088 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008197, test:0.002092 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007723, test:0.000400 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007157, test:0.000412 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008469, test:0.000860 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008474, test:0.000777 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007818, test:0.002015 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008593, test:0.002234 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007962, test:0.000633 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006407, test:0.000735 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007117, test:0.000674 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007252, test:0.002487 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008632, test:0.001320 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008517, test:0.000425 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007057, test:0.000457 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009029, test:0.002105 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006643, test:0.000413 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006464, test:0.000429 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005853, test:0.000558 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005407, test:0.000390 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006500, test:0.000396 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006338, test:0.000370 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.009417, test:0.000451 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006288, test:0.000401 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005596, test:0.000411 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005654, test:0.000392 | lr:0.001000\n",
      "Mean absolute error:  1.7846962586258406\n",
      "Root mean squared error:  5.860369977242378\n",
      "Epoch[1/100] | loss train:0.069892, test:0.000450 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011137, test:0.001298 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010783, test:0.000452 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009884, test:0.001634 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009759, test:0.001659 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009700, test:0.000558 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009726, test:0.000956 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009788, test:0.001878 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.012802, test:0.003733 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008459, test:0.000447 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008194, test:0.000342 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008856, test:0.000398 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007789, test:0.000993 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.016665, test:0.001844 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008346, test:0.000427 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008366, test:0.001973 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008227, test:0.000629 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007088, test:0.000681 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008256, test:0.000552 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.014567, test:0.002769 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008608, test:0.001989 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007591, test:0.004009 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007702, test:0.000590 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007750, test:0.001393 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007188, test:0.003609 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.009399, test:0.000787 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007155, test:0.000969 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28/100] | loss train:0.009440, test:0.002875 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.011709, test:0.000660 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.010446, test:0.000488 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006928, test:0.002663 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.010471, test:0.000839 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007773, test:0.001155 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007000, test:0.001917 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009794, test:0.000379 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007027, test:0.000665 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007875, test:0.001796 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006325, test:0.000543 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007703, test:0.000592 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006859, test:0.000449 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005848, test:0.000398 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005867, test:0.000406 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.006084, test:0.000790 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005433, test:0.000405 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006521, test:0.000385 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.009315, test:0.000511 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005511, test:0.000373 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.006195, test:0.000366 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005482, test:0.000360 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004791, test:0.000385 | lr:0.001000\n",
      "Mean absolute error:  1.8388926806130579\n",
      "Root mean squared error:  5.863232955459987\n",
      "Epoch[1/100] | loss train:0.052867, test:0.000526 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011290, test:0.004091 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.012053, test:0.011738 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010062, test:0.000854 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009904, test:0.000694 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010328, test:0.008536 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010864, test:0.004647 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008265, test:0.000482 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009009, test:0.001914 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009908, test:0.004581 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.011993, test:0.001410 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009765, test:0.001339 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010511, test:0.001510 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007769, test:0.001028 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007709, test:0.000705 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007691, test:0.000585 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008267, test:0.000456 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007647, test:0.000537 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.015044, test:0.001412 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.010069, test:0.003636 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008632, test:0.001105 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008016, test:0.002002 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006018, test:0.003512 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008125, test:0.000920 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006975, test:0.002307 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007478, test:0.003014 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007604, test:0.000464 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007338, test:0.000902 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008529, test:0.000504 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007482, test:0.001372 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007348, test:0.000872 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007268, test:0.000422 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008065, test:0.001227 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007635, test:0.000984 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.011820, test:0.001958 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.010710, test:0.002257 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007461, test:0.001196 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007114, test:0.000458 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007043, test:0.003864 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008228, test:0.009199 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006979, test:0.000432 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005503, test:0.000470 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005539, test:0.000403 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006260, test:0.000416 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005395, test:0.000413 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005919, test:0.000393 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005346, test:0.000408 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005453, test:0.000535 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005410, test:0.000398 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006002, test:0.000429 | lr:0.001000\n",
      "Mean absolute error:  2.1879132364189853\n",
      "Root mean squared error:  5.997663993435413\n",
      "Epoch[1/100] | loss train:0.051021, test:0.002366 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013309, test:0.000452 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009865, test:0.001819 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009804, test:0.001118 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009273, test:0.005201 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009760, test:0.001480 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.017093, test:0.000848 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009576, test:0.000496 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010867, test:0.002679 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007463, test:0.000602 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007851, test:0.000383 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008332, test:0.000860 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007901, test:0.000665 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.012411, test:0.000926 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.013578, test:0.002965 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008941, test:0.000442 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.010153, test:0.000458 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007221, test:0.001933 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009724, test:0.003254 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007471, test:0.000326 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007392, test:0.000733 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007414, test:0.002087 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006854, test:0.000480 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006938, test:0.005332 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007861, test:0.000372 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006910, test:0.000648 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008833, test:0.000493 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007466, test:0.002622 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008331, test:0.001081 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008343, test:0.001590 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008976, test:0.001817 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006282, test:0.000671 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006887, test:0.000537 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007134, test:0.000346 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007188, test:0.000444 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007915, test:0.002409 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007096, test:0.000459 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007175, test:0.000379 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007527, test:0.002795 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006577, test:0.001190 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006713, test:0.000344 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005490, test:0.000339 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005072, test:0.000344 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004971, test:0.000755 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.007065, test:0.000476 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005172, test:0.000742 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005379, test:0.000303 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005106, test:0.000364 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004862, test:0.000328 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005047, test:0.000293 | lr:0.001000\n",
      "Mean absolute error:  2.105724246629903\n",
      "Root mean squared error:  5.901847023393329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] | loss train:0.058256, test:0.000738 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013451, test:0.001835 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011751, test:0.000347 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008963, test:0.010437 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012372, test:0.000698 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009151, test:0.004673 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008365, test:0.000377 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.007805, test:0.003082 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008441, test:0.000717 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008600, test:0.001090 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.006713, test:0.000277 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007110, test:0.000570 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009374, test:0.001293 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009348, test:0.000318 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009607, test:0.001432 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007739, test:0.000641 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007726, test:0.007848 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010627, test:0.000529 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007799, test:0.000484 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007153, test:0.000349 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007438, test:0.001278 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.006761, test:0.000389 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007767, test:0.000733 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007079, test:0.000779 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007389, test:0.000592 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006801, test:0.000647 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008180, test:0.001505 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007455, test:0.001036 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007242, test:0.000376 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007402, test:0.000357 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007562, test:0.000639 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006754, test:0.000637 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008435, test:0.000577 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008062, test:0.000837 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007104, test:0.000378 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007486, test:0.000758 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.008590, test:0.000580 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007898, test:0.000437 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007826, test:0.000650 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007049, test:0.000338 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005369, test:0.000396 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.004972, test:0.000300 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005044, test:0.000310 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005539, test:0.000291 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005931, test:0.000563 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005331, test:0.000379 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006265, test:0.000315 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005503, test:0.000327 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006660, test:0.000269 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005294, test:0.000309 | lr:0.001000\n",
      "Mean absolute error:  1.6947518071579037\n",
      "Root mean squared error:  5.785069684352606\n",
      "Epoch[1/100] | loss train:0.067591, test:0.001508 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.017190, test:0.000420 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013020, test:0.000670 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009369, test:0.000273 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010675, test:0.001737 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010755, test:0.005580 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009838, test:0.001412 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009128, test:0.001095 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007912, test:0.002184 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010495, test:0.001381 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008327, test:0.004410 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009159, test:0.000885 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.006659, test:0.000316 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007378, test:0.001830 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008185, test:0.004950 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007832, test:0.002895 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007153, test:0.002455 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009603, test:0.000868 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007375, test:0.000347 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007900, test:0.002739 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.009152, test:0.001772 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008952, test:0.000328 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007389, test:0.000745 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.010334, test:0.000430 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007183, test:0.000360 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006663, test:0.000426 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007781, test:0.000603 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007834, test:0.000378 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007379, test:0.001536 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009156, test:0.000367 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008526, test:0.002265 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.009053, test:0.000525 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007438, test:0.000648 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009507, test:0.009240 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008594, test:0.000359 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009386, test:0.000747 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006736, test:0.000426 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006578, test:0.001365 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006644, test:0.000371 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008478, test:0.000466 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006280, test:0.000422 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.008174, test:0.000421 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005251, test:0.000342 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005630, test:0.000371 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006478, test:0.000366 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005336, test:0.000368 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005545, test:0.000584 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005096, test:0.000359 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006753, test:0.000368 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005090, test:0.000356 | lr:0.001000\n",
      "Mean absolute error:  1.8529507416766355\n",
      "Root mean squared error:  5.85299544901112\n",
      "Epoch[1/100] | loss train:0.050349, test:0.000431 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012703, test:0.002944 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010049, test:0.000781 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010815, test:0.002015 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010632, test:0.001607 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011517, test:0.001592 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009130, test:0.000843 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008025, test:0.000370 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007060, test:0.000718 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008794, test:0.000406 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009385, test:0.000642 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010890, test:0.001714 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007734, test:0.001080 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007036, test:0.001782 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008906, test:0.001078 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008386, test:0.000375 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008252, test:0.000403 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008158, test:0.000813 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008111, test:0.001767 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008159, test:0.000998 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008582, test:0.000806 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009159, test:0.001708 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007819, test:0.002440 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.011061, test:0.001787 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/100] | loss train:0.009439, test:0.001780 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007801, test:0.000704 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008007, test:0.004740 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007953, test:0.000386 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007815, test:0.000412 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007697, test:0.001507 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007941, test:0.000583 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007031, test:0.000487 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007811, test:0.001278 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007368, test:0.001335 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007103, test:0.000464 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007996, test:0.000472 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007473, test:0.000620 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007080, test:0.000609 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007153, test:0.000359 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006192, test:0.000558 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006710, test:0.000465 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005680, test:0.000530 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005462, test:0.000375 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.006092, test:0.000547 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005330, test:0.000538 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005722, test:0.000409 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005387, test:0.000392 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005537, test:0.000385 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005084, test:0.000341 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005531, test:0.000493 | lr:0.001000\n",
      "Mean absolute error:  1.9976393452013947\n",
      "Root mean squared error:  6.0389642082345105\n",
      "Epoch[1/100] | loss train:0.056463, test:0.000645 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.014057, test:0.005513 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011651, test:0.000955 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.017112, test:0.001251 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009943, test:0.002094 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009472, test:0.001304 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009862, test:0.000732 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008198, test:0.001915 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.007434, test:0.002229 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.007812, test:0.000546 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007641, test:0.000748 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.015593, test:0.000322 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008515, test:0.002123 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008695, test:0.000307 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009119, test:0.001450 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.011682, test:0.001690 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008550, test:0.000388 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008037, test:0.001405 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009469, test:0.000362 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007893, test:0.000460 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007534, test:0.000387 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007263, test:0.000706 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007480, test:0.000601 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007248, test:0.001035 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007316, test:0.003295 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007762, test:0.000455 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007877, test:0.002284 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007582, test:0.000497 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006719, test:0.000939 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008002, test:0.000376 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.010508, test:0.000557 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.010444, test:0.000639 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007358, test:0.000868 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006540, test:0.001396 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008031, test:0.000939 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007813, test:0.003044 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007870, test:0.000727 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006965, test:0.000522 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.010229, test:0.000595 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008702, test:0.000693 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.007133, test:0.000993 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005135, test:0.000485 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005070, test:0.000448 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005912, test:0.000778 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005985, test:0.000397 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005482, test:0.000390 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005288, test:0.000373 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005753, test:0.000389 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005523, test:0.000394 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005315, test:0.000342 | lr:0.001000\n",
      "Mean absolute error:  1.7642847545231226\n",
      "Root mean squared error:  5.825855171597985\n",
      "Epoch[1/100] | loss train:0.079849, test:0.011680 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.013862, test:0.001934 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011790, test:0.002281 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010403, test:0.000991 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011271, test:0.001661 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010482, test:0.001265 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.010679, test:0.002403 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008173, test:0.001035 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008406, test:0.001215 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008218, test:0.000413 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.012341, test:0.000416 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008696, test:0.004145 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.010440, test:0.000426 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007713, test:0.000678 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.009207, test:0.000448 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008453, test:0.000741 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007522, test:0.002090 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007897, test:0.001007 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008314, test:0.000939 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007551, test:0.000805 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007370, test:0.002346 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007883, test:0.001144 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007248, test:0.000532 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007257, test:0.001331 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006989, test:0.000535 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008387, test:0.000911 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009264, test:0.002454 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007784, test:0.005838 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008684, test:0.000572 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007170, test:0.002318 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007249, test:0.001108 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007684, test:0.000406 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.009034, test:0.002268 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009449, test:0.001115 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008223, test:0.003903 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007573, test:0.000557 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007212, test:0.000612 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008058, test:0.000410 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007168, test:0.002203 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.010571, test:0.004031 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006448, test:0.000488 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005801, test:0.000519 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005576, test:0.000384 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005952, test:0.000590 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005436, test:0.000366 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006049, test:0.000376 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.008276, test:0.000364 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.007193, test:0.000347 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49/100] | loss train:0.005292, test:0.000355 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005498, test:0.000328 | lr:0.001000\n",
      "Mean absolute error:  2.0152195255585537\n",
      "Root mean squared error:  5.885118505881825\n",
      "Epoch[1/100] | loss train:0.062030, test:0.001268 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.009367, test:0.003180 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009445, test:0.002875 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008866, test:0.001183 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010687, test:0.004610 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009881, test:0.003021 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008961, test:0.000341 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010438, test:0.000281 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.006879, test:0.000322 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009468, test:0.000307 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008874, test:0.000943 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007717, test:0.005310 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007175, test:0.000430 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008846, test:0.000527 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007047, test:0.000397 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007771, test:0.000501 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007590, test:0.001311 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007218, test:0.000353 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.009226, test:0.000554 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007814, test:0.001355 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007634, test:0.000458 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.009482, test:0.000444 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008781, test:0.000632 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007447, test:0.000509 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007296, test:0.000766 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007284, test:0.002056 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007462, test:0.000325 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006508, test:0.000883 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006489, test:0.009171 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008161, test:0.000302 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.006781, test:0.002469 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008127, test:0.000742 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007832, test:0.000479 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006532, test:0.000546 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.006237, test:0.000488 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.009568, test:0.000332 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007090, test:0.007313 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.009266, test:0.000279 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006346, test:0.001350 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007176, test:0.000787 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005855, test:0.000298 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005617, test:0.000291 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005821, test:0.000269 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005436, test:0.000274 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005593, test:0.000341 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005147, test:0.000299 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.006346, test:0.000278 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005740, test:0.000289 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005942, test:0.000296 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005367, test:0.000297 | lr:0.001000\n",
      "Mean absolute error:  1.874851422958268\n",
      "Root mean squared error:  5.847843552895185\n",
      "Epoch[1/100] | loss train:0.049788, test:0.000457 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012598, test:0.000942 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009982, test:0.000514 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010729, test:0.000356 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.017047, test:0.002485 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009889, test:0.000952 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007844, test:0.004571 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008887, test:0.000417 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008820, test:0.000440 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.006998, test:0.000344 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010154, test:0.001975 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.011236, test:0.002789 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008700, test:0.000350 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.010955, test:0.007828 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008207, test:0.000596 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007798, test:0.001309 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008098, test:0.002712 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008832, test:0.002100 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007334, test:0.001667 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008698, test:0.002213 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008486, test:0.000407 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007333, test:0.001997 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007248, test:0.000794 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009919, test:0.001011 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007146, test:0.000759 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007077, test:0.000809 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.009156, test:0.000595 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008143, test:0.001016 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006879, test:0.001402 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.006571, test:0.000419 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008258, test:0.000522 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006157, test:0.000946 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006787, test:0.003162 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007317, test:0.002424 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008470, test:0.000762 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006940, test:0.001421 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007507, test:0.000662 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006019, test:0.003026 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006813, test:0.000442 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007199, test:0.000552 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006197, test:0.000489 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.009310, test:0.000292 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005284, test:0.000631 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.004826, test:0.000306 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005207, test:0.000323 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005105, test:0.000423 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005971, test:0.000327 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.004956, test:0.000282 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005397, test:0.000418 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005166, test:0.000353 | lr:0.001000\n",
      "Mean absolute error:  1.81872355368093\n",
      "Root mean squared error:  5.880332765642724\n",
      "Epoch[1/100] | loss train:0.049501, test:0.002198 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010448, test:0.000505 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009647, test:0.000329 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009091, test:0.000925 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007674, test:0.001495 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009395, test:0.002956 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.007783, test:0.000510 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010080, test:0.000974 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008593, test:0.001348 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008297, test:0.000465 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007967, test:0.000644 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.010136, test:0.000561 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008223, test:0.001138 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007802, test:0.001195 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007000, test:0.000755 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007045, test:0.001956 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008764, test:0.000372 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007200, test:0.000502 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008442, test:0.000507 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008726, test:0.001172 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008291, test:0.003082 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/100] | loss train:0.008040, test:0.000835 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007141, test:0.000401 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009165, test:0.000676 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006614, test:0.000977 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007606, test:0.000588 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007601, test:0.003867 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008673, test:0.003399 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007682, test:0.000578 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007485, test:0.001767 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007244, test:0.000916 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007051, test:0.000608 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007443, test:0.000592 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006818, test:0.001075 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007105, test:0.006161 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007873, test:0.001323 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006375, test:0.000629 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007688, test:0.001190 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006699, test:0.000471 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006592, test:0.000483 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006037, test:0.000397 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005130, test:0.000439 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005176, test:0.000357 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005479, test:0.000384 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005669, test:0.000378 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005483, test:0.000543 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007161, test:0.000445 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005113, test:0.000492 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005935, test:0.000540 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005043, test:0.000340 | lr:0.001000\n",
      "Mean absolute error:  1.784254824263927\n",
      "Root mean squared error:  5.835542308899288\n",
      "Epoch[1/100] | loss train:0.053992, test:0.000465 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012027, test:0.000501 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.009300, test:0.002653 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.008699, test:0.000271 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.012752, test:0.001453 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009674, test:0.002284 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008695, test:0.000662 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010496, test:0.001828 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008908, test:0.000973 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009002, test:0.000518 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008227, test:0.004219 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007453, test:0.000634 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008117, test:0.000327 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007700, test:0.000433 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008560, test:0.000610 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.006676, test:0.000568 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009338, test:0.004751 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009399, test:0.001080 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.008743, test:0.000737 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.006745, test:0.001626 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008206, test:0.001260 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007652, test:0.000488 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007129, test:0.000440 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.006683, test:0.002242 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007959, test:0.001700 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007698, test:0.001088 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006789, test:0.003187 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007206, test:0.006264 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007595, test:0.000539 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008225, test:0.001294 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007260, test:0.001398 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.008216, test:0.000532 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006014, test:0.000736 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008296, test:0.003026 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008272, test:0.000533 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006731, test:0.000393 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007114, test:0.000373 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007460, test:0.000524 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007256, test:0.000436 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007470, test:0.001991 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005388, test:0.000280 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005343, test:0.000539 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005675, test:0.000317 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005339, test:0.000305 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005018, test:0.000291 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.006162, test:0.000511 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005161, test:0.000377 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005371, test:0.000315 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005761, test:0.000351 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005366, test:0.000292 | lr:0.001000\n",
      "Mean absolute error:  1.787970650459128\n",
      "Root mean squared error:  5.8041247756926495\n",
      "Epoch[1/100] | loss train:0.060568, test:0.001822 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.010640, test:0.010688 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.013684, test:0.000382 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010293, test:0.000286 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.010149, test:0.000724 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009583, test:0.000404 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.015387, test:0.017056 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.011588, test:0.000794 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.013875, test:0.000349 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.010136, test:0.000630 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.009008, test:0.000801 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008534, test:0.000952 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.008060, test:0.000359 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008878, test:0.000854 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.006989, test:0.006744 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.010370, test:0.002757 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008930, test:0.000376 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.010359, test:0.000411 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007258, test:0.000359 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.008221, test:0.003686 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008193, test:0.000386 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007696, test:0.000383 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007285, test:0.000659 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007000, test:0.000353 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008887, test:0.000568 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007548, test:0.000495 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008014, test:0.001480 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008438, test:0.002575 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007124, test:0.000848 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007650, test:0.000389 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008925, test:0.000407 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006884, test:0.004231 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.008381, test:0.000507 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007032, test:0.007435 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.009984, test:0.000891 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008633, test:0.000900 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006911, test:0.001591 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006872, test:0.000567 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007141, test:0.000377 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008692, test:0.000594 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006378, test:0.000429 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005638, test:0.000427 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005923, test:0.000479 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005517, test:0.000571 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006356, test:0.000410 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[46/100] | loss train:0.005787, test:0.000419 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.007539, test:0.000371 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005232, test:0.000445 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005565, test:0.000477 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005287, test:0.000408 | lr:0.001000\n",
      "Mean absolute error:  2.0056833525710087\n",
      "Root mean squared error:  5.924005404970428\n",
      "Epoch[1/100] | loss train:0.040964, test:0.000856 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011868, test:0.003765 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011243, test:0.000834 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009438, test:0.000743 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011208, test:0.000312 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.010145, test:0.001851 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008199, test:0.000608 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.009541, test:0.001752 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010101, test:0.000620 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008627, test:0.001372 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008875, test:0.002312 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007888, test:0.000424 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.009793, test:0.001018 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007866, test:0.004736 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007084, test:0.000495 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008349, test:0.000391 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007793, test:0.000503 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007458, test:0.000502 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.017009, test:0.001752 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.009586, test:0.002227 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.006840, test:0.000865 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.011918, test:0.000539 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007868, test:0.000722 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008442, test:0.008473 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.006966, test:0.000437 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008634, test:0.000881 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007828, test:0.000352 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007062, test:0.000437 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007412, test:0.004604 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007838, test:0.001197 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007572, test:0.000580 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007117, test:0.000327 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006614, test:0.000624 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006777, test:0.003002 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008718, test:0.000492 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006492, test:0.000704 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007332, test:0.000598 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007095, test:0.000441 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007713, test:0.001104 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007590, test:0.000391 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005982, test:0.000435 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005586, test:0.000473 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005706, test:0.000368 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005788, test:0.000514 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005197, test:0.000313 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.004913, test:0.000327 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005882, test:0.000520 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005356, test:0.000414 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.006165, test:0.000334 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.004952, test:0.000443 | lr:0.001000\n",
      "Mean absolute error:  1.8839005307188619\n",
      "Root mean squared error:  5.9061284922342905\n",
      "Epoch[1/100] | loss train:0.063341, test:0.004675 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012748, test:0.001207 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.010486, test:0.003161 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010533, test:0.001318 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009497, test:0.012292 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.008682, test:0.001181 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008839, test:0.001883 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008812, test:0.001173 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009911, test:0.000630 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008078, test:0.000310 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007359, test:0.003954 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.020308, test:0.003290 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.013002, test:0.002112 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007026, test:0.001933 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008808, test:0.000785 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007080, test:0.001223 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008287, test:0.000512 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.009057, test:0.004714 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007898, test:0.000748 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007566, test:0.001646 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007786, test:0.000402 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007101, test:0.000408 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.007776, test:0.002346 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007864, test:0.000742 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008323, test:0.001652 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007726, test:0.000320 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007415, test:0.001820 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007357, test:0.000638 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.008037, test:0.003635 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009499, test:0.001109 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007142, test:0.000986 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007412, test:0.000498 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.007479, test:0.000973 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.009010, test:0.003405 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007293, test:0.001893 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007008, test:0.002811 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007689, test:0.003061 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.008561, test:0.004762 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.011814, test:0.003996 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008791, test:0.001068 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005418, test:0.000395 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005866, test:0.000399 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005577, test:0.000425 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005531, test:0.000361 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.007094, test:0.000416 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005480, test:0.000403 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.004900, test:0.000398 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005520, test:0.000331 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005237, test:0.000438 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005152, test:0.000495 | lr:0.001000\n",
      "Mean absolute error:  1.925717682609223\n",
      "Root mean squared error:  6.015566704456062\n",
      "Epoch[1/100] | loss train:0.045227, test:0.000762 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.012567, test:0.000813 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.016235, test:0.000418 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.011518, test:0.002112 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009724, test:0.002873 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007909, test:0.001102 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008761, test:0.000371 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008525, test:0.001382 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009532, test:0.005796 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.009210, test:0.000952 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.006723, test:0.001265 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.008603, test:0.005136 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.011635, test:0.000504 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.009814, test:0.000819 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.011647, test:0.001492 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.008079, test:0.000608 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008115, test:0.000373 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008045, test:0.000596 | lr:0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/100] | loss train:0.008462, test:0.000955 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007306, test:0.001596 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008292, test:0.000569 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.018788, test:0.004198 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008741, test:0.002065 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.009418, test:0.000710 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008092, test:0.000443 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.007783, test:0.004720 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.008280, test:0.000403 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.006579, test:0.000429 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006491, test:0.000480 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.008326, test:0.000885 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007296, test:0.000978 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007340, test:0.001202 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006325, test:0.000493 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.015492, test:0.000954 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008252, test:0.000487 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006796, test:0.000781 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.006758, test:0.000423 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007163, test:0.004249 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.007036, test:0.000494 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.006439, test:0.000411 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.005867, test:0.000383 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005802, test:0.000435 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.005299, test:0.000370 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005512, test:0.000531 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006213, test:0.000395 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005090, test:0.000445 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005102, test:0.000478 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005505, test:0.000454 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.004983, test:0.001352 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.006867, test:0.000720 | lr:0.001000\n",
      "Mean absolute error:  2.7926105221374935\n",
      "Root mean squared error:  6.577950648509495\n",
      "Epoch[1/100] | loss train:0.075543, test:0.000357 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011632, test:0.000356 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.011700, test:0.000380 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.010454, test:0.000490 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.011564, test:0.002729 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.011772, test:0.000828 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009706, test:0.000455 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.010144, test:0.000385 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.010142, test:0.000345 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008776, test:0.000676 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.008011, test:0.003350 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.009226, test:0.000541 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007902, test:0.001206 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007162, test:0.000723 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.025808, test:0.000590 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.017101, test:0.004442 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.009229, test:0.000811 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.007681, test:0.001033 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007746, test:0.000359 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007931, test:0.000899 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007764, test:0.000415 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007680, test:0.004533 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008770, test:0.000637 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.010278, test:0.001054 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007761, test:0.000627 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.006752, test:0.000673 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006434, test:0.000621 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.008118, test:0.001512 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.006899, test:0.000991 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007199, test:0.000582 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007481, test:0.001719 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007860, test:0.000371 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006800, test:0.000490 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.008480, test:0.004354 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.008499, test:0.000549 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.006697, test:0.001232 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007281, test:0.000663 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006489, test:0.000536 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006701, test:0.000554 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.007113, test:0.003792 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006056, test:0.000391 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005231, test:0.000313 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007550, test:0.000351 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005827, test:0.000391 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.006723, test:0.000302 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005131, test:0.000341 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005257, test:0.000300 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005971, test:0.000334 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005165, test:0.000308 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005123, test:0.000380 | lr:0.001000\n",
      "Mean absolute error:  2.131171433512303\n",
      "Root mean squared error:  5.981133062966683\n",
      "Epoch[1/100] | loss train:0.061183, test:0.000388 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.011112, test:0.000416 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.015059, test:0.000833 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.009548, test:0.000293 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.007409, test:0.000322 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.007709, test:0.000458 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.008039, test:0.000344 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.008683, test:0.001237 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.008340, test:0.000351 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008879, test:0.001049 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.007680, test:0.000741 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.007775, test:0.000583 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.007867, test:0.002236 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.007393, test:0.000393 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.007179, test:0.007385 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007835, test:0.001025 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.007049, test:0.001272 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.006392, test:0.000350 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007624, test:0.000420 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007578, test:0.002997 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.007461, test:0.003508 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.007527, test:0.002974 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.006628, test:0.001255 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.007954, test:0.002589 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.008798, test:0.001790 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008304, test:0.003770 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.006920, test:0.000593 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.007058, test:0.001542 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.009126, test:0.009086 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.009782, test:0.000294 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.007438, test:0.000719 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.006631, test:0.001660 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006161, test:0.000720 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.006032, test:0.000641 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.007138, test:0.000451 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.007108, test:0.000314 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007093, test:0.000755 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.006470, test:0.000416 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.006301, test:0.000702 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.009093, test:0.000328 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.006549, test:0.000278 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.005797, test:0.000386 | lr:0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[43/100] | loss train:0.006380, test:0.000295 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005356, test:0.000263 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005535, test:0.000569 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.005759, test:0.000258 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005347, test:0.000334 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005295, test:0.000277 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005178, test:0.000287 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.005120, test:0.000290 | lr:0.001000\n",
      "Mean absolute error:  1.7704682945014882\n",
      "Root mean squared error:  5.821281504617999\n",
      "Epoch[1/100] | loss train:0.057932, test:0.006801 | lr:0.010000\n",
      "Epoch[2/100] | loss train:0.016080, test:0.000909 | lr:0.010000\n",
      "Epoch[3/100] | loss train:0.023010, test:0.005543 | lr:0.010000\n",
      "Epoch[4/100] | loss train:0.013498, test:0.006535 | lr:0.010000\n",
      "Epoch[5/100] | loss train:0.009855, test:0.003409 | lr:0.010000\n",
      "Epoch[6/100] | loss train:0.009631, test:0.000766 | lr:0.010000\n",
      "Epoch[7/100] | loss train:0.009718, test:0.015066 | lr:0.010000\n",
      "Epoch[8/100] | loss train:0.013208, test:0.000759 | lr:0.010000\n",
      "Epoch[9/100] | loss train:0.009057, test:0.000635 | lr:0.010000\n",
      "Epoch[10/100] | loss train:0.008223, test:0.000464 | lr:0.010000\n",
      "Epoch[11/100] | loss train:0.010616, test:0.001822 | lr:0.010000\n",
      "Epoch[12/100] | loss train:0.027563, test:0.001570 | lr:0.010000\n",
      "Epoch[13/100] | loss train:0.015723, test:0.001054 | lr:0.010000\n",
      "Epoch[14/100] | loss train:0.008447, test:0.000480 | lr:0.010000\n",
      "Epoch[15/100] | loss train:0.008277, test:0.000901 | lr:0.010000\n",
      "Epoch[16/100] | loss train:0.007648, test:0.000744 | lr:0.010000\n",
      "Epoch[17/100] | loss train:0.008805, test:0.000490 | lr:0.010000\n",
      "Epoch[18/100] | loss train:0.008053, test:0.002507 | lr:0.010000\n",
      "Epoch[19/100] | loss train:0.007331, test:0.002771 | lr:0.010000\n",
      "Epoch[20/100] | loss train:0.007161, test:0.002175 | lr:0.010000\n",
      "Epoch[21/100] | loss train:0.008247, test:0.005683 | lr:0.010000\n",
      "Epoch[22/100] | loss train:0.008251, test:0.002695 | lr:0.010000\n",
      "Epoch[23/100] | loss train:0.008033, test:0.000558 | lr:0.010000\n",
      "Epoch[24/100] | loss train:0.008890, test:0.001851 | lr:0.010000\n",
      "Epoch[25/100] | loss train:0.007388, test:0.000727 | lr:0.010000\n",
      "Epoch[26/100] | loss train:0.008309, test:0.000473 | lr:0.010000\n",
      "Epoch[27/100] | loss train:0.007154, test:0.001115 | lr:0.010000\n",
      "Epoch[28/100] | loss train:0.009114, test:0.002439 | lr:0.010000\n",
      "Epoch[29/100] | loss train:0.007679, test:0.000498 | lr:0.010000\n",
      "Epoch[30/100] | loss train:0.007046, test:0.003575 | lr:0.010000\n",
      "Epoch[31/100] | loss train:0.008034, test:0.000500 | lr:0.010000\n",
      "Epoch[32/100] | loss train:0.007896, test:0.000446 | lr:0.010000\n",
      "Epoch[33/100] | loss train:0.006290, test:0.003855 | lr:0.010000\n",
      "Epoch[34/100] | loss train:0.007115, test:0.000448 | lr:0.010000\n",
      "Epoch[35/100] | loss train:0.011310, test:0.002379 | lr:0.010000\n",
      "Epoch[36/100] | loss train:0.008209, test:0.000532 | lr:0.010000\n",
      "Epoch[37/100] | loss train:0.007056, test:0.001107 | lr:0.010000\n",
      "Epoch[38/100] | loss train:0.007982, test:0.000473 | lr:0.010000\n",
      "Epoch[39/100] | loss train:0.008121, test:0.000659 | lr:0.010000\n",
      "Epoch[40/100] | loss train:0.008188, test:0.000992 | lr:0.010000\n",
      "Epoch[41/100] | loss train:0.009222, test:0.000467 | lr:0.001000\n",
      "Epoch[42/100] | loss train:0.006275, test:0.000559 | lr:0.001000\n",
      "Epoch[43/100] | loss train:0.007980, test:0.000519 | lr:0.001000\n",
      "Epoch[44/100] | loss train:0.005823, test:0.000340 | lr:0.001000\n",
      "Epoch[45/100] | loss train:0.005608, test:0.000350 | lr:0.001000\n",
      "Epoch[46/100] | loss train:0.008343, test:0.000357 | lr:0.001000\n",
      "Epoch[47/100] | loss train:0.005331, test:0.000395 | lr:0.001000\n",
      "Epoch[48/100] | loss train:0.005359, test:0.000390 | lr:0.001000\n",
      "Epoch[49/100] | loss train:0.005697, test:0.000618 | lr:0.001000\n",
      "Epoch[50/100] | loss train:0.008915, test:0.000361 | lr:0.001000\n",
      "Mean absolute error:  1.7470889079553344\n",
      "Root mean squared error:  5.838508702188295\n"
     ]
    }
   ],
   "source": [
    "# 50 epochs\n",
    "\n",
    "n_epochs = 50\n",
    "uni_absolute2 = []\n",
    "uni_root2 = []\n",
    "\n",
    "for i in range(n):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "\n",
    "    model = LSTMModel(input_size=config[\"model\"][\"input_size\"], hidden_layer_size=config[\"model\"][\"lstm_size\"], num_layers=config[\"model\"][\"num_lstm_layers\"], output_size=1, dropout=config[\"model\"][\"dropout\"])\n",
    "    model = model.to(config[\"training\"][\"device\"])\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.98), eps=1e-9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"training\"][\"scheduler_step_size\"], gamma=0.1)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_train, lr_train = run_epoch(train_dataloader, is_training=True)\n",
    "        loss_val, lr_val = run_epoch(val_dataloader)\n",
    "        scheduler.step()\n",
    "\n",
    "        print('Epoch[{}/{}] | loss train:{:.6f}, test:{:.6f} | lr:{:.6f}'\n",
    "                  .format(epoch+1, config[\"training\"][\"num_epoch\"], loss_train, loss_val, lr_train))\n",
    "        \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    predicted_train = np.array([])\n",
    "\n",
    "    for idx, (x, y) in enumerate(train_dataloader):\n",
    "        x = x.to(config[\"training\"][\"device\"])\n",
    "        out = model(x)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        predicted_train = np.concatenate((predicted_train, out))\n",
    "\n",
    "    predicted_val = np.array([])\n",
    "\n",
    "    for idx, (x, y) in enumerate(val_dataloader):\n",
    "        x = x.to(config[\"training\"][\"device\"])\n",
    "        out = model(x)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        predicted_val = np.concatenate((predicted_val, out))\n",
    "\n",
    "    data_y_train_pred = np.zeros(num_data_points)\n",
    "    data_y_val_pred = np.zeros(num_data_points)\n",
    "\n",
    "    data_y_train_pred[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(predicted_train)\n",
    "    data_y_val_pred[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(predicted_val)\n",
    "\n",
    "    mae = mean_absolute_error(close_price_data, data_y_train_pred + data_y_val_pred)\n",
    "    print(\"Mean absolute error: \", mae)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(close_price_data, data_y_train_pred+data_y_val_pred))\n",
    "    print(\"Root mean squared error: \", rmse)\n",
    "    \n",
    "    uni_absolute2.append(mae)\n",
    "    uni_root2.append(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2870b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 40.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mean absolute error, early stop\n",
    "\n",
    "mean = sum(uni_absolute2) / len(uni_absolute2)\n",
    "variance = sum([((x - mean) ** 2) for x in uni_absolute2]) / len(uni_absolute2)\n",
    "sd = variance ** 0.5\n",
    "\n",
    "m, bins, patches = plt.hist(x=uni_absolute2, bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('MAE for 50 Epochs')\n",
    "maxfreq = m.max()\n",
    "plt.text(1.75, 4.5, '\\u03BC={},\\n\\n\\u03C3={}$'.format(mean,sd))\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad592be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 40.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Root mean squared error, early stop\n",
    "\n",
    "mean = sum(uni_root2) / len(uni_root2)\n",
    "variance = sum([((x - mean) ** 2) for x in uni_root2]) / len(uni_root2)\n",
    "sd = variance ** 0.5\n",
    "\n",
    "m, bins, patches = plt.hist(x=uni_root2, bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('RMSE for 50 Epochs')\n",
    "plt.text(1.75, 4.5, '\\u03BC={},\\n\\n\\u03C3={}'.format(mean,sd))\n",
    "maxfreq = m.max()\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
